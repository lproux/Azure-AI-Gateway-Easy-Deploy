{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIM ‚ù§Ô∏è AI Foundry\n",
    "\n",
    "## üé® Image Generation and multi-modal analysis + Authentication using JWT\n",
    "![flow](../../images/image-gen.gif)\n",
    "\n",
    "Playground to try the [OAuth 2.0 authorization feature](https://learn.microsoft.com/azure/api-management/api-management-authenticate-authorize-azure-openai#oauth-20-authorization-using-identity-provider) using identity provider to enable more fine-grained access to AI Foundry models by particular users or client.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- [Python 3.12 or later version](https://www.python.org/) installed\n",
    "- [VS Code](https://code.visualstudio.com/) installed with the [Jupyter notebook extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) enabled\n",
    "- [Python environment](https://code.visualstudio.com/docs/python/environments#_creating-environments) with the [requirements.txt](../../requirements.txt) or run `pip install -r requirements.txt` in your terminal\n",
    "- [An Azure Subscription](https://azure.microsoft.com/free/) with [Contributor](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#contributor) + [RBAC Administrator](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#role-based-access-control-administrator) or [Owner](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#owner) roles\n",
    "- [Azure CLI](https://learn.microsoft.com/cli/azure/install-azure-cli) installed and [Signed into your Azure subscription](https://learn.microsoft.com/cli/azure/authenticate-azure-cli-interactively)\n",
    "\n",
    "‚ñ∂Ô∏è Click `Run All` to execute all steps sequentially, or execute them `Step by Step`... \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "### 0Ô∏è‚É£ Initialize notebook variables\n",
    "\n",
    "- Resources will be suffixed by a unique string based on your subscription id.\n",
    "- Adjust the location parameters according your preferences and on the [product availability by Azure region.](https://azure.microsoft.com/explore/global-infrastructure/products-by-region/?cdn=disable&products=cognitive-services,api-management) \n",
    "- Adjust the models and versions according the [availability by region.](https://learn.microsoft.com/azure/ai-services/openai/concepts/models) \n",
    "\n",
    "*Important* As of the time of this writing, GPT-Image-1 is a gated model, meaning you'll need to [submit a request](https://customervoice.microsoft.com/Pages/ResponsePage.aspx?id=v4j5cvGGr0GRqy180BHbR7en2Ais5pxKtso_Pz4b1_xUQ1VGQUEzRlBIMVU2UFlHSFpSNkpOR0paRSQlQCN0PWcu) to gain access to the model, if you don't have access to GPT-Image-1, you can still use Black Forest models available in most regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ \u001b[1;32mNotebook initialized\u001b[0m ‚åö 10:09:21.769910 \n"
     ]
    }
   ],
   "source": [
    "import os, sys, json\n",
    "sys.path.insert(1, '../../shared')  # add the shared directory to the Python path\n",
    "import utils\n",
    "\n",
    "deployment_name = os.path.basename(os.path.dirname(globals()['__vsc_ipynb_file__']))\n",
    "resource_group_name = f\"lab-{deployment_name}\" # change the name to match your naming style\n",
    "resource_group_location = \"eastus2\"\n",
    "\n",
    "aiservices_config = [{\"name\": \"images\", \"location\": \"westus3\"}]\n",
    "\n",
    "models_config = [{\"name\": \"gpt-4.1\", \"publisher\": \"OpenAI\", \"version\": \"2025-04-14\", \"sku\": \"GlobalStandard\", \"capacity\": 100},          ## a multi-modal chat completion model to analyze images and text\n",
    "                 {\"name\": \"gpt-image-1\", \"publisher\": \"OpenAI\", \"version\": \"2025-04-15\", \"sku\": \"GlobalStandard\", \"capacity\": 1},\n",
    "                 {\"name\": \"FLUX-1.1-pro\", \"publisher\": \"Black Forest Labs\", \"version\": \"1\", \"sku\": \"GlobalStandard\", \"capacity\": 100}]\n",
    "\n",
    "apim_sku = 'Basicv2'\n",
    "apim_subscriptions_config = [{\"name\": \"subscription1\", \"displayName\": \"Subscription 1\"}]\n",
    "\n",
    "inference_api_path = \"inference\"  # path to the inference API in the APIM service\n",
    "inference_api_type = \"AzureOpenAI\"  # options: AzureOpenAI, AzureAI, OpenAI, PassThrough\n",
    "inference_api_version = \"2025-03-01-preview\"\n",
    "foundry_project_name = deployment_name\n",
    "\n",
    "app_registration_name = f\"{deployment_name}-app\" # name of the app that will be registered in Microsoft Entra ID\n",
    "\n",
    "utils.print_ok('Notebook initialized')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "### 1Ô∏è‚É£ Create the App Registration in Microsoft Entra ID\n",
    "The following command creates a client application registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az account show \u001b[0m\n",
      "‚úÖ \u001b[1;32mRetrieved az account\u001b[0m ‚åö 10:09:24.447387 [0m:2s]\n",
      "üëâüèΩ \u001b[1;34mCurrent user: lproux@microsoft.com\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mTenant ID: 2b9d9f47-1fb6-400a-a438-39fe7d768649\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mSubscription ID: d334f2cd-3efd-494e-9fd3-2470b1a13e4c\u001b[0m\n",
      "‚öôÔ∏è \u001b[1;34mRunning: az ad app list --filter \"displayName eq 'image-generation-app'\" \u001b[0m\n",
      "‚úÖ \u001b[1;32mRetrieved app registration with name image-generation-app\u001b[0m ‚åö 10:09:27.278786 [0m:2s]\n",
      "‚öôÔ∏è \u001b[1;34mRunning: az ad app create --display-name image-generation-app --is-fallback-public-client true \u001b[0m\n",
      "‚úÖ \u001b[1;32mCreated app registration with name image-generation-app\u001b[0m ‚åö 10:09:32.251296 [0m:4s]\n",
      "üëâüèª Client Id: 16f1b1b4-2b6d-45dd-94df-564b672fea95\n"
     ]
    }
   ],
   "source": [
    "output = utils.run(\"az account show\", \"Retrieved az account\", \"Failed to get the current az account\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    current_user = output.json_data['user']['name']\n",
    "    tenant_id = output.json_data['tenantId']\n",
    "    subscription_id = output.json_data['id']\n",
    "\n",
    "    utils.print_info(f\"Current user: {current_user}\")\n",
    "    utils.print_info(f\"Tenant ID: {tenant_id}\")\n",
    "    utils.print_info(f\"Subscription ID: {subscription_id}\")\n",
    "\n",
    "client_id = None\n",
    "output = utils.run(f\"az ad app list --filter \\\"displayName eq '{app_registration_name}'\\\"\", f\"Retrieved app registration with name {app_registration_name}\", \"Failed to get the app registration\")\n",
    "if output.success and output.json_data:\n",
    "    client_id = output.json_data[0]['appId']\n",
    "else:\n",
    "    output = utils.run(f\"az ad app create --display-name {app_registration_name} --is-fallback-public-client true\", f\"Created app registration with name {app_registration_name}\", \"Failed to create the app registration\")\n",
    "    if output.success and output.json_data:\n",
    "        client_id = output.json_data['appId']\n",
    "\n",
    "print(f\"üëâüèª Client Id: {client_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### 2Ô∏è‚É£ Create deployment using ü¶æ Bicep\n",
    "\n",
    "This lab uses [Bicep](https://learn.microsoft.com/azure/azure-resource-manager/bicep/overview?tabs=bicep) to declarative define all the resources that will be deployed in the specified resource group. Change the parameters or the [main.bicep](main.bicep) directly to try different configurations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az group show --name lab-image-generation \u001b[0m\n",
      "üëâüèΩ \u001b[1;34mResource group lab-image-generation does not yet exist. Creating the resource group now...\u001b[0m\n",
      "‚öôÔ∏è \u001b[1;34mRunning: az group create --name lab-image-generation --location eastus2 --tags source=ai-gateway \u001b[0m\n",
      "‚úÖ \u001b[1;32mResource group 'lab-image-generation' created\u001b[0m ‚åö 10:11:29.681251 [0m:5s]\n",
      "‚öôÔ∏è \u001b[1;34mRunning: az deployment group create --name image-generation --resource-group lab-image-generation --template-file main.bicep --parameters params.json \u001b[0m\n",
      "‚ùå \u001b[1;33mDeployment 'image-generation' failed\u001b[0m ‚åö 10:14:19.940078 [2m:50s] WARNING: c:\\Users\\lproux\\OneDrive - Microsoft\\bkp\\Documents\\GitHub\\MCP-servers-internalMSFT-and-external\\AI-Gateway\\labs\\image-generation\\main.bicep(67,5) : Warning no-unnecessary-dependson: Remove unnecessary dependsOn entry 'apimModule'. [https://aka.ms/bicep/linter-diagnostics#no-unnecessary-dependson]\n",
      "\n",
      "c:\\Users\\lproux\\OneDrive - Microsoft\\bkp\\Documents\\GitHub\\MCP-servers-internalMSFT-and-external\\AI-Gateway\\labs\\image-generation\\main.bicep(68,5) : Warning no-unnecessary-dependson: Remove unnecessary dependsOn entry 'foundryModule'. [https://aka.ms/bicep/linter-diagnostics#no-unnecessary-dependson]\n",
      "\n",
      "\n",
      "ERROR: {\"status\":\"Failed\",\"error\":{\"code\":\"DeploymentFailed\",\"target\":\"/subscriptions/d334f2cd-3efd-494e-9fd3-2470b1a13e4c/resourceGroups/lab-image-generation/providers/Microsoft.Resources/deployments/image-generation\",\"message\":\"At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/arm-deployment-operations for usage details.\",\"details\":[{\"code\":\"ResourceDeploymentFailure\",\"target\":\"/subscriptions/d334f2cd-3efd-494e-9fd3-2470b1a13e4c/resourceGroups/lab-image-generation/providers/Microsoft.Resources/deployments/foundryModule\",\"message\":\"The resource write operation failed to complete successfully, because it reached terminal provisioning state 'Failed'.\",\"details\":[{\"code\":\"DeploymentFailed\",\"target\":\"/subscriptions/d334f2cd-3efd-494e-9fd3-2470b1a13e4c/resourceGroups/lab-image-generation/providers/Microsoft.Resources/deployments/foundryModule\",\"message\":\"At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/arm-deployment-operations for usage details.\",\"details\":[{\"code\":\"ResourceDeploymentFailure\",\"target\":\"/subscriptions/d334f2cd-3efd-494e-9fd3-2470b1a13e4c/resourceGroups/lab-image-generation/providers/Microsoft.Resources/deployments/models-images-clvvox2jfsmwk\",\"message\":\"The resource write operation failed to complete successfully, because it reached terminal provisioning state 'Failed'.\",\"details\":[{\"code\":\"DeploymentFailed\",\"target\":\"/subscriptions/d334f2cd-3efd-494e-9fd3-2470b1a13e4c/resourceGroups/lab-image-generation/providers/Microsoft.Resources/deployments/models-images-clvvox2jfsmwk\",\"message\":\"At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/arm-deployment-operations for usage details.\",\"details\":[{\"code\":\"SpecialFeatureOrQuotaIdRequired\",\"message\":\"The current subscription does not have access to this model 'Format:OpenAI,Name:gpt-image-1,Version:2025-04-15'.\"}]}]}]}]}]}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the resource group if doesn't exist\n",
    "utils.create_resource_group(resource_group_name, resource_group_location)\n",
    "\n",
    "# Define the Bicep parameters\n",
    "bicep_parameters = {\n",
    "    \"$schema\": \"https://schema.management.azure.com/schemas/2019-04-01/deploymentParameters.json#\",\n",
    "    \"contentVersion\": \"1.0.0.0\",\n",
    "    \"parameters\": {\n",
    "        \"apimSku\": { \"value\": apim_sku },\n",
    "        \"aiServicesConfig\": { \"value\": aiservices_config },\n",
    "        \"modelsConfig\": { \"value\": models_config },\n",
    "        \"apimSubscriptionsConfig\": { \"value\": apim_subscriptions_config },\n",
    "        \"inferenceAPIPath\": { \"value\": inference_api_path },\n",
    "        \"inferenceAPIType\": { \"value\": inference_api_type },\n",
    "        \"foundryProjectName\": { \"value\": foundry_project_name },\n",
    "        \"tenantId\": { \"value\": tenant_id },\n",
    "        \"clientId\": { \"value\": client_id }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Write the parameters to the params.json file\n",
    "with open('params.json', 'w') as bicep_parameters_file:\n",
    "    bicep_parameters_file.write(json.dumps(bicep_parameters))\n",
    "\n",
    "# Run the deployment\n",
    "output = utils.run(f\"az deployment group create --name {deployment_name} --resource-group {resource_group_name} --template-file main.bicep --parameters params.json\",\n",
    "    f\"Deployment '{deployment_name}' succeeded\", f\"Deployment '{deployment_name}' failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "### 4Ô∏è‚É£ Get the deployment outputs\n",
    "\n",
    "We are now at the stage where we only need to retrieve the gateway URL and the subscription before we are ready for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az deployment group show --name image-generation -g lab-image-generation \u001b[0m\n",
      "‚úÖ \u001b[1;32mRetrieved deployment: image-generation\u001b[0m ‚åö 10:14:24.487183 [0m:4s]\n",
      "‚ùå \u001b[1;33mFailed to retrieve output property: 'logAnalyticsWorkspaceId'\n",
      "Error: 'NoneType' object is not subscriptable\u001b[0m ‚åö 10:14:24.487673 \n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Failed to retrieve output property: 'logAnalyticsWorkspaceId'\nError: 'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lproux\\OneDrive - Microsoft\\bkp\\Documents\\GitHub\\MCP-servers-internalMSFT-and-external\\AI-Gateway\\labs\\image-generation\\../../shared\\utils.py:197\u001b[39m, in \u001b[36mget_deployment_output\u001b[39m\u001b[34m(output, output_property, output_label, secure)\u001b[39m\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m     deployment_output = \u001b[43moutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjson_data\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mproperties\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43moutputs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43moutput_property\u001b[49m\u001b[43m]\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    199\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m output_label:\n",
      "\u001b[31mTypeError\u001b[39m: 'NoneType' object is not subscriptable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m output = utils.run(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33maz deployment group show --name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeployment_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m -g \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_group_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRetrieved deployment: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeployment_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to retrieve deployment: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeployment_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output.success \u001b[38;5;129;01mand\u001b[39;00m output.json_data:\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     log_analytics_id = \u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_deployment_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlogAnalyticsWorkspaceId\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mLog Analytics Id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     apim_service_id = utils.get_deployment_output(output, \u001b[33m'\u001b[39m\u001b[33mapimServiceId\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mAPIM Service Id\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      7\u001b[39m     apim_resource_gateway_url = utils.get_deployment_output(output, \u001b[33m'\u001b[39m\u001b[33mapimResourceGatewayURL\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mAPIM API Gateway URL\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lproux\\OneDrive - Microsoft\\bkp\\Documents\\GitHub\\MCP-servers-internalMSFT-and-external\\AI-Gateway\\labs\\image-generation\\../../shared\\utils.py:209\u001b[39m, in \u001b[36mget_deployment_output\u001b[39m\u001b[34m(output, output_property, output_label, secure)\u001b[39m\n\u001b[32m    207\u001b[39m error = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to retrieve output property: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_property\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    208\u001b[39m print_error(error)\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(error)\n",
      "\u001b[31mException\u001b[39m: Failed to retrieve output property: 'logAnalyticsWorkspaceId'\nError: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Obtain all of the outputs from the deployment\n",
    "output = utils.run(f\"az deployment group show --name {deployment_name} -g {resource_group_name}\", f\"Retrieved deployment: {deployment_name}\", f\"Failed to retrieve deployment: {deployment_name}\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    log_analytics_id = utils.get_deployment_output(output, 'logAnalyticsWorkspaceId', 'Log Analytics Id')\n",
    "    apim_service_id = utils.get_deployment_output(output, 'apimServiceId', 'APIM Service Id')\n",
    "    apim_resource_gateway_url = utils.get_deployment_output(output, 'apimResourceGatewayURL', 'APIM API Gateway URL')\n",
    "    apim_subscriptions = json.loads(utils.get_deployment_output(output, 'apimSubscriptions').replace(\"\\'\", \"\\\"\"))\n",
    "    for subscription in apim_subscriptions:\n",
    "        subscription_name = subscription['name']\n",
    "        subscription_key = subscription['key']\n",
    "        utils.print_info(f\"Subscription Name: {subscription_name}\")\n",
    "        utils.print_info(f\"Subscription Key: ****{subscription_key[-4:]}\")\n",
    "    api_key = apim_subscriptions[0].get(\"key\") # default api key to the first subscription key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5'></a>\n",
    "### 5Ô∏è‚É£ Create a device flow to get the access token\n",
    "\n",
    "Notes for fine grained authorization:\n",
    "- The APIM [JWT validation policy](https://learn.microsoft.com/azure/api-management/validate-azure-ad-token-policy) can check for specific claims (that needs to exist in the token) and apply fine-grained authorization.\n",
    "- Group claims is a typical method. You can use this approach to drive authorization. However, when the user is a member of too many groups, the `groups` will be excluded from the token due to limitations in token size.\n",
    "- An alternative is to configure app role definitions and assign users/groups to app roles. This Zero Trust developer best practice improves flexibility and control while increasing application security with least privilege. [Learn more](https://learn.microsoft.com/security/zero-trust/develop/configure-tokens-group-claims-app-roles).\n",
    "- To obtain the `roles` claim, navigate to the \"Expose an API\" section of the App Registration. Add the Application ID URI and a scope. Then, copy the full scope `(app://<id>/scope)` and replace in the scope array below.\n",
    "- Navigate to the \"App Roles\" blade and create an App Role (ex: OpenAI.ChatCompletion) for Users/Groups members. Then assign the testing user or group to the App Role.   \n",
    "- After logging in, use https://jwt.io/ to decode the `access_token` variable and verify that the `roles` are being sent.\n",
    "- With the above configuration, you can add the following fragment to the APIM policy to verify that the user belongs to a specific App Role:\n",
    "```\n",
    "            <required-claims>\n",
    "                <claim name=\"roles\" match=\"any\">\n",
    "                    <value>OpenAI.ChatCompletion</value>\n",
    "                </claim>\n",
    "            </required-claims>\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import msal\n",
    "\n",
    "app = msal.PublicClientApplication(client_id, authority = \"https://login.microsoftonline.com/\" + tenant_id)\n",
    "\n",
    "flow = app.initiate_device_flow(scopes = [\"User.Read\"])\n",
    "\n",
    "if \"user_code\" not in flow:\n",
    "    raise ValueError(\n",
    "        \"Fail to create device flow. Err: %s\" % json.dumps(flow, indent = 4))\n",
    "\n",
    "print(flow[\"message\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6'></a>\n",
    "### 6Ô∏è‚É£ Acquire the token and query the graph API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, base64, json\n",
    "\n",
    "result = app.acquire_token_by_device_flow(flow)\n",
    "\n",
    "if \"access_token\" in result:\n",
    "    access_token = result['access_token']\n",
    "    # Calling graph using the access token\n",
    "    header, payload, signature = access_token.split('.')\n",
    "    def pad(b): return b + '=' * (-len(b) % 4)\n",
    "    print(\"Decoded JWT Header and Payload:\")\n",
    "    print(json.dumps(json.loads(base64.urlsafe_b64decode(pad(header)).decode('utf-8')), indent=4))\n",
    "    print(json.dumps(json.loads(base64.urlsafe_b64decode(pad(payload)).decode('utf-8')), indent=4))\n",
    "\n",
    "    graph_data = requests.get(  # Use token to call downstream service\n",
    "        \"https://graph.microsoft.com/v1.0/me\",\n",
    "        headers={'Authorization': 'Bearer ' + access_token},).json()\n",
    "    print(\"Graph API call result: %s\" % json.dumps(graph_data, indent = 2))\n",
    "    # print(access_token) # Use a tool like https://jwt.io/ to decode the access token and see its contents\n",
    "else:\n",
    "    print(result.get(\"error\"))\n",
    "    print(result.get(\"error_description\"))\n",
    "    print(result.get(\"correlation_id\"))  # You may need this when reporting a bug\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='requests'></a>\n",
    "### üß™ Test the API using the access token\n",
    "\n",
    "Tip: Use the [tracing tool](../../tools/tracing.ipynb) to debug the policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"{apim_resource_gateway_url}/{inference_api_path}/openai/deployments/{models_config[0]['name']}/chat/completions?api-version={inference_api_version}\"\n",
    "\n",
    "messages = { \"messages\": [\n",
    "    {\"role\": \"system\", \"content\": \"You are a sarcastic unhelpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you tell me the time, please?\"}\n",
    "]}\n",
    "\n",
    "response = requests.post(url, headers = {'api-key': api_key, 'Authorization': 'Bearer ' + access_token}, json = messages)\n",
    "utils.print_response_code(response)\n",
    "\n",
    "if (response.status_code == 200):\n",
    "    data = json.loads(response.text)\n",
    "    print(f\"üí¨ {data.get(\"choices\")[0].get(\"message\").get(\"content\")}\")\n",
    "else:\n",
    "    print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sdk'></a>\n",
    "### üß™ Test the API using the Azure OpenAI Python SDK\n",
    "OpenAPI provides a widely used [Python library](https://github.com/openai/openai-python). The library includes type definitions for all request params and response fields. The goal of this test is to assert that APIM can seamlessly proxy requests to OpenAI without disrupting its functionality.\n",
    "- Note: run ```pip install openai``` in a terminal before executing this step.\n",
    "\n",
    "### üé® Generating an image with a simple prompt using two different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from PIL import Image as PILImage\n",
    "from base64 import b64decode\n",
    "from io import BytesIO\n",
    "\n",
    "image_b64 = []\n",
    "\n",
    "for model in models_config:\n",
    "    print(f\"Generating image using model: {model['name']}\")\n",
    "    \n",
    "    image_url = f\"{apim_resource_gateway_url}/{inference_api_path}/openai/deployments/{model['name']}/images/generations?api-version={inference_api_version}\"\n",
    "\n",
    "    image_payload = {\n",
    "        \"prompt\": \"A futuristic cityscape at sunset, vibrant colors, high detail\",\n",
    "        \"n\": 1,\n",
    "        \"size\": \"1024x1024\",\n",
    "        \"output_format\": \"png\"\n",
    "    }\n",
    "\n",
    "    image_response = requests.post(\n",
    "        image_url,\n",
    "        headers={\n",
    "            \"api-key\": api_key,\n",
    "            \"Authorization\": \"Bearer \" + access_token\n",
    "        },\n",
    "        json=image_payload\n",
    "    )\n",
    "\n",
    "    utils.print_response_code(image_response)\n",
    "\n",
    "    if image_response.status_code == 200:\n",
    "        image_data = image_response.json()\n",
    "        print(\"Image generation successful!\")\n",
    "        image_b64.append(image_data[\"data\"][0][\"b64_json\"])\n",
    "        print(\"Image Base64 Data:\", image_b64[-1][:50])  # Print first 50 characters for brevity\n",
    "        image=PILImage.open(BytesIO(b64decode(image_b64[-1])))\n",
    "        ##### Uncomment the line below to save the images generated by each model\n",
    "        ## image.save(f\"{model['name']}_image.png\")\n",
    "        display(image)\n",
    "    else:\n",
    "        print(image_response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§î Process and compare both images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint = f\"{apim_resource_gateway_url}/{inference_api_path}\",\n",
    "    api_key = api_key,\n",
    "    api_version = inference_api_version\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = models_config[0]['name'], \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a sarcastic helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"describe these two image, and tell me which one is better\"},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_b64[0]}\"}},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_b64[1]}\"}}\n",
    "            ]\n",
    "        }\n",
    "    ], \n",
    "    extra_headers = {\"Authorization\": \"Bearer \" + access_token}\n",
    ")\n",
    "\n",
    "print(f\"üí¨ {response.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "### üóëÔ∏è Clean up resources\n",
    "\n",
    "When you're finished with the lab, you should remove all your deployed resources from Azure to avoid extra charges and keep your Azure subscription uncluttered.\n",
    "Use the [clean-up-resources notebook](clean-up-resources.ipynb) for that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
