# CELL-BY-CELL TESTING & VALIDATION STRATEGY
## Master AI Gateway Notebook - Comprehensive Testing Plan

**Goal:** Execute each cell, evaluate outputs for unloaded parameters/variables, and attempt resolution using multiple methods (no mocks)

---

## TESTING PHILOSOPHY

### Core Principles:
1. **Real execution** - No mocks, no simulations
2. **Cell-by-cell validation** - Test each cell independently AND in sequence
3. **Output analysis** - Parse outputs for missing parameters, undefined variables
4. **Multi-method resolution** - Try multiple approaches to fix issues
5. **State tracking** - Track what loaded successfully vs what failed
6. **Auto-recovery** - Attempt automatic fixes before manual intervention

### Testing Layers:
```
Layer 1: Pre-Execution Validation
  ‚Üì
Layer 2: Cell Execution & Output Capture
  ‚Üì
Layer 3: Output Parsing & Error Detection
  ‚Üì
Layer 4: Resolution Attempts (Multi-Method)
  ‚Üì
Layer 5: Post-Execution Validation
  ‚Üì
Layer 6: State Documentation
```

---

## SECTION 1: PRE-EXECUTION VALIDATION

### Create Validation Cell (Insert as Cell 0.5)

```python
# Cell 0.5: Pre-Execution Validator
"""
Validates environment before executing any deployment cells.
Checks for:
- Required files
- Environment variables
- Python dependencies
- Azure CLI availability
- Credentials
"""
import sys, os, subprocess
from pathlib import Path
from typing import List, Tuple, Dict

class PreflightChecker:
    def __init__(self):
        self.errors = []
        self.warnings = []
        self.info = []
        self.fixes_attempted = []

    def check(self, condition: bool, error_msg: str, warning_msg: str = "", fix_func=None):
        """Check condition, record error/warning, attempt fix if provided"""
        if condition:
            return True

        if fix_func:
            self.info.append(f"Attempting fix: {error_msg}")
            self.fixes_attempted.append(error_msg)
            try:
                fix_result = fix_func()
                if fix_result:
                    self.info.append(f"‚úÖ Fixed: {error_msg}")
                    return True
                else:
                    if warning_msg:
                        self.warnings.append(warning_msg)
                    else:
                        self.errors.append(error_msg)
            except Exception as e:
                self.errors.append(f"{error_msg} (fix failed: {e})")
        else:
            if warning_msg:
                self.warnings.append(warning_msg)
            else:
                self.errors.append(error_msg)

        return False

    def report(self):
        print("="*70)
        print("PRE-FLIGHT CHECK RESULTS")
        print("="*70)

        if self.info:
            print("\nüìã INFO:")
            for msg in self.info:
                print(f"  {msg}")

        if self.warnings:
            print("\n‚ö†Ô∏è  WARNINGS:")
            for msg in self.warnings:
                print(f"  {msg}")

        if self.errors:
            print("\n‚ùå ERRORS:")
            for msg in self.errors:
                print(f"  {msg}")
            print("\n‚ö†Ô∏è  Cannot proceed. Fix errors above.")
            return False
        else:
            print("\n‚úÖ All checks passed!")
            return True

# Initialize checker
checker = PreflightChecker()

# Check 1: Bicep files
BICEP_DIR = Path("archive/scripts")
REQUIRED_BICEP = [
    "deploy-01-core.bicep",
    "deploy-02c-apim-api.bicep",
    "deploy-03-supporting.bicep",
    "deploy-04-mcp.bicep"
]

def fix_bicep_path():
    """Try to find bicep files in common locations"""
    search_paths = [
        Path("archive/scripts"),
        Path("../archive/scripts"),
        Path("scripts"),
        Path("bicep"),
        Path("."),
    ]
    for search_path in search_paths:
        if search_path.exists() and (search_path / "deploy-01-core.bicep").exists():
            # Update global BICEP_DIR
            globals()['BICEP_DIR'] = search_path
            return True
    return False

for bicep_file in REQUIRED_BICEP:
    checker.check(
        (BICEP_DIR / bicep_file).exists(),
        f"Missing bicep file: {bicep_file}",
        fix_func=fix_bicep_path
    )

# Check 2: Parameter files
REQUIRED_PARAMS = ["params-01-core.json", "params-03-supporting.json"]
for param_file in REQUIRED_PARAMS:
    checker.check(
        (BICEP_DIR / param_file).exists(),
        f"Missing parameter file: {param_file}"
    )

# Check 3: Environment file
ENV_FILE = Path("master-lab.env")

def fix_env_file():
    """Create master-lab.env from template"""
    template = """# Generated by Pre-Flight Check
SUBSCRIPTION_ID=
RESOURCE_GROUP=
LOCATION=uksouth
APIM_GATEWAY_URL=
APIM_SERVICE=
API_ID=azure-openai-api
INFERENCE_API_PATH=/inference
OPENAI_ENDPOINT=
MODEL_SKU=gpt-4o-mini
"""
    ENV_FILE.write_text(template)
    print(f"Created {ENV_FILE} - FILL IN VALUES BEFORE RUNNING DEPLOYMENT")
    return True

checker.check(
    ENV_FILE.exists(),
    f"Missing {ENV_FILE}",
    fix_func=fix_env_file
)

# Check 4: Required environment variables (from master-lab.env)
if ENV_FILE.exists():
    env_vars = {}
    for line in ENV_FILE.read_text().splitlines():
        if '=' in line and not line.startswith('#'):
            k, v = line.split('=', 1)
            env_vars[k.strip()] = v.strip()

    REQUIRED_VARS = ['SUBSCRIPTION_ID', 'RESOURCE_GROUP', 'LOCATION']
    for var in REQUIRED_VARS:
        checker.check(
            var in env_vars and env_vars[var],
            f"Environment variable not set: {var} (edit {ENV_FILE})"
        )

# Check 5: Azure CLI
def fix_azure_cli():
    """Try to find Azure CLI in common locations"""
    import shutil
    az_path = shutil.which('az')
    if az_path:
        os.environ['AZ_CLI'] = az_path
        return True
    common_paths = [
        r"C:\Program Files\Microsoft SDKs\Azure\CLI2\wbin\az.cmd",
        "/usr/bin/az",
        "/usr/local/bin/az"
    ]
    for path in common_paths:
        if Path(path).exists():
            os.environ['AZ_CLI'] = path
            return True
    return False

checker.check(
    bool(os.getenv('AZ_CLI')) or fix_azure_cli(),
    "Azure CLI not found",
    fix_func=fix_azure_cli
)

# Check 6: Python dependencies
def fix_dependencies():
    """Attempt to install requirements.txt"""
    req_file = Path("requirements.txt")
    if not req_file.exists():
        return False
    result = subprocess.run(
        [sys.executable, "-m", "pip", "install", "-r", str(req_file)],
        capture_output=True,
        text=True
    )
    return result.returncode == 0

REQUIRED_MODULES = ['azure', 'openai', 'dotenv']
for module in REQUIRED_MODULES:
    try:
        __import__(module.replace('-', '_'))
        checker.info.append(f"‚úÖ Module {module} available")
    except ImportError:
        checker.check(
            False,
            f"Missing Python module: {module}",
            fix_func=fix_dependencies
        )

# Check 7: Azure credentials
CREDS_FILE = Path(".azure-credentials.env")
checker.check(
    CREDS_FILE.exists(),
    "No service principal credentials (.azure-credentials.env)",
    warning_msg="Will use interactive Azure CLI login"
)

# Report results
preflight_passed = checker.report()

if not preflight_passed:
    print("\n" + "="*70)
    print("RECOMMENDED ACTIONS:")
    print("="*70)
    print("1. Edit master-lab.env with your Azure subscription details")
    print("2. Ensure Azure CLI is installed and in PATH")
    print("3. Run 'az login' to authenticate")
    print("4. Run this cell again to verify")
    sys.exit(1)
else:
    print(f"\nüìÇ Bicep files location: {BICEP_DIR.resolve()}")
    print("‚úÖ Ready to proceed with deployment")

# Export validated paths for use by other cells
os.environ['BICEP_DIR'] = str(BICEP_DIR.resolve())
```

---

## SECTION 2: CELL EXECUTION WITH OUTPUT CAPTURE

### Create Test Executor Cell (Insert as Cell 0.6)

```python
# Cell 0.6: Cell-by-Cell Test Executor
"""
Executes cells one-by-one, captures outputs, analyzes for issues.
"""
import re, sys, traceback
from IPython import get_ipython
from IPython.utils.capture import capture_output
from typing import Dict, List, Any

class CellTester:
    def __init__(self):
        self.results = {}
        self.undefined_vars = {}
        self.missing_params = {}
        self.cell_outputs = {}
        self.resolution_attempts = {}

    def test_cell(self, cell_num: int, expected_vars: List[str] = None) -> bool:
        """
        Execute a cell and analyze its output.
        Returns True if cell executed successfully.
        """
        print(f"\n{'='*70}")
        print(f"TESTING CELL {cell_num}")
        print(f"{'='*70}")

        try:
            # Capture execution
            ipython = get_ipython()
            with capture_output() as captured:
                ipython.run_cell(In[cell_num])

            # Store output
            self.cell_outputs[cell_num] = {
                'stdout': captured.stdout,
                'stderr': captured.stderr,
                'outputs': captured.outputs
            }

            # Analyze output
            issues = self._analyze_output(cell_num, captured.stdout, captured.stderr)

            # Check for expected variables
            if expected_vars:
                missing = self._check_variables(expected_vars)
                if missing:
                    issues['missing_variables'] = missing

            # Report
            if issues:
                print(f"‚ö†Ô∏è  Issues found in Cell {cell_num}:")
                for issue_type, details in issues.items():
                    print(f"  - {issue_type}: {details}")

                # Attempt resolution
                resolved = self._attempt_resolution(cell_num, issues)
                self.resolution_attempts[cell_num] = resolved

                if resolved:
                    print(f"‚úÖ Issues resolved for Cell {cell_num}")
                    self.results[cell_num] = 'SUCCESS_WITH_FIXES'
                    return True
                else:
                    print(f"‚ùå Could not resolve issues in Cell {cell_num}")
                    self.results[cell_num] = 'FAILED'
                    return False
            else:
                print(f"‚úÖ Cell {cell_num} executed successfully")
                self.results[cell_num] = 'SUCCESS'
                return True

        except Exception as e:
            print(f"‚ùå Cell {cell_num} raised exception:")
            print(f"  {type(e).__name__}: {e}")
            traceback.print_exc()
            self.results[cell_num] = 'EXCEPTION'
            self.resolution_attempts[cell_num] = []

            # Try to extract undefined variables from exception
            if "NameError" in str(type(e)):
                match = re.search(r"name '(\w+)' is not defined", str(e))
                if match:
                    undefined_var = match.group(1)
                    self.undefined_vars.setdefault(cell_num, []).append(undefined_var)
                    print(f"  üìù Detected undefined variable: {undefined_var}")

            return False

    def _analyze_output(self, cell_num: int, stdout: str, stderr: str) -> Dict[str, List[str]]:
        """Parse output for common issues"""
        issues = {}

        # Check for missing environment variables
        env_pattern = r"(?:Missing|not found|undefined).*?(?:env|variable|key).*?:?\s*([A-Z_]+)"
        env_matches = re.findall(env_pattern, stdout + stderr, re.IGNORECASE)
        if env_matches:
            issues['missing_env_vars'] = list(set(env_matches))

        # Check for missing files
        file_pattern = r"(?:No such file|FileNotFoundError|cannot find).*?['\"]([^'\"]+)['\"]"
        file_matches = re.findall(file_pattern, stdout + stderr)
        if file_matches:
            issues['missing_files'] = list(set(file_matches))

        # Check for undefined variables
        undef_pattern = r"NameError.*?name '(\w+)' is not defined"
        undef_matches = re.findall(undef_pattern, stderr)
        if undef_matches:
            issues['undefined_variables'] = list(set(undef_matches))

        # Check for warnings
        if '‚ö†' in stdout or 'WARNING' in stdout.upper():
            warnings = [line for line in stdout.split('\n') if '‚ö†' in line or 'WARNING' in line.upper()]
            issues['warnings'] = warnings[:3]  # Limit to first 3

        # Check for errors
        if '‚ùå' in stdout or 'ERROR' in stdout.upper():
            errors = [line for line in stdout.split('\n') if '‚ùå' in line or 'ERROR' in line.upper()]
            issues['errors'] = errors[:3]

        return issues

    def _check_variables(self, var_names: List[str]) -> List[str]:
        """Check if variables are defined in global scope"""
        ipython = get_ipython()
        missing = []
        for var in var_names:
            if var not in ipython.user_ns or ipython.user_ns[var] is None:
                missing.append(var)
        return missing

    def _attempt_resolution(self, cell_num: int, issues: Dict[str, List[str]]) -> List[str]:
        """
        Attempt to resolve detected issues using multiple methods.
        Returns list of successful resolutions.
        """
        resolutions = []
        ipython = get_ipython()

        # Resolution 1: Missing environment variables
        if 'missing_env_vars' in issues:
            for var in issues['missing_env_vars']:
                # Method 1: Check if it exists in ENV dictionary
                if 'ENV' in ipython.user_ns and var in ipython.user_ns['ENV']:
                    os.environ[var] = ipython.user_ns['ENV'][var]
                    resolutions.append(f"Set {var} from ENV dict")
                    continue

                # Method 2: Check if it's in master-lab.env but not loaded
                env_file = Path('master-lab.env')
                if env_file.exists():
                    for line in env_file.read_text().splitlines():
                        if line.startswith(var + '='):
                            _, value = line.split('=', 1)
                            os.environ[var] = value.strip()
                            resolutions.append(f"Loaded {var} from master-lab.env")
                            break

                # Method 3: Try to derive from existing variables
                derived = self._derive_variable(var, ipython.user_ns)
                if derived:
                    os.environ[var] = derived
                    resolutions.append(f"Derived {var} = {derived[:50]}...")

        # Resolution 2: Missing files
        if 'missing_files' in issues:
            for file in issues['missing_files']:
                # Method 1: Check if file exists with different path
                found_path = self._search_file(file)
                if found_path:
                    resolutions.append(f"Found {file} at {found_path}")

        # Resolution 3: Undefined variables
        if 'undefined_variables' in issues:
            for var in issues['undefined_variables']:
                # Method 1: Check if it should be imported
                if var in ['Path', 'os', 'sys', 'json']:
                    exec(f"import {var}", ipython.user_ns)
                    resolutions.append(f"Imported {var}")
                    continue

                # Method 2: Check if it's defined in earlier cells
                found_in_cell = self._find_variable_definition(var)
                if found_in_cell:
                    resolutions.append(f"{var} defined in Cell {found_in_cell} (re-run that cell)")

                # Method 3: Check if it's a typo of existing variable
                similar = self._find_similar_variable(var, ipython.user_ns)
                if similar:
                    resolutions.append(f"{var} might be typo of {similar}")

        return resolutions

    def _derive_variable(self, var_name: str, namespace: Dict) -> str:
        """Attempt to derive missing variable from existing ones"""
        # Example: APIM_SERVICE from APIM_GATEWAY_URL
        if var_name == 'APIM_SERVICE' and 'APIM_GATEWAY_URL' in os.environ:
            url = os.environ['APIM_GATEWAY_URL']
            match = re.search(r'//([^.]+)', url)
            if match:
                return match.group(1)

        # Example: API_ID default
        if var_name == 'API_ID':
            return 'azure-openai-api'

        # Example: RESOURCE_GROUP from config
        if var_name == 'RESOURCE_GROUP':
            if 'config' in namespace and hasattr(namespace['config'], 'resource_group'):
                return namespace['config'].resource_group

        return None

    def _search_file(self, filename: str) -> str:
        """Search for file in common locations"""
        search_paths = [
            Path('.'),
            Path('archive/scripts'),
            Path('../archive/scripts'),
            Path('scripts'),
            Path('bicep'),
        ]

        for path in search_paths:
            full_path = path / filename
            if full_path.exists():
                return str(full_path.resolve())

        return None

    def _find_variable_definition(self, var_name: str) -> int:
        """Find which cell defines a variable"""
        for cell_num in range(1, len(In)):
            if f"{var_name} =" in In[cell_num] or f"{var_name}=" in In[cell_num]:
                return cell_num
        return None

    def _find_similar_variable(self, var_name: str, namespace: Dict) -> str:
        """Find variables with similar names (detect typos)"""
        import difflib
        all_vars = [k for k in namespace.keys() if not k.startswith('_')]
        matches = difflib.get_close_matches(var_name, all_vars, n=1, cutoff=0.7)
        return matches[0] if matches else None

    def summary_report(self):
        """Print comprehensive test summary"""
        print("\n" + "="*70)
        print("TEST SUMMARY")
        print("="*70)

        success = sum(1 for r in self.results.values() if 'SUCCESS' in r)
        total = len(self.results)

        print(f"\nTotal cells tested: {total}")
        print(f"Successful: {success} ({success/total*100:.1f}%)")
        print(f"Failed: {total - success}")

        if self.resolution_attempts:
            print(f"\nüìù Resolution Attempts:")
            for cell_num, resolutions in self.resolution_attempts.items():
                if resolutions:
                    print(f"  Cell {cell_num}:")
                    for res in resolutions:
                        print(f"    - {res}")

        print("\n" + "="*70)

# Create tester instance
tester = CellTester()
print("‚úÖ Cell Tester initialized - use tester.test_cell(N) to test cells")
```

---

## SECTION 3: TESTING SEQUENCE FOR CELLS 1-41

### Test Plan: Initialization Cells

```python
# Cell 0.7: Execute Test Sequence for Cells 1-41
"""
Tests all initialization cells in correct order.
"""

# Define test sequence with expected outputs
test_sequence = [
    # (cell_num, description, expected_variables)
    (1, "Documentation", []),
    (3, "Environment Loader", ['ENV', 'ENV_FILE', 'config']),
    (4, "Dependencies Install", []),
    (5, "Azure CLI Setup", ['az_cli', 'AZ_CLI']),
    (6, "Endpoint Normalizer", ['OPENAI_ENDPOINT']),
    (7, "az() Helper", ['az']),
    (8, "Deployment Helpers", ['compile_bicep', 'deploy_template', 'get_deployment_outputs']),
    (10, "MCP Initialization", ['MCP_SERVERS']),
    (11, "AzureOps Wrapper", ['AzureOps']),
    (28, "Master Imports", []),
    (30, "Verify Environment", []),
    (34, "Deployment Config", ['subscription_id', 'resource_group_name', 'location']),
    (36, "Azure SDK Auth", ['credential', 'resource_client']),
]

print("="*70)
print("TESTING CELLS 1-41 (INITIALIZATION SEQUENCE)")
print("="*70)

for cell_num, description, expected_vars in test_sequence:
    print(f"\n{'‚îÄ'*70}")
    print(f"[{cell_num}] {description}")
    print(f"{'‚îÄ'*70}")

    # Test cell
    success = tester.test_cell(cell_num, expected_vars)

    if not success:
        print(f"\n‚ö†Ô∏è  Cell {cell_num} failed. Fix issues before continuing.")
        user_input = input("Continue anyway? (y/n): ")
        if user_input.lower() != 'y':
            print("‚ùå Testing stopped.")
            break

print("\n" + "="*70)
print("INITIALIZATION SEQUENCE TEST COMPLETE")
print("="*70)

# Generate report
tester.summary_report()

# Save results to file
import json
results_file = Path("test_results_cells_1_41.json")
results_file.write_text(json.dumps({
    'results': tester.results,
    'outputs': {k: v['stdout'][:500] for k, v in tester.cell_outputs.items()},
    'resolutions': tester.resolution_attempts
}, indent=2))
print(f"\nüìÑ Results saved to {results_file}")
```

---

## SECTION 4: VARIABLE/PARAMETER RESOLUTION MATRIX

### Resolution Methods by Issue Type

| Issue Type | Method 1 | Method 2 | Method 3 | Method 4 |
|------------|----------|----------|----------|----------|
| **Missing Environment Variable** | Check ENV dict | Read master-lab.env | Derive from related vars | Prompt user |
| **Undefined Variable** | Check if should be imported | Find definition in earlier cell | Check for typo (fuzzy match) | Use default value |
| **Missing File** | Search common directories | Check archive/scripts | Download if URL provided | Create from template |
| **Failed Import** | Install via pip | Check if module name changed | Try alternative import | Check Python version |
| **Authentication Error** | Check .azure-credentials.env | Try AzureCliCredential | Run 'az login' | Create service principal |
| **API Error** | Retry with backoff | Check endpoint URL | Verify API key | Check quota/limits |

### Resolution Code Examples

```python
# Example 1: Resolve Missing Environment Variable (Multi-Method)
def resolve_env_var(var_name: str) -> str:
    """Try 4 methods to resolve missing environment variable"""

    # Method 1: Check ENV dictionary
    if 'ENV' in globals() and var_name in globals()['ENV']:
        value = globals()['ENV'][var_name]
        os.environ[var_name] = value
        print(f"[resolve] ‚úÖ {var_name} found in ENV dict")
        return value

    # Method 2: Parse master-lab.env directly
    env_file = Path('master-lab.env')
    if env_file.exists():
        for line in env_file.read_text().splitlines():
            if line.startswith(var_name + '='):
                value = line.split('=', 1)[1].strip()
                if value:
                    os.environ[var_name] = value
                    print(f"[resolve] ‚úÖ {var_name} loaded from {env_file}")
                    return value

    # Method 3: Derive from related variables
    if var_name == 'APIM_SERVICE':
        if 'APIM_GATEWAY_URL' in os.environ:
            url = os.environ['APIM_GATEWAY_URL']
            match = re.search(r'//([^.]+)', url)
            if match:
                value = match.group(1)
                os.environ[var_name] = value
                print(f"[resolve] ‚úÖ {var_name} derived from APIM_GATEWAY_URL")
                return value

    # Method 4: Use sensible default
    defaults = {
        'API_ID': 'azure-openai-api',
        'LOCATION': 'uksouth',
        'MODEL_SKU': 'gpt-4o-mini',
        'INFERENCE_API_PATH': '/inference'
    }
    if var_name in defaults:
        value = defaults[var_name]
        os.environ[var_name] = value
        print(f"[resolve] ‚ö†Ô∏è  {var_name} using default: {value}")
        return value

    # Failed all methods
    print(f"[resolve] ‚ùå Could not resolve {var_name}")
    return None

# Example 2: Resolve Missing File (Multi-Method)
def resolve_missing_file(filename: str) -> Path:
    """Try 3 methods to find missing file"""

    # Method 1: Search common directories
    search_paths = [
        Path('.'),
        Path('archive/scripts'),
        Path('../archive/scripts'),
        Path('../../archive/scripts'),
        Path('scripts'),
        Path('bicep'),
        Path('deployments'),
    ]

    for search_dir in search_paths:
        full_path = search_dir / filename
        if full_path.exists():
            print(f"[resolve] ‚úÖ Found {filename} at {full_path}")
            return full_path.resolve()

    # Method 2: Search entire directory tree (slow)
    print(f"[resolve] Searching entire directory for {filename}...")
    for path in Path('.').rglob(filename):
        print(f"[resolve] ‚úÖ Found {filename} at {path}")
        return path.resolve()

    # Method 3: Check if it's a template that should be created
    if filename == 'master-lab.env':
        # Create from template
        template = create_env_template()
        Path(filename).write_text(template)
        print(f"[resolve] ‚úÖ Created {filename} from template")
        return Path(filename).resolve()

    # Failed all methods
    print(f"[resolve] ‚ùå Could not find {filename}")
    return None

# Example 3: Resolve Undefined Variable (Multi-Method)
def resolve_undefined_variable(var_name: str) -> bool:
    """Try 4 methods to resolve undefined variable"""

    # Method 1: Check if it's a standard library that should be imported
    standard_libs = {
        'os': 'import os',
        'sys': 'import sys',
        'json': 'import json',
        'Path': 'from pathlib import Path',
        'subprocess': 'import subprocess',
        're': 'import re',
    }

    if var_name in standard_libs:
        exec(standard_libs[var_name], globals())
        print(f"[resolve] ‚úÖ Imported {var_name}")
        return True

    # Method 2: Find definition in earlier cells
    for i in range(1, len(In)):
        if f"{var_name} =" in In[i] or f"def {var_name}" in In[i]:
            print(f"[resolve] ‚ÑπÔ∏è  {var_name} defined in Cell {i} - re-run that cell")
            # Optionally auto-run that cell
            get_ipython().run_cell(In[i])
            print(f"[resolve] ‚úÖ Re-executed Cell {i}")
            return True

    # Method 3: Check for typos using fuzzy matching
    import difflib
    all_vars = [k for k in globals().keys() if not k.startswith('_')]
    matches = difflib.get_close_matches(var_name, all_vars, n=3, cutoff=0.7)
    if matches:
        print(f"[resolve] ‚ö†Ô∏è  {var_name} not found. Did you mean: {matches}?")
        return False

    # Method 4: Check if it's a missing dependency
    try:
        exec(f"import {var_name}", globals())
        print(f"[resolve] ‚úÖ Imported module {var_name}")
        return True
    except ImportError:
        print(f"[resolve] ‚ùå Could not resolve {var_name}")
        return False
```

---

## SECTION 5: DEPLOYMENT PHASE TESTING

### Test Deployment Flow (Cells 37.5, 38, 40)

```python
# Cell 0.8: Deployment Phase Tester
"""
Tests the deployment cells with checkpointing and rollback capability.
"""

class DeploymentTester:
    def __init__(self):
        self.checkpoints = {}
        self.deployment_state = {
            'step1': None,  # Core
            'step2': None,  # AI Foundry
            'step3': None,  # Supporting
            'step4': None,  # MCP
        }

    def test_deployment(self):
        """Execute deployment with validation at each step"""

        # Pre-deployment validation
        print("="*70)
        print("DEPLOYMENT TESTING")
        print("="*70)

        print("\n[1/4] Pre-Deployment Validation...")
        self.checkpoint('pre_deployment')

        # Run Cell 37.5 (if exists) or run inline validation
        validation_passed = self._validate_pre_deployment()

        if not validation_passed:
            print("‚ùå Pre-deployment validation failed. Fix issues first.")
            return False

        # Update bicep file paths to use archive/scripts
        self._update_bicep_paths()

        # Execute deployment (Cell 38)
        print("\n[2/4] Executing Main Deployment (Cell 38)...")
        try:
            with capture_output() as captured:
                get_ipython().run_cell(In[38])

            output = captured.stdout

            # Check each deployment step
            self._analyze_deployment_output(output)

            print("‚úÖ Deployment completed")

        except Exception as e:
            print(f"‚ùå Deployment failed: {e}")
            self._attempt_recovery()
            return False

        # Generate environment file (Cell 40)
        print("\n[3/4] Generating Environment File (Cell 40)...")
        try:
            get_ipython().run_cell(In[40])
            print("‚úÖ Environment file generated")
        except Exception as e:
            print(f"‚ö†Ô∏è  Environment file generation had issues: {e}")

        # Post-deployment verification
        print("\n[4/4] Post-Deployment Verification...")
        verification_passed = self._verify_deployment()

        if verification_passed:
            print("\n" + "="*70)
            print("‚úÖ DEPLOYMENT TEST PASSED")
            print("="*70)
            return True
        else:
            print("\n" + "="*70)
            print("‚ö†Ô∏è  DEPLOYMENT COMPLETED WITH WARNINGS")
            print("="*70)
            return False

    def checkpoint(self, name: str):
        """Save current state"""
        self.checkpoints[name] = {
            'env_vars': dict(os.environ),
            'timestamp': datetime.now().isoformat()
        }
        print(f"[checkpoint] Saved: {name}")

    def _validate_pre_deployment(self) -> bool:
        """Validate all prerequisites"""
        checks = []

        # Check bicep files with updated path
        bicep_dir = Path(os.getenv('BICEP_DIR', 'archive/scripts'))
        required_bicep = [
            'deploy-01-core.bicep',
            'deploy-02c-apim-api.bicep',
            'deploy-03-supporting.bicep',
            'deploy-04-mcp.bicep'
        ]

        for bicep in required_bicep:
            exists = (bicep_dir / bicep).exists()
            checks.append(('Bicep: ' + bicep, exists))

        # Check environment variables
        required_vars = ['SUBSCRIPTION_ID', 'RESOURCE_GROUP', 'LOCATION']
        for var in required_vars:
            exists = bool(os.getenv(var))
            checks.append(('ENV: ' + var, exists))

        # Check Azure CLI
        az_cli = os.getenv('AZ_CLI') or 'az_cli' in globals()
        checks.append(('Azure CLI', az_cli))

        # Report
        for check_name, passed in checks:
            status = "‚úÖ" if passed else "‚ùå"
            print(f"  {status} {check_name}")

        return all(passed for _, passed in checks)

    def _update_bicep_paths(self):
        """Update bicep file references to use archive/scripts"""
        bicep_dir = Path(os.getenv('BICEP_DIR', 'archive/scripts'))
        print(f"[config] Using bicep directory: {bicep_dir.resolve()}")

        # Update globals used by deployment functions
        globals()['BICEP_DIR'] = str(bicep_dir.resolve())
        os.environ['BICEP_DIR'] = str(bicep_dir.resolve())

    def _analyze_deployment_output(self, output: str):
        """Parse deployment output for status of each step"""
        steps = ['Step 1', 'Step 2', 'Step 3', 'Step 4']

        for i, step in enumerate(steps, 1):
            if f"{step}" in output:
                # Check if this step succeeded
                if "‚úÖ" in output or "[OK]" in output:
                    self.deployment_state[f'step{i}'] = 'SUCCESS'
                    print(f"  ‚úÖ Step {i} completed")
                elif "‚ùå" in output or "ERROR" in output:
                    self.deployment_state[f'step{i}'] = 'FAILED'
                    print(f"  ‚ùå Step {i} failed")
                else:
                    self.deployment_state[f'step{i}'] = 'UNKNOWN'
                    print(f"  ‚ö†Ô∏è  Step {i} status unclear")

    def _verify_deployment(self) -> bool:
        """Verify deployed resources are accessible"""
        checks = []

        # Check 1: Resource group exists
        if 'resource_client' in globals():
            try:
                rg_name = os.getenv('RESOURCE_GROUP')
                rg = globals()['resource_client'].resource_groups.get(rg_name)
                checks.append(('Resource Group', True))
                print(f"  ‚úÖ Resource group: {rg_name}")
            except Exception as e:
                checks.append(('Resource Group', False))
                print(f"  ‚ùå Resource group check failed: {e}")

        # Check 2: APIM endpoint reachable
        if 'APIM_GATEWAY_URL' in os.environ:
            import requests
            try:
                url = os.environ['APIM_GATEWAY_URL']
                response = requests.get(url, timeout=10)
                reachable = response.status_code < 500
                checks.append(('APIM Endpoint', reachable))
                print(f"  {'‚úÖ' if reachable else '‚ùå'} APIM endpoint: {url[:50]}...")
            except Exception as e:
                checks.append(('APIM Endpoint', False))
                print(f"  ‚ö†Ô∏è  APIM endpoint not reachable (may be expected): {e}")

        # Check 3: Environment file generated
        env_file = Path('master-lab.env')
        exists = env_file.exists()
        checks.append(('master-lab.env', exists))
        print(f"  {'‚úÖ' if exists else '‚ùå'} Environment file")

        return all(passed for _, passed in checks if passed is not None)

    def _attempt_recovery(self):
        """Attempt to recover from deployment failure"""
        print("\n[recovery] Attempting recovery...")

        # Try to get deployment error details
        if 'resource_client' in globals():
            try:
                rg_name = os.getenv('RESOURCE_GROUP')
                deployments = list(globals()['resource_client'].deployments.list_by_resource_group(rg_name))

                # Find failed deployments
                for deployment in deployments[:5]:  # Last 5 deployments
                    if deployment.properties.provisioning_state == 'Failed':
                        print(f"\n[recovery] Failed deployment: {deployment.name}")
                        print(f"  Error: {deployment.properties.error}")

            except Exception as e:
                print(f"[recovery] Could not retrieve deployment details: {e}")

# Create deployment tester
deployment_tester = DeploymentTester()
print("‚úÖ Deployment Tester initialized")
```

---

## SECTION 6: CONTINUOUS MONITORING & REPORTING

### Create Test Report Generator

```python
# Cell 0.9: Test Report Generator
"""
Generates comprehensive test report with all findings.
"""

class TestReportGenerator:
    def __init__(self, tester, deployment_tester=None):
        self.tester = tester
        self.deployment_tester = deployment_tester

    def generate_report(self, output_file: str = "test_report.md"):
        """Generate comprehensive markdown report"""

        report = f"""# Notebook Testing Report
Generated: {datetime.now().isoformat()}

## Executive Summary

**Total Cells Tested:** {len(self.tester.results)}
**Success Rate:** {sum(1 for r in self.tester.results.values() if 'SUCCESS' in r) / len(self.tester.results) * 100:.1f}%

### Results Breakdown

| Status | Count |
|--------|-------|
"""

        # Count results
        status_counts = {}
        for status in self.tester.results.values():
            status_counts[status] = status_counts.get(status, 0) + 1

        for status, count in sorted(status_counts.items()):
            report += f"| {status} | {count} |\n"

        report += """
## Cell-by-Cell Results

"""

        for cell_num, status in sorted(self.tester.results.items()):
            icon = "‚úÖ" if "SUCCESS" in status else "‚ùå"
            report += f"### Cell {cell_num} {icon}\n\n"
            report += f"**Status:** {status}\n\n"

            # Add output snippet
            if cell_num in self.tester.cell_outputs:
                stdout = self.tester.cell_outputs[cell_num]['stdout']
                if stdout:
                    report += f"**Output:**\n```\n{stdout[:200]}...\n```\n\n"

            # Add resolutions
            if cell_num in self.tester.resolution_attempts:
                resolutions = self.tester.resolution_attempts[cell_num]
                if resolutions:
                    report += "**Resolution Attempts:**\n"
                    for res in resolutions:
                        report += f"- {res}\n"
                    report += "\n"

        # Deployment results
        if self.deployment_tester:
            report += """
## Deployment Results

"""
            for step, status in self.deployment_tester.deployment_state.items():
                icon = "‚úÖ" if status == "SUCCESS" else "‚ùå" if status == "FAILED" else "‚ö†Ô∏è"
                report += f"- {icon} **{step}:** {status or 'Not executed'}\n"

        report += """
## Issues Found

### Missing Environment Variables
"""
        all_missing_vars = set()
        for cell_num, issues in self.tester.cell_outputs.items():
            # Extract from analysis
            pass  # TODO: Implement

        if all_missing_vars:
            for var in sorted(all_missing_vars):
                report += f"- `{var}`\n"
        else:
            report += "None\n"

        report += """
### Missing Files
"""
        # TODO: Add missing files

        report += """
## Recommendations

1. **Fix Critical Issues First:** Address all cells marked as FAILED
2. **Re-run Cells with Fixes:** Some cells may succeed after resolution
3. **Validate Environment:** Ensure all required environment variables are set
4. **Update File Paths:** Bicep files are in `archive/scripts`, update references

## Next Steps

- [ ] Fix all FAILED cells
- [ ] Re-run test sequence
- [ ] Proceed with deployment
- [ ] Verify post-deployment health
"""

        # Write report
        Path(output_file).write_text(report)
        print(f"‚úÖ Report generated: {output_file}")

        # Also display in notebook
        from IPython.display import display, Markdown
        display(Markdown(report[:2000] + "\n\n... (see full report in file)"))

# Usage
report_gen = TestReportGenerator(tester, deployment_tester)
print("‚úÖ Report Generator initialized")
```

---

## SECTION 7: EXECUTION SUMMARY

### Complete Testing Workflow

**Phase 1: Setup**
```python
# Run these cells in order:
# Cell 0.5 - Pre-Flight Check
# Cell 0.6 - Cell Tester
# Cell 0.7 - Test Sequence Executor
```

**Phase 2: Fix Issues**
```python
# After Cell 0.7 runs, review output
# Fix any FAILED cells
# Re-run test sequence
```

**Phase 3: Deployment Testing**
```python
# Run:
# Cell 0.8 - Deployment Tester
deployment_tester.test_deployment()
```

**Phase 4: Reporting**
```python
# Run:
# Cell 0.9 - Generate Report
report_gen.generate_report()
```

---

## APPENDIX: Quick Reference

### Key Functions

```python
# Test a single cell
tester.test_cell(cell_number, expected_variables=['var1', 'var2'])

# Run full test sequence
# (Run Cell 0.7)

# Test deployment
deployment_tester.test_deployment()

# Generate report
report_gen.generate_report()

# Resolve missing environment variable
resolved_value = resolve_env_var('VAR_NAME')

# Find missing file
file_path = resolve_missing_file('filename.bicep')

# Check if variable is defined
if 'var_name' in globals():
    print("Defined")
```

### Troubleshooting Commands

```python
# Show all environment variables
for k, v in os.environ.items():
    if not k.startswith('_'):
        print(f"{k} = {v[:50]}...")

# Show all defined variables
for k in sorted(globals().keys()):
    if not k.startswith('_'):
        print(k)

# Check cell execution history
for i, cell in enumerate(In[1:], 1):
    if cell:
        print(f"Cell {i}: {cell[:50]}...")

# Check outputs
for i, output in enumerate(Out.values()):
    print(f"Output {i}: {str(output)[:50]}...")
```

---

**END OF TESTING STRATEGY**

This testing strategy provides:
- ‚úÖ Real execution (no mocks)
- ‚úÖ Cell-by-cell validation
- ‚úÖ Output analysis for missing parameters/variables
- ‚úÖ Multi-method resolution attempts
- ‚úÖ Comprehensive reporting
- ‚úÖ Deployment phase testing
- ‚úÖ Automated recovery attempts
