#!/usr/bin/env python3
"""
Rebuild deployment cells in master-ai-gateway.ipynb
Uses Azure Python SDK for modular, debuggable deployments
"""

import json
import time

print('[*] Reading notebook...')
with open('master-ai-gateway.ipynb', 'r', encoding='utf-8') as f:
    nb = json.load(f)

print(f'[*] Current cells: {len(nb["cells"])}')

print('[*] Removing old deployment cells (10-14)...')
del nb['cells'][10:15]

print(f'[*] Cells after removal: {len(nb["cells"])}')

print('[*] Creating new deployment cells...')

new_cells = []

# Cell 1: Markdown - Configuration
new_cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "### Master Lab Configuration\n",
        "\n",
        "Set deployment configuration for all 4 deployment steps."
    ]
})

# Cell 2: Code - Configuration
new_cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "# Master Lab Configuration\n",
        "deployment_name_prefix = 'master-lab'\n",
        "resource_group_name = 'lab-master-lab'\n",
        "location = 'uksouth'\n",
        "\n",
        "# Deployment names for each step\n",
        "deployment_step1 = f'{deployment_name_prefix}-01-core'\n",
        "deployment_step2 = f'{deployment_name_prefix}-02-ai-foundry'\n",
        "deployment_step3 = f'{deployment_name_prefix}-03-supporting'\n",
        "deployment_step4 = f'{deployment_name_prefix}-04-mcp'\n",
        "\n",
        "print('[OK] Configuration set')\n",
        "print(f'  Resource Group: {resource_group_name}')\n",
        "print(f'  Location: {location}')\n",
        "print(f'  Deployment Prefix: {deployment_name_prefix}')\n"
    ]
})

# Cell 3: Markdown - Helper Functions
new_cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "### Deployment Helper Functions\n",
        "\n",
        "Azure SDK functions for deployment management."
    ]
})

# Cell 4: Code - Helper Functions
new_cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "import subprocess\n",
        "import json\n",
        "import time\n",
        "from azure.mgmt.resource import ResourceManagementClient\n",
        "from azure.identity import AzureCliCredential\n",
        "\n",
        "# Initialize Azure SDK\n",
        "print('[*] Initializing Azure SDK...')\n",
        "credential = AzureCliCredential()\n",
        "\n",
        "# Get subscription ID\n",
        "result = subprocess.run(['az', 'account', 'show', '--query', 'id', '-o', 'tsv'], \n",
        "                       capture_output=True, text=True)\n",
        "subscription_id = result.stdout.strip()\n",
        "print(f'[OK] Subscription ID: {subscription_id}')\n",
        "\n",
        "# Create Resource Management Client\n",
        "resource_client = ResourceManagementClient(credential, subscription_id)\n",
        "print('[OK] Azure SDK initialized')\n",
        "\n",
        "def compile_bicep(bicep_file):\n",
        "    \"\"\"Compile Bicep to JSON\"\"\"\n",
        "    print(f'[*] Compiling {bicep_file}...')\n",
        "    result = subprocess.run(['az', 'bicep', 'build', '--file', bicep_file],\n",
        "                          capture_output=True, text=True)\n",
        "    if result.returncode != 0:\n",
        "        print(f'[ERROR] Compilation failed: {result.stderr}')\n",
        "        return False\n",
        "    json_file = bicep_file.replace('.bicep', '.json')\n",
        "    print(f'[OK] Compiled to {json_file}')\n",
        "    return json_file\n",
        "\n",
        "def check_resource_group_exists(rg_name):\n",
        "    \"\"\"Check if resource group exists\"\"\"\n",
        "    try:\n",
        "        resource_client.resource_groups.get(rg_name)\n",
        "        return True\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "def check_deployment_exists(rg_name, deployment_name):\n",
        "    \"\"\"Check if deployment exists and succeeded\"\"\"\n",
        "    try:\n",
        "        deployment = resource_client.deployments.get(rg_name, deployment_name)\n",
        "        if deployment.properties.provisioning_state == 'Succeeded':\n",
        "            return True, deployment\n",
        "        else:\n",
        "            return False, deployment\n",
        "    except:\n",
        "        return False, None\n",
        "\n",
        "def deploy_template(rg_name, deployment_name, template_file, parameters_dict):\n",
        "    \"\"\"Deploy ARM template using Azure SDK\"\"\"\n",
        "    print(f'[*] Deploying {deployment_name}...')\n",
        "    \n",
        "    # Read template\n",
        "    with open(template_file, 'r') as f:\n",
        "        template = json.load(f)\n",
        "    \n",
        "    # Prepare deployment properties\n",
        "    deployment_properties = {\n",
        "        'mode': 'Incremental',\n",
        "        'template': template,\n",
        "        'parameters': parameters_dict\n",
        "    }\n",
        "    \n",
        "    # Start deployment\n",
        "    deployment_async = resource_client.deployments.begin_create_or_update(\n",
        "        rg_name,\n",
        "        deployment_name,\n",
        "        {'properties': deployment_properties}\n",
        "    )\n",
        "    \n",
        "    # Poll deployment status\n",
        "    print('[*] Deployment started. Polling status...')\n",
        "    start_time = time.time()\n",
        "    last_update = start_time\n",
        "    \n",
        "    while not deployment_async.done():\n",
        "        time.sleep(30)\n",
        "        elapsed = time.time() - start_time\n",
        "        if time.time() - last_update >= 60:\n",
        "            print(f'[*] Still deploying... {int(elapsed/60)}m {int(elapsed%60)}s elapsed')\n",
        "            last_update = time.time()\n",
        "    \n",
        "    # Get result\n",
        "    deployment_result = deployment_async.result()\n",
        "    elapsed = time.time() - start_time\n",
        "    \n",
        "    if deployment_result.properties.provisioning_state == 'Succeeded':\n",
        "        print(f'[OK] Deployment succeeded in {int(elapsed/60)}m {int(elapsed%60)}s')\n",
        "        return True, deployment_result\n",
        "    else:\n",
        "        print(f'[ERROR] Deployment failed: {deployment_result.properties.provisioning_state}')\n",
        "        return False, deployment_result\n",
        "\n",
        "def get_deployment_outputs(rg_name, deployment_name):\n",
        "    \"\"\"Get deployment outputs\"\"\"\n",
        "    deployment = resource_client.deployments.get(rg_name, deployment_name)\n",
        "    if deployment.properties.outputs:\n",
        "        return {k: v['value'] for k, v in deployment.properties.outputs.items()}\n",
        "    return {}\n",
        "\n",
        "print('[OK] Helper functions defined')\n"
    ]
})

# Cell 5: Markdown - Main Deployment
new_cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "### Main Deployment - All 4 Steps\n",
        "\n",
        "Deploys all infrastructure in sequence:\n",
        "1. Core (APIM, Log Analytics, App Insights) - ~10 min\n",
        "2. AI Foundry (3 hubs + 14 models) - ~15 min\n",
        "3. Supporting Services (Redis, Search, Cosmos, Content Safety) - ~10 min\n",
        "4. MCP Servers (Container Apps + 7 servers) - ~5 min\n",
        "\n",
        "**Total time: ~40 minutes**\n",
        "\n",
        "Each step checks if already deployed and skips if successful."
    ]
})

# Cell 6: Code - Main Deployment
new_cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "print('=' * 70)\n",
        "print('MASTER LAB DEPLOYMENT - 4 STEPS')\n",
        "print('=' * 70)\n",
        "print()\n",
        "\n",
        "total_start = time.time()\n",
        "\n",
        "# Ensure resource group exists\n",
        "print('[*] Step 0: Ensuring resource group exists...')\n",
        "if not check_resource_group_exists(resource_group_name):\n",
        "    print(f'[*] Creating resource group: {resource_group_name}')\n",
        "    resource_client.resource_groups.create_or_update(\n",
        "        resource_group_name,\n",
        "        {'location': location}\n",
        "    )\n",
        "    print('[OK] Resource group created')\n",
        "else:\n",
        "    print('[OK] Resource group already exists')\n",
        "print()\n",
        "\n",
        "# STEP 1: Core Infrastructure\n",
        "print('=' * 70)\n",
        "print('STEP 1: CORE INFRASTRUCTURE')\n",
        "print('=' * 70)\n",
        "print('[*] Resources: Log Analytics, App Insights, API Management')\n",
        "print('[*] Estimated time: ~10 minutes')\n",
        "print()\n",
        "\n",
        "exists, deployment = check_deployment_exists(resource_group_name, deployment_step1)\n",
        "if exists:\n",
        "    print('[OK] Step 1 already deployed. Skipping...')\n",
        "    step1_outputs = get_deployment_outputs(resource_group_name, deployment_step1)\n",
        "else:\n",
        "    print('[*] Step 1 not found. Deploying...')\n",
        "    json_file = compile_bicep('deploy-01-core.bicep')\n",
        "    if not json_file:\n",
        "        raise Exception('Bicep compilation failed for Step 1')\n",
        "    \n",
        "    with open('params-01-core.json', 'r') as f:\n",
        "        params_data = json.load(f)\n",
        "    params_dict = {k: {'value': v['value']} for k, v in params_data['parameters'].items()}\n",
        "    \n",
        "    success, result = deploy_template(resource_group_name, deployment_step1, json_file, params_dict)\n",
        "    if not success:\n",
        "        raise Exception('Step 1 deployment failed')\n",
        "    \n",
        "    step1_outputs = get_deployment_outputs(resource_group_name, deployment_step1)\n",
        "    print('[OK] Step 1 complete')\n",
        "\n",
        "print()\n",
        "print('[OK] Step 1 outputs retrieved:')\n",
        "print(f'  - APIM Gateway: {step1_outputs.get(\"apimGatewayUrl\", \"N/A\")}')\n",
        "print(f'  - Log Analytics: {step1_outputs.get(\"logAnalyticsWorkspaceId\", \"N/A\")[:50]}...')\n",
        "print()\n",
        "\n",
        "# STEP 2: AI Foundry\n",
        "print('=' * 70)\n",
        "print('STEP 2: AI FOUNDRY')\n",
        "print('=' * 70)\n",
        "print('[*] Resources: 3 Foundry hubs, 3 projects, 14 AI models')\n",
        "print('[*] Estimated time: ~15 minutes')\n",
        "print()\n",
        "\n",
        "exists, deployment = check_deployment_exists(resource_group_name, deployment_step2)\n",
        "if exists:\n",
        "    print('[OK] Step 2 already deployed. Skipping...')\n",
        "    step2_outputs = get_deployment_outputs(resource_group_name, deployment_step2)\n",
        "else:\n",
        "    print('[*] Step 2 not found. Deploying...')\n",
        "    json_file = compile_bicep('deploy-02-ai-foundry.bicep')\n",
        "    if not json_file:\n",
        "        raise Exception('Bicep compilation failed for Step 2')\n",
        "    \n",
        "    # Build parameters from Step 1 outputs\n",
        "    params_dict = {\n",
        "        'apimPrincipalId': {'value': step1_outputs['apimPrincipalId']},\n",
        "        'appInsightsId': {'value': step1_outputs['appInsightsId']},\n",
        "        'appInsightsInstrumentationKey': {'value': step1_outputs['appInsightsInstrumentationKey']},\n",
        "        'apimLoggerId': {'value': step1_outputs['apimLoggerId']},\n",
        "        'foundryProjectName': {'value': 'master-lab'},\n",
        "        'inferenceAPIPath': {'value': 'inference'},\n",
        "        'inferenceAPIType': {'value': 'AzureOpenAI'}\n",
        "    }\n",
        "    \n",
        "    success, result = deploy_template(resource_group_name, deployment_step2, json_file, params_dict)\n",
        "    if not success:\n",
        "        raise Exception('Step 2 deployment failed')\n",
        "    \n",
        "    step2_outputs = get_deployment_outputs(resource_group_name, deployment_step2)\n",
        "    print('[OK] Step 2 complete')\n",
        "\n",
        "print()\n",
        "print('[OK] Step 2 outputs retrieved:')\n",
        "print(f'  - Foundry Endpoint: {step2_outputs.get(\"foundryProjectEndpoint\", \"N/A\")}')\n",
        "print()\n",
        "\n",
        "# STEP 3: Supporting Services\n",
        "print('=' * 70)\n",
        "print('STEP 3: SUPPORTING SERVICES')\n",
        "print('=' * 70)\n",
        "print('[*] Resources: Redis, Search, Cosmos DB, Content Safety')\n",
        "print('[*] Estimated time: ~10 minutes')\n",
        "print()\n",
        "\n",
        "exists, deployment = check_deployment_exists(resource_group_name, deployment_step3)\n",
        "if exists:\n",
        "    print('[OK] Step 3 already deployed. Skipping...')\n",
        "    step3_outputs = get_deployment_outputs(resource_group_name, deployment_step3)\n",
        "else:\n",
        "    print('[*] Step 3 not found. Deploying...')\n",
        "    json_file = compile_bicep('deploy-03-supporting.bicep')\n",
        "    if not json_file:\n",
        "        raise Exception('Bicep compilation failed for Step 3')\n",
        "    \n",
        "    with open('params-03-supporting.json', 'r') as f:\n",
        "        params_data = json.load(f)\n",
        "    params_dict = {k: {'value': v['value']} for k, v in params_data['parameters'].items()}\n",
        "    \n",
        "    success, result = deploy_template(resource_group_name, deployment_step3, json_file, params_dict)\n",
        "    if not success:\n",
        "        raise Exception('Step 3 deployment failed')\n",
        "    \n",
        "    step3_outputs = get_deployment_outputs(resource_group_name, deployment_step3)\n",
        "    print('[OK] Step 3 complete')\n",
        "\n",
        "print()\n",
        "print('[OK] Step 3 outputs retrieved:')\n",
        "print(f'  - Redis Host: {step3_outputs.get(\"redisCacheHost\", \"N/A\")}')\n",
        "print(f'  - Search Endpoint: {step3_outputs.get(\"searchServiceEndpoint\", \"N/A\")}')\n",
        "print(f'  - Cosmos Endpoint: {step3_outputs.get(\"cosmosDbEndpoint\", \"N/A\")}')\n",
        "print()\n",
        "\n",
        "# STEP 4: MCP Servers\n",
        "print('=' * 70)\n",
        "print('STEP 4: MCP SERVERS')\n",
        "print('=' * 70)\n",
        "print('[*] Resources: Container Registry, Container Apps Environment, 7 MCP servers')\n",
        "print('[*] Estimated time: ~5 minutes')\n",
        "print()\n",
        "\n",
        "exists, deployment = check_deployment_exists(resource_group_name, deployment_step4)\n",
        "if exists:\n",
        "    print('[OK] Step 4 already deployed. Skipping...')\n",
        "    step4_outputs = get_deployment_outputs(resource_group_name, deployment_step4)\n",
        "else:\n",
        "    print('[*] Step 4 not found. Deploying...')\n",
        "    json_file = compile_bicep('deploy-04-mcp.bicep')\n",
        "    if not json_file:\n",
        "        raise Exception('Bicep compilation failed for Step 4')\n",
        "    \n",
        "    # Build parameters from Step 1 outputs\n",
        "    params_dict = {\n",
        "        'location': {'value': location},\n",
        "        'logAnalyticsCustomerId': {'value': step1_outputs['logAnalyticsCustomerId']},\n",
        "        'logAnalyticsPrimarySharedKey': {'value': step1_outputs['logAnalyticsPrimarySharedKey']}\n",
        "    }\n",
        "    \n",
        "    success, result = deploy_template(resource_group_name, deployment_step4, json_file, params_dict)\n",
        "    if not success:\n",
        "        raise Exception('Step 4 deployment failed')\n",
        "    \n",
        "    step4_outputs = get_deployment_outputs(resource_group_name, deployment_step4)\n",
        "    print('[OK] Step 4 complete')\n",
        "\n",
        "print()\n",
        "print('[OK] Step 4 outputs retrieved:')\n",
        "mcp_urls = step4_outputs.get('mcpServerUrls', [])\n",
        "print(f'  - MCP Servers deployed: {len(mcp_urls)}')\n",
        "for mcp in mcp_urls[:3]:\n",
        "    print(f'    - {mcp[\"name\"]}: {mcp[\"url\"][:50]}...')\n",
        "print()\n",
        "\n",
        "# Summary\n",
        "total_elapsed = time.time() - total_start\n",
        "print('=' * 70)\n",
        "print('DEPLOYMENT COMPLETE')\n",
        "print('=' * 70)\n",
        "print(f'[OK] Total time: {int(total_elapsed/60)}m {int(total_elapsed%60)}s')\n",
        "print('[OK] All 4 steps deployed successfully')\n",
        "print()\n",
        "print('[*] Next: Run the cell below to generate .env file')\n",
        "print('=' * 70)\n"
    ]
})

# Cell 7: Markdown - Generate .env
new_cells.append({
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "### Generate .env File\n",
        "\n",
        "Create `master-lab.env` with all deployment outputs for use in lab tests."
    ]
})

# Cell 8: Code - Generate .env
new_cells.append({
    "cell_type": "code",
    "execution_count": None,
    "metadata": {},
    "outputs": [],
    "source": [
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "print('[*] Generating master-lab.env...')\n",
        "\n",
        "# Get API key from APIM subscriptions\n",
        "apim_subscriptions = step1_outputs.get('apimSubscriptions', [])\n",
        "api_key = apim_subscriptions[0]['key'] if apim_subscriptions else 'N/A'\n",
        "\n",
        "# Build .env content with grouped structure\n",
        "env_content = f\"\"\"# Master AI Gateway Lab - Deployment Outputs\n",
        "# Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "# Resource Group: {resource_group_name}\n",
        "\n",
        "# ===========================================\n",
        "# APIM (API Management)\n",
        "# ===========================================\n",
        "APIM_GATEWAY_URL={step1_outputs.get('apimGatewayUrl', '')}\n",
        "APIM_SERVICE_ID={step1_outputs.get('apimServiceId', '')}\n",
        "APIM_SERVICE_NAME={step1_outputs.get('apimServiceName', '')}\n",
        "APIM_API_KEY={api_key}\n",
        "\n",
        "# ===========================================\n",
        "# AI Foundry\n",
        "# ===========================================\n",
        "FOUNDRY_PROJECT_ENDPOINT={step2_outputs.get('foundryProjectEndpoint', '')}\n",
        "INFERENCE_API_PATH={step2_outputs.get('inferenceAPIPath', 'inference')}\n",
        "\n",
        "# ===========================================\n",
        "# Supporting Services\n",
        "# ===========================================\n",
        "\n",
        "# Redis (Semantic Caching)\n",
        "REDIS_HOST={step3_outputs.get('redisCacheHost', '')}\n",
        "REDIS_PORT={step3_outputs.get('redisCachePort', 10000)}\n",
        "REDIS_KEY={step3_outputs.get('redisCacheKey', '')}\n",
        "\n",
        "# Azure Cognitive Search\n",
        "SEARCH_SERVICE_NAME={step3_outputs.get('searchServiceName', '')}\n",
        "SEARCH_ENDPOINT={step3_outputs.get('searchServiceEndpoint', '')}\n",
        "SEARCH_ADMIN_KEY={step3_outputs.get('searchServiceAdminKey', '')}\n",
        "\n",
        "# Cosmos DB\n",
        "COSMOS_ACCOUNT_NAME={step3_outputs.get('cosmosDbAccountName', '')}\n",
        "COSMOS_ENDPOINT={step3_outputs.get('cosmosDbEndpoint', '')}\n",
        "COSMOS_KEY={step3_outputs.get('cosmosDbKey', '')}\n",
        "\n",
        "# Content Safety\n",
        "CONTENT_SAFETY_ENDPOINT={step3_outputs.get('contentSafetyEndpoint', '')}\n",
        "CONTENT_SAFETY_KEY={step3_outputs.get('contentSafetyKey', '')}\n",
        "\n",
        "# ===========================================\n",
        "# MCP Servers\n",
        "# ===========================================\n",
        "CONTAINER_REGISTRY={step4_outputs.get('containerRegistryLoginServer', '')}\n",
        "CONTAINER_APP_ENV_ID={step4_outputs.get('containerAppEnvId', '')}\n",
        "\"\"\"\n",
        "\n",
        "# Add MCP server URLs\n",
        "mcp_urls = step4_outputs.get('mcpServerUrls', [])\n",
        "for mcp in mcp_urls:\n",
        "    var_name = f\"MCP_SERVER_{mcp['name'].upper().replace('-', '_')}_URL\"\n",
        "    env_content += f\"{var_name}={mcp['url']}\\n\"\n",
        "\n",
        "env_content += f\"\"\"\n",
        "# ===========================================\n",
        "# Deployment Info\n",
        "# ===========================================\n",
        "RESOURCE_GROUP={resource_group_name}\n",
        "LOCATION={location}\n",
        "DEPLOYMENT_PREFIX={deployment_name_prefix}\n",
        "\"\"\"\n",
        "\n",
        "# Write to file\n",
        "env_file = 'master-lab.env'\n",
        "with open(env_file, 'w') as f:\n",
        "    f.write(env_content)\n",
        "\n",
        "print(f'[OK] Created {env_file}')\n",
        "print(f'[OK] File location: {os.path.abspath(env_file)}')\n",
        "print()\n",
        "print('[OK] You can now load this in all lab tests:')\n",
        "print('  from dotenv import load_dotenv')\n",
        "print('  load_dotenv(\"master-lab.env\")')\n",
        "print()\n",
        "print('=' * 70)\n",
        "print('SETUP COMPLETE - ALL LABS READY')\n",
        "print('=' * 70)\n"
    ]
})

# Insert new cells at position 10
print(f'[*] Inserting {len(new_cells)} new cells at position 10...')
for i, cell in enumerate(new_cells):
    nb['cells'].insert(10 + i, cell)

print(f'[*] Total cells after insertion: {len(nb["cells"])}')

# Save notebook
print('[*] Saving notebook...')
with open('master-ai-gateway.ipynb', 'w', encoding='utf-8') as f:
    json.dump(nb, f, indent=1, ensure_ascii=False)

print('[OK] Notebook rebuilt successfully!')
print()
print('[OK] New structure:')
print('  Cell 10: Configuration')
print('  Cell 11: Configuration code')
print('  Cell 12: Helper Functions header')
print('  Cell 13: Helper Functions code')
print('  Cell 14: Main Deployment header')
print('  Cell 15: Main Deployment code (4 steps)')
print('  Cell 16: Generate .env header')
print('  Cell 17: Generate .env code')
print()
print('[OK] Ready to run!')
