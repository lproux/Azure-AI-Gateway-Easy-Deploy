# Comprehensive Fix Plan - Phase 2 Continuation

**Date**: 2025-11-17
**Status**: ðŸ”§ IN PROGRESS - Systematic Fixes
**Backup**: `master-ai-gateway-fix-MCP.ipynb.backup-phase2-comprehensive-*`

---

## Completed Tasks âœ…

1. **Cosmos DB RBAC** - Granted to service principal `c1a04baa-9221-4490-821b-5968bbf3772b`
2. **MCP Pattern Analysis** - Found working implementation in workshop notebooks
3. **Environment Analysis** - Identified missing model deployment fields in master-lab.env

---

## Fix Sequence

### PHASE A: Infrastructure & Environment (CRITICAL)

#### Fix 1: Cell 29 - Capture Model Deployment Outputs

**Problem**: Cell 29 deploys models but doesn't structure outputs for Cell 32

**Current Behavior**:
- Deploys 3 foundries (uksouth, eastus, norwayeast)
- Deploys 6 models in foundry1, 1 in foundry2, 1 in foundry3
- Stores results in `deployment_results` dict
- Doesn't capture foundry endpoints/keys for env file

**Required Output Structure**:
```python
step2_outputs = {
  'foundries': [
    {
      'name': 'foundry1-pavavy6pu5hpa',
      'location': 'uksouth',
      'endpoint': 'https://foundry1-pavavy6pu5hpa.openai.azure.com/',
      'key': '<foundry_key>',
      'models': ['gpt-4o-mini', 'gpt-4o', 'text-embedding-3-small',
                 'text-embedding-3-large', 'dall-e-3', 'gpt-4.1-nano']
    },
    {
      'name': 'foundry2-pavavy6pu5hpa',
      'location': 'eastus',
      'endpoint': 'https://foundry2-pavavy6pu5hpa.openai.azure.com/',
      'key': '<foundry_key>',
      'models': ['gpt-4o-mini']
    },
    {
      'name': 'foundry3-pavavy6pu5hpa',
      'location': 'norwayeast',
      'endpoint': 'https://foundry3-pavavy6pu5hpa.openai.azure.com/',
      'key': '<foundry_key>',
      'models': ['gpt-4o-mini']
    }
  ],
  'foundryProjectEndpoint': '',
  'inferenceAPIPath': 'inference'
}
```

**Fix Implementation**:
Add after Phase 2b model deployment (around line 200):

```python
# Collect foundry outputs for env file generation
print('[*] Collecting foundry deployment outputs...')
step2_outputs = {
    'foundryProjectEndpoint': '',
    'inferenceAPIPath': 'inference',
    'foundries': []
}

for foundry in foundries:
    foundry_name = foundry['name']
    try:
        # Get account details
        account = cog_client.accounts.get(resource_group_name, foundry_name)

        # Get primary key
        keys = cog_client.accounts.list_keys(resource_group_name, foundry_name)
        primary_key = keys.key1

        # Build endpoint
        endpoint = f"https://{foundry_name}.openai.azure.com/"

        # Get deployed model names
        short_name = foundry_name.split('-')[0]
        model_names = [m['name'] for m in models_config.get(short_name, [])]

        foundry_output = {
            'name': foundry_name,
            'location': foundry['location'],
            'endpoint': endpoint,
            'key': primary_key,
            'models': model_names
        }

        step2_outputs['foundries'].append(foundry_output)
        print(f'  [OK] Captured {foundry_name}: {len(model_names)} models')

    except Exception as e:
        print(f'  [WARN] Could not capture {foundry_name} outputs: {str(e)[:80]}')

print(f'[OK] Captured {len(step2_outputs["foundries"])} foundry outputs')
```

**Location**: After line ~200 (after model deployment loop)

---

#### Fix 2: Cell 14 - Update Environment Template

**Problem**: Template missing model deployment fields

**Current Template**: Has placeholders for DALL_E, FLUX, VISION only

**Required Template**: All models from Cell 29

**Fix Implementation**:

Update `_DEFAULT_ENV_TEMPLATE` to include:

```python
_DEFAULT_ENV_TEMPLATE = """# master-lab.env - autogenerated template
# Core Azure API Management / Resource settings
APIM_GATEWAY_URL=
APIM_API_KEY=
RESOURCE_GROUP=
LOCATION=
INFERENCE_API_PATH=inference

# ===========================================
# AI Model Deployments
# ===========================================

# GPT-4o-mini (Multi-region load balanced)
MODEL_GPT_4O_MINI_ENDPOINT_R1=
MODEL_GPT_4O_MINI_KEY_R1=
MODEL_GPT_4O_MINI_ENDPOINT_R2=
MODEL_GPT_4O_MINI_KEY_R2=
MODEL_GPT_4O_MINI_ENDPOINT_R3=
MODEL_GPT_4O_MINI_KEY_R3=

# GPT-4o (UK South only)
MODEL_GPT_4O_ENDPOINT_R1=
MODEL_GPT_4O_KEY_R1=

# Text Embeddings (UK South only)
MODEL_TEXT_EMBEDDING_3_SMALL_ENDPOINT_R1=
MODEL_TEXT_EMBEDDING_3_SMALL_KEY_R1=
MODEL_TEXT_EMBEDDING_3_LARGE_ENDPOINT_R1=
MODEL_TEXT_EMBEDDING_3_LARGE_KEY_R1=

# DALL-E 3 (UK South only)
MODEL_DALL_E_3_ENDPOINT_R1=
MODEL_DALL_E_3_KEY_R1=

# GPT-4.1 Nano (UK South only)
MODEL_GPT_4_1_NANO_ENDPOINT_R1=
MODEL_GPT_4_1_NANO_KEY_R1=

# Load Balancing Configuration
LB_REGIONS=uksouth,eastus,norwayeast
LB_GPT4O_MINI_ENDPOINTS=
LB_ENABLED=true

# ===========================================
# Supporting Services
# ===========================================

# Redis (Semantic Caching)
REDIS_HOST=
REDIS_PORT=
REDIS_KEY=

# Azure Cognitive Search
SEARCH_SERVICE_NAME=
SEARCH_ENDPOINT=
SEARCH_ADMIN_KEY=

# Cosmos DB
COSMOS_ACCOUNT_NAME=
COSMOS_ENDPOINT=
COSMOS_KEY=

# Content Safety
CONTENT_SAFETY_ENDPOINT=
CONTENT_SAFETY_KEY=
""".strip() + "\n"
```

**Location**: Cell 14, around line 20-60

---

#### Fix 3: Verify Cell 32

**Status**: Cell 32 already looks correct - it extracts from `step2_outputs['foundries']`

**Action**: Verify it works once Cell 29 fix is applied

---

### PHASE B: MCP Integration

#### Fix 4: Apply MCP Pattern to Cells 81, 83, 86, 132

**Working Pattern** (from workshop):
```python
# 1. Upload Excel file via MCP
upload_result = mcp.excel.upload_excel(str(local_excel_path))
file_cache_key = upload_result.get('file_name', excel_file_name)

# 2. Analyze with dynamic columns
analysis_result = mcp.excel.analyze_sales(
    file_cache_key,
    group_by='Region',
    metric='TotalAmount'
)
```

**Cells to Fix**:
- **Cell 81**: Sales analysis - Use MCP instead of pandas
- **Cell 83**: Same pattern as 81
- **Cell 86**: Same pattern as 81
- **Cell 132**: Dynamic MCP analysis

**Prerequisites**:
1. Check if `notebook_mcp_helpers` module exists
2. Verify `.mcp-servers-config` file exists
3. Ensure `MCPClient` is initialized (may need Cell 6 from workshop)

**Implementation Plan**:
1. Add MCP client initialization before Cell 81
2. Replace pandas logic with MCP calls
3. Keep pandas as fallback if MCP fails

---

### PHASE C: Other Fixes

#### Fix 5: Cell 101 - Caching Verification

**Problem**: Using timing heuristic (`cached: elapsed < 0.5`) instead of response headers

**Current Code**:
```python
print(f'Request {i+1}: {elapsed:.2f}s (cached: {elapsed < 0.5})')
```

**Fix**:
```python
# Check for cache headers in response
cached = False
if hasattr(response, 'response_headers'):
    cache_status = response.response_headers.get('x-cache', '')
    cached = 'hit' in cache_status.lower()
elif elapsed < 0.5:
    cached = True  # Fallback to timing heuristic

print(f'Request {i+1}: {elapsed:.2f}s (cached: {cached})')
```

---

#### Fix 6: Cell 116 - Create Real A2A Agents

**Problem**: Using simulated agents

**Current**:
```python
print("[ERROR] Missing agents: ['planner', 'critic', 'summarizer']")
# Uses simulated coordination
```

**Fix**: Create actual AutoGen agents

```python
from autogen import ConversableAgent, UserProxyAgent

# Create planning agent
planner_agent = ConversableAgent(
    name="Planner",
    system_message=(
        "You are a strategic planner. Analyze requirements and create "
        "comprehensive deployment plans with security considerations."
    ),
    llm_config={"config_list": config_list, "temperature": 0.7},
)

# Create critic agent
critic_agent = ConversableAgent(
    name="Critic",
    system_message=(
        "You are a security and reliability critic. Review plans for "
        "risks, vulnerabilities, and potential failures."
    ),
    llm_config={"config_list": config_list, "temperature": 0.5},
)

# Create summarizer agent
summarizer_agent = ConversableAgent(
    name="Summarizer",
    system_message=(
        "You are a technical writer. Create concise summaries of "
        "discussions and action items."
    ),
    llm_config={"config_list": config_list, "temperature": 0.3},
)

# User proxy to coordinate
user_proxy = UserProxyAgent(
    name="Coordinator",
    human_input_mode="NEVER",
    max_consecutive_auto_reply=10,
    code_execution_config=False,
)

print("[OK] Created A2A agents: planner, critic, summarizer")

# Run A2A workflow
result = user_proxy.initiate_chat(
    planner_agent,
    message="Create a deployment plan for secure scaling of the AI Gateway",
)

# Get critic feedback
critic_result = user_proxy.initiate_chat(
    critic_agent,
    message=f"Review this plan and identify risks:\n\n{result}",
)

# Generate summary
summary = user_proxy.initiate_chat(
    summarizer_agent,
    message=f"Summarize the plan and critique:\n\nPlan:\n{result}\n\nCritique:\n{critic_result}",
)
```

---

#### Fix 7: Consolidate Image Generation Cells

**Cells to Merge**: 106, 108, 129, 130

**Problem**: Scattered image generation logic, missing subscription keys

**Consolidated Cell** (replace Cell 108):

```python
print("=" * 80)
print("IMAGE GENERATION - Consolidated")
print("=" * 80)

import os
import httpx

# Configuration
apim_gateway_url = os.getenv('APIM_GATEWAY_URL', '')
apim_api_key = os.getenv('APIM_API_KEY', '')
image_model = os.getenv('IMAGE_MODEL', 'gpt-image-1')

# Build endpoint
endpoint = f"{apim_gateway_url.rstrip('/')}/inference/openai/images/generations?api-version=2025-06-01-preview"

# Headers with subscription key
headers = {
    'Content-Type': 'application/json',
    'Ocp-Apim-Subscription-Key': apim_api_key,  # FIX: Add subscription key
}

# Test generation
payload = {
    'model': image_model,
    'prompt': 'A futuristic AI gateway architecture diagram',
    'size': '1024x1024',
    'n': 1
}

try:
    response = httpx.post(endpoint, json=payload, headers=headers, timeout=60)

    if response.status_code == 200:
        result = response.json()
        image_url = result.get('data', [{}])[0].get('url', '')
        print(f"âœ… Image generated successfully")
        print(f"URL: {image_url[:100]}...")
    else:
        print(f"âŒ Error {response.status_code}: {response.text[:200]}")

except Exception as e:
    print(f"âŒ Exception: {str(e)}")

print("\n[OK] Image generation test complete")
```

**Action**: Delete cells 106, 129, 130 after consolidation

---

#### Fix 8: Cell 145 - Real Vector Search Implementation

**Problem**: Using simulated embeddings and responses

**Current**:
```python
print("âš  No embedding deployment found. Using simulated embeddings.")
print("âš  No valid chat deployment found. Will use simulated responses.")
```

**Fix**: Use real Azure Search + embeddings from env

```python
print("=" * 80)
print("SEMANTIC KERNEL: Vector Search with Real Azure Search")
print("=" * 80)

import os
from semantic_kernel import Kernel
from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, AzureTextEmbedding
from openai import AsyncAzureOpenAI

# Load from environment
search_endpoint = os.getenv('SEARCH_ENDPOINT', '')
search_key = os.getenv('SEARCH_ADMIN_KEY', '')
embedding_endpoint = os.getenv('MODEL_TEXT_EMBEDDING_3_SMALL_ENDPOINT_R1', '')
embedding_key = os.getenv('MODEL_TEXT_EMBEDDING_3_SMALL_KEY_R1', '')
chat_endpoint = os.getenv('MODEL_GPT_4O_MINI_ENDPOINT_R1', '')
chat_key = os.getenv('MODEL_GPT_4O_MINI_KEY_R1', '')

if not all([search_endpoint, embedding_endpoint, chat_endpoint]):
    print("âŒ Missing required environment variables")
    print(f"  SEARCH_ENDPOINT: {'âœ“' if search_endpoint else 'âœ—'}")
    print(f"  Embedding endpoint: {'âœ“' if embedding_endpoint else 'âœ—'}")
    print(f"  Chat endpoint: {'âœ“' if chat_endpoint else 'âœ—'}")
else:
    # Create kernel with real services
    kernel = Kernel()

    # Add embedding service
    embedding_client = AsyncAzureOpenAI(
        azure_endpoint=embedding_endpoint,
        api_key=embedding_key,
        api_version="2024-02-01"
    )

    embedding_service = AzureTextEmbedding(
        service_id="embedding_service",
        deployment_name="text-embedding-3-small",
        async_client=embedding_client
    )
    kernel.add_service(embedding_service)

    # Add chat service
    chat_client = AsyncAzureOpenAI(
        azure_endpoint=chat_endpoint,
        api_key=chat_key,
        api_version="2024-02-01"
    )

    chat_service = AzureChatCompletion(
        service_id="chat_service",
        deployment_name="gpt-4o-mini",
        async_client=chat_client
    )
    kernel.add_service(chat_service)

    print("âœ“ Real embedding service configured")
    print("âœ“ Real chat service configured")

    # Create embeddings for sample data
    knowledge_base = [
        "Azure API Management (APIM) is a fully managed service...",
        "Semantic Kernel is an SDK that composes AI services...",
        "Function calling enables LLMs to invoke external tools...",
        "Vector search uses embeddings for semantic similarity..."
    ]

    # TODO: Use Azure AI Search for vector storage
    # For now, use in-memory vector store
    print("âš ï¸  Using in-memory vector store (production should use Azure AI Search)")

    print("\n[OK] Real vector search configured")
```

---

## Execution Order

1. âœ… Cosmos DB RBAC (DONE)
2. ðŸ”§ Fix Cell 29 - Capture deployment outputs
3. ðŸ”§ Fix Cell 14 - Update env template
4. ðŸ”§ Run Cell 32 - Generate master-lab.env with models
5. ðŸ”§ Fix Cells 81, 83, 86, 132 - Apply MCP pattern
6. ðŸ”§ Fix Cell 101 - Caching headers
7. ðŸ”§ Fix Cell 116 - Real A2A agents
8. ðŸ”§ Consolidate image cells (106, 108, 129, 130)
9. ðŸ”§ Fix Cell 145 - Real vector search
10. âœ… Test all fixes
11. âœ… Commit changes

---

## Testing Strategy

After each fix:
1. Read cell to verify change applied
2. Document what was changed
3. Move to next fix

After all fixes:
1. Full notebook execution test
2. Verify master-lab.env has all model fields
3. Check critical cells (81, 101, 116, 145, 147)

---

## Rollback Plan

If issues occur:
- Restore from `master-ai-gateway-fix-MCP.ipynb.backup-phase2-comprehensive-*`
- Review specific cell changes
- Apply fixes incrementally

---

**Status**: Ready to execute fixes
**Next**: Start with Fix 1 (Cell 29)
