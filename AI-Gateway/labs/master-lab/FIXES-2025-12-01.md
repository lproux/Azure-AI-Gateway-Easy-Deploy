# Master Lab Fixes - December 1, 2025

This document details all issues encountered during notebook execution and their solutions.

---

## Table of Contents

1. [JWT Authentication 404 Error (Cell 37)](#1-jwt-authentication-404-error-cell-37)
2. [Semantic Caching 500 Errors (Cells 51-54)](#2-semantic-caching-500-errors-cells-51-54)
3. [Cosmos DB Forbidden Error (Cell 61)](#3-cosmos-db-forbidden-error-cell-61)
4. [Cosmos DB Missing Database/Container (Cell 63)](#4-cosmos-db-missing-databasecontainer-cell-63)
5. [Weather MCP Empty Response (Cells 117, 128)](#5-weather-mcp-empty-response-cells-117-128)

---

## 1. JWT Authentication 404 Error (Cell 37)

### Symptom
```
Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}
```

### Root Cause
The `INFERENCE_API_PATH` environment variable was set to `inference/openai`, but the Azure OpenAI SDK automatically appends `/openai` to the base URL. This resulted in a double path: `/inference/openai/openai/deployments/...`

### How to Identify
- Check the `INFERENCE_API_PATH` value in `master-lab.env`
- If it contains `/openai`, the SDK will create a malformed URL

### Solution
Changed Cell 25 to output `INFERENCE_API_PATH=inference` (without `/openai` suffix).

### Files Modified
- `master-ai-gateway-deploy-from-notebook.ipynb` (Cell 25)
- `master-lab.env` (if manually created)

### Code Change (Cell 25)
```python
# Before
env_content += f"INFERENCE_API_PATH=inference/openai\n"

# After
env_content += f"INFERENCE_API_PATH=inference\n"
```

### Verification
```bash
grep INFERENCE_API_PATH master-lab.env
# Should output: INFERENCE_API_PATH=inference
```

---

## 2. Semantic Caching 500 Errors (Cells 51-54)

### Symptom
First request succeeds, subsequent requests fail with HTTP 500 error.

### Root Cause
Three missing components:
1. **Missing `set-backend-service`** in the semantic caching policy - after cache lookup, requests weren't routed to any backend
2. **Missing APIM External Cache** - Redis wasn't connected to APIM for caching
3. **Missing `embeddings-backend`** - required for semantic similarity calculations

### How to Identify
- First request works (cache miss goes to default backend)
- Second request fails (cache lookup fails, no backend configured)
- Check APIM for external cache configuration
- Check for `embeddings-backend` named value

### Solution

#### Part A: Update Semantic Caching Policy (Cell 51)
Added backend routing and retry logic to the policy:

```xml
<policies>
    <inbound>
        <base />
        <!-- Semantic Cache Lookup -->
        <azure-openai-semantic-cache-lookup
            score-threshold="0.8"
            embeddings-backend-id="embeddings-backend"
            embeddings-backend-auth="system-assigned" />
        <!-- Route to backend pool (CRITICAL - was missing) -->
        <set-backend-service backend-id="inference-backend-pool" />
    </inbound>
    <backend>
        <!-- Retry on throttling (from load balancing policy) -->
        <retry count="2" interval="0" first-fast-retry="true"
               condition="@(context.Response.StatusCode == 429 ||
                          (context.Response.StatusCode == 503 &amp;&amp;
                           !context.Response.StatusReason.Contains(&quot;Backend pool&quot;)))">
            <forward-request buffer-request-body="true" />
        </retry>
    </backend>
    <outbound>
        <azure-openai-semantic-cache-store duration="120" />
        <base />
    </outbound>
    <on-error>
        <base />
    </on-error>
</policies>
```

#### Part B: Add APIM Prerequisites (New Step 3b in Cell 21)
Added code to create:
1. APIM External Cache (Redis connection)
2. Embeddings backend for semantic similarity

```python
# Step 3b: Configure APIM for Semantic Caching
print("Step 3b: Configuring APIM for Semantic Caching...")

# Create external cache
cache_cmd = f'''
az apim cache create \
    --resource-group {resource_group} \
    --service-name {apim_name} \
    --name "semantic-cache" \
    --connection-string "redis://{redis_host}:{redis_port},password={redis_key},ssl=True,abortConnect=False" \
    --description "Redis cache for semantic caching" \
    --use-from-location "default"
'''

# Create embeddings backend
backend_cmd = f'''
az apim backend create \
    --resource-group {resource_group} \
    --service-name {apim_name} \
    --backend-id "embeddings-backend" \
    --protocol "http" \
    --url "{embeddings_endpoint}" \
    --description "Embeddings backend for semantic caching"
'''
```

### Files Modified
- `master-ai-gateway-deploy-from-notebook.ipynb` (Cells 21, 51)
- `policies/semantic-caching-policy.xml`

### Verification
```bash
# Check APIM has external cache
az apim cache list --resource-group $RG --service-name $APIM_NAME

# Check embeddings backend exists
az apim backend show --resource-group $RG --service-name $APIM_NAME --backend-id embeddings-backend
```

---

## 3. Cosmos DB Forbidden Error (Cell 61)

### Symptom
```
Error: Forbidden - Request originated from IP through public internet
```

### Root Cause
Cosmos DB was deployed with `publicNetworkAccess: Disabled`, blocking all public network requests including from Codespaces.

### How to Identify
```bash
az cosmosdb show --name $COSMOS_NAME --resource-group $RG --query "publicNetworkAccess"
# Returns: "Disabled"
```

### Solution
Enable public network access:
```bash
az cosmosdb update \
    --name $COSMOS_NAME \
    --resource-group $RG \
    --public-network-access Enabled
```

### Files Modified
None (runtime fix). Consider updating Bicep template to set `publicNetworkAccess: Enabled` by default.

### Verification
```bash
az cosmosdb show --name $COSMOS_NAME --resource-group $RG --query "publicNetworkAccess"
# Should return: "Enabled"
```

---

## 4. Cosmos DB Missing Database/Container (Cell 63)

### Symptom
```
Error: Owner resource does not exist
```

### Root Cause
The Cosmos DB account was created but the database (`messages-db`) and container (`conversations`) were not created.

### How to Identify
```bash
az cosmosdb sql database list --account-name $COSMOS_NAME --resource-group $RG
# Returns empty list or missing database
```

### Solution
Create the database and container:
```bash
# Create database
az cosmosdb sql database create \
    --account-name $COSMOS_NAME \
    --resource-group $RG \
    --name messages-db

# Create container with partition key
az cosmosdb sql container create \
    --account-name $COSMOS_NAME \
    --resource-group $RG \
    --database-name messages-db \
    --name conversations \
    --partition-key-path "/session_id"
```

### Files Modified
None (runtime fix). Consider adding database/container creation to deployment notebook.

### Verification
```bash
az cosmosdb sql container show \
    --account-name $COSMOS_NAME \
    --resource-group $RG \
    --database-name messages-db \
    --name conversations
```

---

## 5. Weather MCP Empty Response (Cells 117, 128)

### Symptom
```
JSONDecodeError: Expecting value: line 1 column 1 (char 0)
```
Weather API calls returned empty responses.

### Root Cause (Multiple Issues)

#### Issue A: Weather Server Response Format
The weather MCP server was returning a simplified response format, but the notebook helper expected raw OpenWeatherMap format.

#### Issue B: Parameter Style Mismatch
The helper used `q` parameter (OpenWeatherMap style: `q=London,GB`) but the original MCP server only accepted `city`/`country` parameters.

#### Issue C: Stale Configuration File
The `.mcp-servers-config` file contained URLs from a previous deployment that no longer existed:
- Old URL: `https://mcp-weather-pavavy6pu5.niceriver-900455a0.uksouth.azurecontainerapps.io`
- New URL: `https://mcp-weather-c7uj6vzppa.wonderfulsea-f914b9a8.uksouth.azurecontainerapps.io`

#### Issue D: Missing WeatherMCPClient Class
The `notebook_mcp_helpers.py` referenced `WeatherMCPClient` class for direct MCP access, but the class wasn't defined.

### How to Identify
```bash
# Test if weather server is responding
curl "https://mcp-weather-xxx/health"
# Should return: {"status":"healthy","service":"weather-mcp","api_key_configured":true}

# Test weather endpoint
curl "https://mcp-weather-xxx/weather?q=London,GB"
# Should return weather JSON data
```

### Solution

#### Fix A: Update Weather Server (weather_server.py)
Added `raw=True` parameter to return raw OpenWeatherMap format by default:

```python
@app.get("/weather")
async def get_weather(
    city: str = None,
    country: str = None,
    q: str = None,           # Added for OpenWeatherMap compatibility
    appid: str = None,       # Ignored - API key is server-side
    units: str = "metric",
    raw: bool = True         # Return raw format by default
):
    # Support both parameter styles
    if q:
        query = q
    elif city:
        query = f"{city},{country}" if country else city
    else:
        raise HTTPException(status_code=400, detail="Either 'city' or 'q' parameter is required")
```

#### Fix B: Add WeatherMCPClient Class (notebook_mcp_helpers.py)
Added new class for direct MCP server access (without APIM passthrough):

```python
class WeatherMCPClient:
    """Direct Weather MCP Server client (no APIM passthrough)"""

    def __init__(self, base_url: str):
        self.base_url = base_url.rstrip('/')
        self.headers = {'User-Agent': 'Notebook-MCP-Helper'}

    def _get(self, endpoint: str, params: Dict[str, Any] = None) -> Dict[str, Any]:
        url = f"{self.base_url}/{endpoint.lstrip('/')}"
        response = httpx.get(url, headers=self.headers, params=params, timeout=30.0)
        response.raise_for_status()
        return response.json()

    def get_weather(self, city: str, country_code: Optional[str] = None, units: str = "metric"):
        query = f"{city},{country_code}" if country_code else city
        return self._get('weather', {'q': query, 'units': units})

    def get_forecast(self, city: str, country_code: Optional[str] = None, units: str = "metric", cnt: int = 40):
        query = f"{city},{country_code}" if country_code else city
        return self._get('forecast', {'q': query, 'units': units, 'cnt': min(cnt, 40)})
```

#### Fix C: Update MCPClient Initialization
Modified to check for `MCP_SERVER_WEATHER_URL` and use `WeatherMCPClient`:

```python
# Weather through APIM (REST API) or direct MCP server
apim_weather_url = self.config.get("APIM_WEATHER_URL", "")
weather_api_key = self.config.get("OPENWEATHER_API_KEY", "") or self.config.get("OWM_API_KEY", "")
mcp_weather_url = self.config.get("MCP_SERVER_WEATHER_URL", "")

if apim_weather_url and apim_key and weather_api_key:
    # APIM passthrough mode
    self.weather = WeatherAPIClient(apim_weather_url, apim_key, weather_api_key)
elif mcp_weather_url:
    # Direct MCP server mode (API key configured server-side)
    self.weather = WeatherMCPClient(mcp_weather_url)
else:
    self.weather = None
```

#### Fix D: Update .mcp-servers-config
Updated configuration file with current deployment URLs:

```ini
# Before (stale)
APIM_WEATHER_URL=https://mcp-weather-pavavy6pu5.niceriver-900455a0.uksouth.azurecontainerapps.io

# After (current)
MCP_SERVER_WEATHER_URL=https://mcp-weather-c7uj6vzppa.wonderfulsea-f914b9a8.uksouth.azurecontainerapps.io
```

### Files Modified
- `mcp-http-wrappers/weather-mcp/weather_server.py`
- `notebook_mcp_helpers.py`
- `.mcp-servers-config`

### Rebuild/Redeploy Required
After modifying `weather_server.py`, rebuild and redeploy the container:

```bash
# Build with new tag
docker build -t $ACR/mcp-weather:v2 ./mcp-http-wrappers/weather-mcp/

# Push to registry
docker push $ACR/mcp-weather:v2

# Update container app
az containerapp update \
    --name mcp-weather-xxx \
    --resource-group $RG \
    --image $ACR/mcp-weather:v2
```

### Verification
```python
from notebook_mcp_helpers import MCPClient

mcp = MCPClient()
print(type(mcp.weather).__name__)  # Should be: WeatherMCPClient

weather = mcp.weather.get_weather("London", "GB")
print(weather.get("name"))  # Should be: London
print(weather.get("main", {}).get("temp"))  # Should be temperature
```

---

## Quick Reference: Environment Variables

| Variable | Purpose | Example |
|----------|---------|---------|
| `INFERENCE_API_PATH` | APIM path for OpenAI (no /openai suffix) | `inference` |
| `MCP_SERVER_WEATHER_URL` | Direct weather MCP server | `https://mcp-weather-xxx.azurecontainerapps.io` |
| `APIM_WEATHER_URL` | Weather via APIM (requires API key) | `https://apim-xxx/weather` |
| `OPENWEATHER_API_KEY` | OpenWeather API key (for APIM mode) | `abc123...` |

---

## Deployment Checklist

Before running the notebook, verify:

- [ ] `INFERENCE_API_PATH` does NOT contain `/openai`
- [ ] Cosmos DB has `publicNetworkAccess: Enabled`
- [ ] Cosmos DB has `messages-db` database and `conversations` container
- [ ] APIM has external cache configured (for semantic caching)
- [ ] APIM has `embeddings-backend` configured
- [ ] `.mcp-servers-config` has current deployment URLs
- [ ] Weather MCP container is running and healthy

---

## Contact

For issues with this lab, check:
1. This document for known fixes
2. Container app logs: `az containerapp logs show --name xxx --resource-group $RG`
3. APIM diagnostics in Azure Portal

Last Updated: 2025-12-01
