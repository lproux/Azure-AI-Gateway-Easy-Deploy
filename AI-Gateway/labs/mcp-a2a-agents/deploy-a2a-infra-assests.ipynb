{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIM ‚ù§Ô∏è AI Agents\n",
    "\n",
    "## Multi-agent architecture using Agent-2-Agent connumication protocols (MCP and A2A)\n",
    "![flow](../../images/mcp-agent-2-agent.gif)\n",
    "![flow](../../images/a2a-agent-2-agent.gif)\n",
    "\n",
    "Playground to experiment with [Agent 2 Agent Communication over MCP](https://devblogs.microsoft.com/blog/can-you-build-agent2agent-communication-on-mcp-yes) and [A2A-enabled](https://www.microsoft.com/en-us/microsoft-cloud/blog/2025/05/07/empowering-multi-agent-apps-with-the-open-agent2agent-a2a-protocol/?msockid=3fc737ab34566ad7248a2255359d6b2c) agents with [MCP Tools](https://modelcontextprotocol.io/) with Azure API Management to enable plug & play of tools to LLMs. Leverages the [credential manager](https://learn.microsoft.com/en-us/azure/api-management/credentials-overview) for  managing OAuth 2.0 tokens to backend tools and [client token validation](https://learn.microsoft.com/en-us/azure/api-management/validate-jwt-policy) to ensure end-to-end authentication and authorization.   \n",
    "\n",
    "This lab includes the following MCP Tools servers:\n",
    "- Basic oncall service: provides a tool to get a list of random people currently on-call with their status and time zone.\n",
    "- Basic weather service: provide tools to get cities for a given country and retrieve random weather information for a specified city.\n",
    "\n",
    "MCP-enabled agents are then deployed within ACA (Azure Container Apps) as both MCP servers and A2A agents, one built with Semantic Kernel, and another with Autogen.\n",
    "\n",
    "This lab demonstrates the art of the possible of creating hetrogenous multi-agentic system with agents created using multiple orchestrators, and then allowing a single unifying protocol to communicate accross the through APIM for Authn/Authz\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- [Python 3.13 or later](https://www.python.org/) installed\n",
    "- [VS Code](https://code.visualstudio.com/) installed with the [Jupyter notebook extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) enabled\n",
    "- [Python environment](https://code.visualstudio.com/docs/python/environments#_creating-environments) with the [requirements.txt](../../requirements.txt) or run `pip install -r requirements.txt` in your terminal\n",
    "- [An Azure Subscription](https://azure.microsoft.com/free/) with [Contributor](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#contributor) + [RBAC Administrator](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#role-based-access-control-administrator) or [Owner](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#owner) roles\n",
    "- [Azure CLI](https://learn.microsoft.com/cli/azure/install-azure-cli) installed and [Signed into your Azure subscription](https://learn.microsoft.com/cli/azure/authenticate-azure-cli-interactively)\n",
    "\n",
    "‚ñ∂Ô∏è Click `Run All` to execute all steps sequentially, or execute them `Step by Step`...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "### 0Ô∏è‚É£ Initialize notebook variables\n",
    "\n",
    "- Resources will be suffixed by a unique string based on your subscription id.\n",
    "- Adjust the location parameters according your preferences and on the [product availability by Azure region.](https://azure.microsoft.com/explore/global-infrastructure/products-by-region/?cdn=disable&products=cognitive-services,api-management) \n",
    "- Adjust the OpenAI model and version according the [availability by region.](https://learn.microsoft.com/azure/ai-services/openai/concepts/models) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ \u001b[1;32mNotebook initialized\u001b[0m ‚åö 10:09:03.737960 \n"
     ]
    }
   ],
   "source": [
    "import os, sys, json\n",
    "sys.path.insert(1, '../../shared')  # add the shared directory to the Python path\n",
    "import utils\n",
    "\n",
    "deployment_name = os.path.basename(os.path.dirname(globals()['__vsc_ipynb_file__']))\n",
    "resource_group_name = f\"lab-{deployment_name}\" # change the name to match your naming style\n",
    "resource_group_location = \"westeurope\"\n",
    "\n",
    "apim_sku = 'Basicv2'\n",
    "\n",
    "openai_resources = [ {\"name\": \"openai1\", \"location\": \"uksouth\"}]\n",
    "openai_model_name = \"gpt-4o-mini\"\n",
    "openai_model_version = \"2024-07-18\"\n",
    "openai_model_sku = \"GlobalStandard\"\n",
    "openai_deployment_name = \"gpt-4o-mini\"\n",
    "openai_api_version = \"2024-10-21\"\n",
    "\n",
    "build = 0\n",
    "weather_mcp_server_image = \"weather-mcp-server\"\n",
    "weather_mcp_server_src = \"../../shared/mcp-servers/weather/http\"\n",
    "\n",
    "oncall_mcp_server_image = \"oncall-mcp-server\"\n",
    "oncall_mcp_server_src = \"../../shared/mcp-servers/oncall/http\"\n",
    "\n",
    "utils.print_ok('Notebook initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "### 1Ô∏è‚É£ Verify the Azure CLI and the connected Azure subscription\n",
    "\n",
    "The following commands ensure that you have the latest version of the Azure CLI and that the Azure CLI is connected to your Azure subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az account show \u001b[0m\n",
      "‚úÖ \u001b[1;32mRetrieved az account\u001b[0m ‚åö 10:09:06.140056 [0m:2s]\n",
      "üëâüèΩ \u001b[1;34mCurrent user: lproux@microsoft.com\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mTenant ID: 2b9d9f47-1fb6-400a-a438-39fe7d768649\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mSubscription ID: d334f2cd-3efd-494e-9fd3-2470b1a13e4c\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "output = utils.run(\"az account show\", \"Retrieved az account\", \"Failed to get the current az account\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    current_user = output.json_data['user']['name']\n",
    "    tenant_id = output.json_data['tenantId']\n",
    "    subscription_id = output.json_data['id']\n",
    "\n",
    "    utils.print_info(f\"Current user: {current_user}\")\n",
    "    utils.print_info(f\"Tenant ID: {tenant_id}\")\n",
    "    utils.print_info(f\"Subscription ID: {subscription_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### 2Ô∏è‚É£ Create deployment using ü¶æ Bicep\n",
    "\n",
    "This lab uses [Bicep](https://learn.microsoft.com/azure/azure-resource-manager/bicep/overview?tabs=bicep) to declarative define all the resources that will be deployed in the specified resource group. Change the parameters or the [main.bicep](main.bicep) directly to try different configurations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az group show --name lab-mcp-a2a-agents \u001b[0m\n",
      "üëâüèΩ \u001b[1;34mResource group lab-mcp-a2a-agents does not yet exist. Creating the resource group now...\u001b[0m\n",
      "‚öôÔ∏è \u001b[1;34mRunning: az group create --name lab-mcp-a2a-agents --location westeurope --tags source=ai-gateway \u001b[0m\n",
      "‚úÖ \u001b[1;32mResource group 'lab-mcp-a2a-agents' created\u001b[0m ‚åö 10:09:15.977741 [0m:5s]\n",
      "‚öôÔ∏è \u001b[1;34mRunning: az deployment group create --name mcp-a2a-agents --resource-group lab-mcp-a2a-agents --template-file main.bicep --parameters params.json \u001b[0m\n",
      "‚úÖ \u001b[1;32mDeployment 'mcp-a2a-agents' succeeded\u001b[0m ‚åö 10:12:03.576062 [2m:47s]\n"
     ]
    }
   ],
   "source": [
    "# Create the resource group if doesn't exist\n",
    "utils.create_resource_group(resource_group_name, resource_group_location)\n",
    "\n",
    "# Define the Bicep parameters\n",
    "bicep_parameters = {\n",
    "    \"$schema\": \"https://schema.management.azure.com/schemas/2019-04-01/deploymentParameters.json#\",\n",
    "    \"contentVersion\": \"1.0.0.0\",\n",
    "    \"parameters\": {\n",
    "        \"apimSku\": { \"value\": apim_sku },\n",
    "        \"openAIConfig\": { \"value\": openai_resources },\n",
    "        \"openAIDeploymentName\": { \"value\": openai_deployment_name },\n",
    "        \"openAIModelName\": { \"value\": openai_model_name },\n",
    "        \"openAIModelVersion\": { \"value\": openai_model_version },\n",
    "        \"openAIModelSKU\": { \"value\": openai_model_sku },\n",
    "        \"openAIAPIVersion\": { \"value\": openai_api_version },\n",
    "    }\n",
    "}\n",
    "\n",
    "# Write the parameters to the params.json file\n",
    "with open('params.json', 'w') as bicep_parameters_file:\n",
    "    bicep_parameters_file.write(json.dumps(bicep_parameters))\n",
    "\n",
    "# Run the deployment\n",
    "output = utils.run(f\"az deployment group create --name {deployment_name} --resource-group {resource_group_name} --template-file main.bicep --parameters params.json\",\n",
    "    f\"Deployment '{deployment_name}' succeeded\", f\"Deployment '{deployment_name}' failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### 3Ô∏è‚É£ Get the deployment outputs\n",
    "\n",
    "Retrieve the required outputs from the Bicep deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az deployment group show --name mcp-a2a-agents -g lab-mcp-a2a-agents \u001b[0m\n",
      "‚úÖ \u001b[1;32mRetrieved deployment: mcp-a2a-agents\u001b[0m ‚åö 10:12:07.535687 [0m:3s]\n",
      "üëâüèΩ \u001b[1;34mAPIM Service Id: /subscriptions/d334f2cd-3efd-494e-9fd3-2470b1a13e4c/resourceGroups/lab-mcp-a2a-agents/providers/Microsoft.ApiManagement/service/apim-iauylgmgqsk3i\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mAPIM Gateway URL: https://apim-iauylgmgqsk3i.azure-api.net\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mAPIM Resource Name: apim-iauylgmgqsk3i\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mAPIM Subscription Key (masked): 31bdedaaa0694450b92a34459ea0047b\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mApplication Insights Name: insights-iauylgmgqsk3i\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mContainer Registry Name: acriauylgmgqsk3i\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mWeather Container App Resource Name: aca-weather-tools-iauylgmgqsk3i\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mOncall Container App Resource Name: aca-oncall-tools-iauylgmgqsk3i\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mA2A (Weather) Agent Container App Resource Name: aca-weather-agent-iauylgmgqsk3i\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mA2A (Oncall) Agent Container App Resource Name: aca-oncall-agent-iauylgmgqsk3i\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mA2A (Weather) Agent Endpoint: aca-weather-agent-iauylgmgqsk3i.purplebeach-d45f94a9.westeurope.azurecontainerapps.io\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mA2A (Oncall) Agent Endpoint: aca-oncall-agent-iauylgmgqsk3i.purplebeach-d45f94a9.westeurope.azurecontainerapps.io\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Obtain all of the outputs from the deployment\n",
    "output = utils.run(f\"az deployment group show --name {deployment_name} -g {resource_group_name}\", f\"Retrieved deployment: {deployment_name}\", f\"Failed to retrieve deployment: {deployment_name}\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    apim_service_id = utils.get_deployment_output(output, 'apimServiceId', 'APIM Service Id')\n",
    "    apim_resource_gateway_url = utils.get_deployment_output(output, 'apimResourceGatewayURL', 'APIM Gateway URL')\n",
    "    apim_resource_name = utils.get_deployment_output(output, 'apimResourceName', 'APIM Resource Name')\n",
    "    apim_subscription_key = utils.get_deployment_output(output, 'apimSubscriptionKey', 'APIM Subscription Key (masked)', False)\n",
    "    app_insights_name = utils.get_deployment_output(output, 'applicationInsightsName', 'Application Insights Name')\n",
    "    container_registry_name = utils.get_deployment_output(output, 'containerRegistryName', 'Container Registry Name')\n",
    "    weather_containerapp_resource_name = utils.get_deployment_output(output, 'weatherMCPServerContainerAppResourceName', 'Weather Container App Resource Name')\n",
    "    oncall_containerapp_resource_name = utils.get_deployment_output(output, 'oncallMCPServerContainerAppResourceName', 'Oncall Container App Resource Name')\n",
    "\n",
    "    a2a_weather_containerapp_resource_name = utils.get_deployment_output(output, 'a2AWeatherAgentServerContainerAppResourceName', 'A2A (Weather) Agent Container App Resource Name')\n",
    "    a2a_oncall_containerapp_resource_name = utils.get_deployment_output(output, 'a2AOncallAgentServerContainerAppResourceName', 'A2A (Oncall) Agent Container App Resource Name')\n",
    "\n",
    "    a2a_weather_a2a_agent_ep = utils.get_deployment_output(output, 'a2AWeatherAgentServerContainerAppFQDN', 'A2A (Weather) Agent Endpoint')\n",
    "    a2a_oncall_a2a_agent_ep = utils.get_deployment_output(output, 'a2AOncallAgentServerContainerAppFQDN', 'A2A (Oncall) Agent Endpoint')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "### 4Ô∏è‚É£ Build and deploy the MCP Tools (to be use by both labs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az acr build --image weather-mcp-server:v0.2 --resource-group lab-mcp-a2a-agents --registry acriauylgmgqsk3i --file ../../shared/mcp-servers/weather/http/Dockerfile ../../shared/mcp-servers/weather/http/. --no-logs \u001b[0m\n",
      "‚úÖ \u001b[1;32mWeather MCP Server image was successfully built\u001b[0m ‚åö 10:13:15.676921 [1m:8s]\n",
      "‚öôÔ∏è \u001b[1;34mRunning: az containerapp update -n aca-weather-tools-iauylgmgqsk3i -g lab-mcp-a2a-agents --image \"acriauylgmgqsk3i.azurecr.io/weather-mcp-server:v0.2\" \u001b[0m\n",
      "‚úÖ \u001b[1;32mWeather MCP Server deployment succeeded\u001b[0m ‚åö 10:13:36.502738 [0m:20s]\n",
      "‚öôÔ∏è \u001b[1;34mRunning: az acr build --image oncall-mcp-server:v0.2 --resource-group lab-mcp-a2a-agents --registry acriauylgmgqsk3i --file ../../shared/mcp-servers/oncall/http/Dockerfile ../../shared/mcp-servers/oncall/http/. --no-logs \u001b[0m\n",
      "‚úÖ \u001b[1;32mOncall MCP Server image was successfully built\u001b[0m ‚åö 10:14:45.708539 [1m:9s]\n",
      "‚öôÔ∏è \u001b[1;34mRunning: az containerapp update -n aca-oncall-tools-iauylgmgqsk3i -g lab-mcp-a2a-agents --image \"acriauylgmgqsk3i.azurecr.io/oncall-mcp-server:v0.2\" \u001b[0m\n",
      "‚úÖ \u001b[1;32mOncall MCP Server deployment succeeded\u001b[0m ‚åö 10:15:07.009874 [0m:21s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<utils.Output at 0x24eedbd3d50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build = build + 2 # increment the build number\n",
    "\n",
    "utils.run(f\"az acr build --image {weather_mcp_server_image}:v0.{build} --resource-group {resource_group_name} --registry {container_registry_name} --file {weather_mcp_server_src}/Dockerfile {weather_mcp_server_src}/. --no-logs\", \n",
    "          \"Weather MCP Server image was successfully built\", \"Failed to build the Weather MCP Server image\")\n",
    "utils.run(f'az containerapp update -n {weather_containerapp_resource_name} -g {resource_group_name} --image \"{container_registry_name}.azurecr.io/{weather_mcp_server_image}:v0.{build}\"', \n",
    "          \"Weather MCP Server deployment succeeded\", \"Weather MCP Server deployment failed\")\n",
    "\n",
    "utils.run(f\"az acr build --image {oncall_mcp_server_image}:v0.{build} --resource-group {resource_group_name} --registry {container_registry_name} --file {oncall_mcp_server_src}/Dockerfile {oncall_mcp_server_src}/. --no-logs\", \n",
    "          \"Oncall MCP Server image was successfully built\", \"Failed to build the Oncall MCP Server image\")\n",
    "utils.run(f'az containerapp update -n {oncall_containerapp_resource_name} -g {resource_group_name} --image \"{container_registry_name}.azurecr.io/{oncall_mcp_server_image}:v0.{build}\"', \n",
    "          \"Oncall MCP Server deployment succeeded\", \"Oncall MCP Server deployment failed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='testconnection'></a>\n",
    "### üß™ Test the connection to the MCP Tools' servers and List Tools\n",
    "\n",
    "üí° To integrate MCP servers in VS Code, use the MCP server URL  `../mcp ` for configuration in GitHub Copilot Agent Mode\n",
    "\n",
    "At this stage we're just testing that our MCP tools servers work:\n",
    "\n",
    "![flow](../../images/agent-2-mcp.gif)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connected to server https://apim-iauylgmgqsk3i.azure-api.net/weather\n",
      "‚öôÔ∏è Tools:\n",
      "  - get_cities\n",
      "     Input Schema: {'properties': {'country': {'type': 'string'}}, 'required': ['country'], 'type': 'object'}\n",
      "  - get_weather\n",
      "     Input Schema: {'properties': {'city': {'type': 'string'}}, 'required': ['city'], 'type': 'object'}\n",
      "‚úÖ Connection closed\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "Cancelled via cancel scope 24ef0bd2150 by <Task cancelling name='Task-20' coro=<list_tools() running at C:\\Users\\lproux\\AppData\\Local\\Temp\\ipykernel_20136\\902043953.py:25>>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mWouldBlock\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lproux\\OneDrive - Microsoft\\bkp\\Documents\\GitHub\\.venv\\Lib\\site-packages\\anyio\\streams\\memory.py:111\u001b[39m, in \u001b[36mMemoryObjectReceiveStream.receive\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreceive_nowait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m WouldBlock:\n\u001b[32m    113\u001b[39m     \u001b[38;5;66;03m# Add ourselves in the queue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lproux\\OneDrive - Microsoft\\bkp\\Documents\\GitHub\\.venv\\Lib\\site-packages\\anyio\\streams\\memory.py:106\u001b[39m, in \u001b[36mMemoryObjectReceiveStream.receive_nowait\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m EndOfStream\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m WouldBlock\n",
      "\u001b[31mWouldBlock\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mlist_tools\u001b[39m\u001b[34m(server_url, authorization_header)\u001b[39m\n\u001b[32m     16\u001b[39m session = \u001b[38;5;28;01mawait\u001b[39;00m session_ctx.\u001b[34m__aenter__\u001b[39m()\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m session.initialize()\n\u001b[32m     18\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m session.list_tools()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lproux\\OneDrive - Microsoft\\bkp\\Documents\\GitHub\\.venv\\Lib\\site-packages\\mcp\\client\\session.py:151\u001b[39m, in \u001b[36mClientSession.initialize\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    142\u001b[39m roots = (\n\u001b[32m    143\u001b[39m     \u001b[38;5;66;03m# TODO: Should this be based on whether we\u001b[39;00m\n\u001b[32m    144\u001b[39m     \u001b[38;5;66;03m# _will_ send notifications, or only whether\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    148\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.send_request(\n\u001b[32m    152\u001b[39m     types.ClientRequest(\n\u001b[32m    153\u001b[39m         types.InitializeRequest(\n\u001b[32m    154\u001b[39m             params=types.InitializeRequestParams(\n\u001b[32m    155\u001b[39m                 protocolVersion=types.LATEST_PROTOCOL_VERSION,\n\u001b[32m    156\u001b[39m                 capabilities=types.ClientCapabilities(\n\u001b[32m    157\u001b[39m                     sampling=sampling,\n\u001b[32m    158\u001b[39m                     elicitation=elicitation,\n\u001b[32m    159\u001b[39m                     experimental=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    160\u001b[39m                     roots=roots,\n\u001b[32m    161\u001b[39m                 ),\n\u001b[32m    162\u001b[39m                 clientInfo=\u001b[38;5;28mself\u001b[39m._client_info,\n\u001b[32m    163\u001b[39m             ),\n\u001b[32m    164\u001b[39m         )\n\u001b[32m    165\u001b[39m     ),\n\u001b[32m    166\u001b[39m     types.InitializeResult,\n\u001b[32m    167\u001b[39m )\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.protocolVersion \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SUPPORTED_PROTOCOL_VERSIONS:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lproux\\OneDrive - Microsoft\\bkp\\Documents\\GitHub\\.venv\\Lib\\site-packages\\mcp\\shared\\session.py:272\u001b[39m, in \u001b[36mBaseSession.send_request\u001b[39m\u001b[34m(self, request, result_type, request_read_timeout_seconds, metadata, progress_callback)\u001b[39m\n\u001b[32m    271\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m anyio.fail_after(timeout):\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m         response_or_error = \u001b[38;5;28;01mawait\u001b[39;00m response_stream_reader.receive()\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lproux\\OneDrive - Microsoft\\bkp\\Documents\\GitHub\\.venv\\Lib\\site-packages\\anyio\\streams\\memory.py:119\u001b[39m, in \u001b[36mMemoryObjectReceiveStream.receive\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m receive_event.wait()\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lproux\\OneDrive - Microsoft\\bkp\\Documents\\GitHub\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py:1783\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1783\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event.wait()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\locks.py:213\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[32m    214\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\futures.py:286\u001b[39m, in \u001b[36mFuture.__await__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28mself\u001b[39m._asyncio_future_blocking = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# This tells Task to wait for completion.\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\tasks.py:375\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m     \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    377\u001b[39m     \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\futures.py:194\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == _CANCELLED:\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_cancelled_error()\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state != _FINISHED:\n",
      "\u001b[31mCancelledError\u001b[39m: Cancelled via cancel scope 24ef0bd19d0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     36\u001b[39m     asyncio.run(list_tools(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mapim_resource_gateway_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/weather\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlist_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mapim_resource_gateway_url\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/oncall\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     39\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Connection closed\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lproux\\OneDrive - Microsoft\\bkp\\Documents\\GitHub\\.venv\\Lib\\site-packages\\nest_asyncio.py:30\u001b[39m, in \u001b[36m_patch_asyncio.<locals>.run\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m     28\u001b[39m task = asyncio.ensure_future(main)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task.done():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lproux\\OneDrive - Microsoft\\bkp\\Documents\\GitHub\\.venv\\Lib\\site-packages\\nest_asyncio.py:98\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\futures.py:194\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the result this future represents.\u001b[39;00m\n\u001b[32m    188\u001b[39m \n\u001b[32m    189\u001b[39m \u001b[33;03mIf the future has been cancelled, raises CancelledError.  If the\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[33;03mfuture's result isn't yet available, raises InvalidStateError.  If\u001b[39;00m\n\u001b[32m    191\u001b[39m \u001b[33;03mthe future is done and has an exception set, this exception is raised.\u001b[39;00m\n\u001b[32m    192\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == _CANCELLED:\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_cancelled_error()\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state != _FINISHED:\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.InvalidStateError(\u001b[33m'\u001b[39m\u001b[33mResult is not ready.\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\tasks.py:306\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    304\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    308\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._must_cancel:\n\u001b[32m    309\u001b[39m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mlist_tools\u001b[39m\u001b[34m(server_url, authorization_header)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     23\u001b[39m     \u001b[38;5;66;03m# Ensure session and streams are closed if they were opened\u001b[39;00m\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m session \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m session_ctx.\u001b[34m__aexit__\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m streams \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     27\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m streams_ctx.\u001b[34m__aexit__\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lproux\\OneDrive - Microsoft\\bkp\\Documents\\GitHub\\.venv\\Lib\\site-packages\\mcp\\shared\\session.py:218\u001b[39m, in \u001b[36mBaseSession.__aexit__\u001b[39m\u001b[34m(self, exc_type, exc_val, exc_tb)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;66;03m# Using BaseSession as a context manager should not block on exit (this\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;66;03m# would be very surprising behavior), so make sure to cancel the tasks\u001b[39;00m\n\u001b[32m    216\u001b[39m \u001b[38;5;66;03m# in the task group.\u001b[39;00m\n\u001b[32m    217\u001b[39m \u001b[38;5;28mself\u001b[39m._task_group.cancel_scope.cancel()\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._task_group.\u001b[34m__aexit__\u001b[39m(exc_type, exc_val, exc_tb)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lproux\\OneDrive - Microsoft\\bkp\\Documents\\GitHub\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py:785\u001b[39m, in \u001b[36mTaskGroup.__aexit__\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    781\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m BaseExceptionGroup(\n\u001b[32m    782\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33munhandled errors in a TaskGroup\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m._exceptions\n\u001b[32m    783\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    784\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m exc_val:\n\u001b[32m--> \u001b[39m\u001b[32m785\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m exc_val\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    787\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cancel_scope.\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mtype\u001b[39m(exc), exc, exc.__traceback__):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lproux\\OneDrive - Microsoft\\bkp\\Documents\\GitHub\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py:753\u001b[39m, in \u001b[36mTaskGroup.__aexit__\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    750\u001b[39m \u001b[38;5;28mself\u001b[39m._on_completed_fut = loop.create_future()\n\u001b[32m    752\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m753\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._on_completed_fut\n\u001b[32m    754\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m CancelledError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    755\u001b[39m     \u001b[38;5;66;03m# Shield the scope against further cancellation attempts,\u001b[39;00m\n\u001b[32m    756\u001b[39m     \u001b[38;5;66;03m# as they're not productive (#695)\u001b[39;00m\n\u001b[32m    757\u001b[39m     wait_scope.shield = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\futures.py:286\u001b[39m, in \u001b[36mFuture.__await__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    285\u001b[39m     \u001b[38;5;28mself\u001b[39m._asyncio_future_blocking = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# This tells Task to wait for completion.\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    288\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mawait wasn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt used with future\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\tasks.py:375\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[32m    374\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m         \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    376\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    377\u001b[39m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[32m    378\u001b[39m         \u001b[38;5;28mself\u001b[39m.__step(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\futures.py:194\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the result this future represents.\u001b[39;00m\n\u001b[32m    188\u001b[39m \n\u001b[32m    189\u001b[39m \u001b[33;03mIf the future has been cancelled, raises CancelledError.  If the\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[33;03mfuture's result isn't yet available, raises InvalidStateError.  If\u001b[39;00m\n\u001b[32m    191\u001b[39m \u001b[33;03mthe future is done and has an exception set, this exception is raised.\u001b[39;00m\n\u001b[32m    192\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == _CANCELLED:\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_cancelled_error()\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state != _FINISHED:\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.InvalidStateError(\u001b[33m'\u001b[39m\u001b[33mResult is not ready.\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mCancelledError\u001b[39m: Cancelled via cancel scope 24ef0bd2150 by <Task cancelling name='Task-20' coro=<list_tools() running at C:\\Users\\lproux\\AppData\\Local\\Temp\\ipykernel_20136\\902043953.py:25>>"
     ]
    }
   ],
   "source": [
    "import os, json, asyncio, time, requests\n",
    "from mcp import ClientSession\n",
    "from mcp.client.streamable_http import streamablehttp_client\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def list_tools(server_url, authorization_header = None):\n",
    "    headers = {\"Authorization\": authorization_header} if authorization_header else None\n",
    "    streams = None\n",
    "    session = None\n",
    "    tools = []\n",
    "    try:\n",
    "        streams_ctx = streamablehttp_client(server_url, headers)\n",
    "        streams = await streams_ctx.__aenter__()\n",
    "        session_ctx = ClientSession(streams[0], streams[1])\n",
    "        session = await session_ctx.__aenter__()\n",
    "        await session.initialize()\n",
    "        response = await session.list_tools()\n",
    "        tools = response.tools\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "    finally:\n",
    "        # Ensure session and streams are closed if they were opened\n",
    "        if session is not None:\n",
    "            await session_ctx.__aexit__(None, None, None) # type: ignore\n",
    "        if streams is not None:\n",
    "            await streams_ctx.__aexit__(None, None, None) # type: ignore\n",
    "    if tools:\n",
    "        print(f\"‚úÖ Connected to server {server_url}\")\n",
    "        print(\"‚öôÔ∏è Tools:\")\n",
    "        for tool in tools:\n",
    "            print(f\"  - {tool.name}\")\n",
    "            print(f\"     Input Schema: {tool.inputSchema}\")\n",
    "\n",
    "try:\n",
    "    asyncio.run(list_tools(f\"{apim_resource_gateway_url}/weather\"))\n",
    "    asyncio.run(list_tools(f\"{apim_resource_gateway_url}/oncall\"))\n",
    "finally:\n",
    "    print(f\"‚úÖ Connection closed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Agent + 2 MCP Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from semantic_kernel.agents import ChatCompletionAgent, ChatHistoryAgentThread\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.connectors.mcp import MCPStreamableHttpPlugin\n",
    "\n",
    "inference_api_path = \"\"\n",
    "inference_api_version = \"2025-03-01-preview\"\n",
    "\n",
    "user_input = \"What's the current weather in Lisbon and London? and who's oncall today?\"\n",
    "\n",
    "weather_plugin = MCPStreamableHttpPlugin(\n",
    "    name=\"Weather\",\n",
    "    url=f\"{apim_resource_gateway_url}/weather\",\n",
    "    description=\"Weather Plugin\",\n",
    "    )\n",
    "\n",
    "oncall_plugin = MCPStreamableHttpPlugin(\n",
    "    name=\"OnCall\",\n",
    "    url=f\"{apim_resource_gateway_url}/oncall\",\n",
    "    description=\"OnCall Plugin\",\n",
    ")\n",
    "\n",
    "await weather_plugin.connect()  # Ensure the plugin is connected before using it\n",
    "await oncall_plugin.connect()  # Ensure the plugin is connected before using it\n",
    "\n",
    "agent = ChatCompletionAgent(\n",
    "    service=AzureChatCompletion(\n",
    "        endpoint=f\"{apim_resource_gateway_url}/{inference_api_path}\",\n",
    "        api_key=apim_subscription_key,\n",
    "        api_version=inference_api_version,                \n",
    "        deployment_name=openai_model_name  # Use the first model from the models_config\n",
    "    ),\n",
    "    name=\"IssueAgent\",\n",
    "    instructions=\"Answer questions using the tools at your disposal.\",\n",
    "    plugins=[weather_plugin, oncall_plugin],\n",
    ")\n",
    "\n",
    "thread: ChatHistoryAgentThread | None = None\n",
    "\n",
    "print(f\"# User: {user_input}\")\n",
    "# 2. Invoke the agent for a response\n",
    "response = await agent.get_response(messages=user_input, thread=thread)\n",
    "print(f\"# {response.name}: {response} \")\n",
    "thread = response.thread # type: ignore\n",
    "\n",
    "# 3. Cleanup: Clear the thread\n",
    "await thread.delete() if thread else None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='inspector'></a>\n",
    "### üß™ (optional) Use the [MCP Inspector](https://modelcontextprotocol.io/docs/tools/inspector) for testing and debugging the MCP servers\n",
    "\n",
    "#### Execute the following steps:\n",
    "1. Execute `npx @modelcontextprotocol/inspector` in a terminal\n",
    "2. Open the provided URL in a browser\n",
    "3. Set the transport type as SSE\n",
    "4. Provide the MCP server url and click connect\n",
    "5. Select the \"Tools\" tab to see and run the available tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='agent-to-agent'></a>\n",
    "### 5Ô∏è‚É£ Experiment with agent-to-agent communication\n",
    "\n",
    "This is what we're all here for!! Choose a path :) \n",
    "\n",
    "- Use notebook to exexoeriment with agent-to-agent communication [(using MCP Protocol)](mcp-agent-as-mcp-server.ipynb)\n",
    "- Use notebooks experiment with a2a-enabled agents [(using a2a Protocol)](mcp-agent-as-a2a-server.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "### üóëÔ∏è Clean up resources\n",
    "\n",
    "When you're finished with the lab, you should remove all your deployed resources from Azure to avoid extra charges and keep your Azure subscription uncluttered.\n",
    "Use the [clean-up-resources notebook](clean-up-resources.ipynb) for that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
