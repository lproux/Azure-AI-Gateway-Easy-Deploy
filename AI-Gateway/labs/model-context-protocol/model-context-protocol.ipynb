{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIM â¤ï¸ AI Agents\n",
    "\n",
    "## Model Context Protocol (MCP) lab\n",
    "![flow](../../images/model-context-protocol.gif)\n",
    "\n",
    "Playground to experiment the [Model Context Protocol](https://modelcontextprotocol.io/) with Azure API Management to enable plug & play of tools to LLMs. Leverages the [credential manager](https://learn.microsoft.com/en-us/azure/api-management/credentials-overview) for  managing OAuth 2.0 tokens to backend tools and [client token validation](https://learn.microsoft.com/en-us/azure/api-management/validate-jwt-policy) to ensure end-to-end authentication and authorization.   \n",
    "This lab includes the following MCP servers:\n",
    "- Basic oncall service: provides a tool to get a list of random people currently on-call with their status and time zone.\n",
    "- Basic weather service: provide tools to get cities for a given country and retrieve random weather information for a specified city.\n",
    "- GitHub Issues MCP Server: provide tools to authenticate on GitHub using the APIM Credential Manager, retrieves user information, and lists issues for a specified repository. This [sequence diagram](./diagrams/diagrams.md) explains the flow. \n",
    "- ServiceNow incidents MCP Server: provides tools to authenticates on ServiceNow using the APIM Credential Manager, lists incidents, retrieves a particular incident and create a new one.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- [Python 3.12 or later version](https://www.python.org/) installed\n",
    "- [VS Code](https://code.visualstudio.com/) installed with the [Jupyter notebook extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) enabled\n",
    "- [Python environment](https://code.visualstudio.com/docs/python/environments#_creating-environments) with the [requirements.txt](../../requirements.txt) or run `pip install -r requirements.txt` in your terminal\n",
    "- [An Azure Subscription](https://azure.microsoft.com/free/) with [Contributor](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#contributor) + [RBAC Administrator](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#role-based-access-control-administrator) or [Owner](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#owner) roles\n",
    "- [Azure CLI](https://learn.microsoft.com/cli/azure/install-azure-cli) installed and [Signed into your Azure subscription](https://learn.microsoft.com/cli/azure/authenticate-azure-cli-interactively)\n",
    "\n",
    "â–¶ï¸ Click `Run All` to execute all steps sequentially, or execute them `Step by Step`...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "### 0ï¸âƒ£ Initialize notebook variables\n",
    "\n",
    "- Resources will be suffixed by a unique string based on your subscription id.\n",
    "- Adjust the location parameters according your preferences and on the [product availability by Azure region.](https://azure.microsoft.com/explore/global-infrastructure/products-by-region/?cdn=disable&products=cognitive-services,api-management) \n",
    "- Adjust the OpenAI model and version according the [availability by region.](https://learn.microsoft.com/azure/ai-services/openai/concepts/models) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… \u001b[1;32mNotebook initialized\u001b[0m âŒš 10:37:04.580467 \n"
     ]
    }
   ],
   "source": [
    "import os, sys, json\n",
    "sys.path.insert(1, '../../shared')  # add the shared directory to the Python path\n",
    "import utils\n",
    "\n",
    "deployment_name = os.path.basename(os.path.dirname(globals()['__vsc_ipynb_file__']))\n",
    "resource_group_name = f\"lab-{deployment_name}\" # change the name to match your naming style\n",
    "resource_group_location = \"eastus2\"\n",
    "\n",
    "aiservices_config = [{\"name\": \"foundry1\", \"location\": \"eastus2\"}]\n",
    "\n",
    "models_config = [{\"name\": \"gpt-4o-mini\", \"publisher\": \"OpenAI\", \"version\": \"2024-07-18\", \"sku\": \"GlobalStandard\", \"capacity\": 100}]\n",
    "\n",
    "apim_sku = 'Basicv2'\n",
    "apim_subscriptions_config = [{\"name\": \"subscription1\", \"displayName\": \"Subscription 1\"}, \n",
    "                             {\"name\": \"subscription2\", \"displayName\": \"Subscription 2\"}, \n",
    "                             {\"name\": \"subscription3\", \"displayName\": \"Subscription 3\"}]\n",
    "\n",
    "inference_api_path = \"\"  # path to the inference API in the APIM service - use blank to use the default path\n",
    "inference_api_type = \"AzureOpenAI\"  # options: AzureOpenAI, AzureAI, OpenAI, PassThrough\n",
    "inference_api_version = \"2025-03-01-preview\"\n",
    "foundry_project_name = deployment_name\n",
    "\n",
    "build = 1\n",
    "weather_mcp_server_image = \"weather-mcp-server\"\n",
    "weather_mcp_server_src = \"../../shared/mcp-servers/weather/http\"\n",
    "\n",
    "oncall_mcp_server_image = \"oncall-mcp-server\"\n",
    "oncall_mcp_server_src = \"../../shared/mcp-servers/oncall/http\"\n",
    "\n",
    "github_mcp_server_image = \"github-mcp-server\"\n",
    "github_mcp_server_src = \"../../shared/mcp-servers/github/http\"\n",
    "\n",
    "utils.print_ok('Notebook initialized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-ai-projects==1.0.0b12 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (1.0.0b12)\n",
      "Requirement already satisfied: agent-framework in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (1.0.0b251016)\n",
      "Requirement already satisfied: isodate>=0.6.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from azure-ai-projects==1.0.0b12) (0.7.2)\n",
      "Requirement already satisfied: azure-core>=1.30.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from azure-ai-projects==1.0.0b12) (1.35.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from azure-ai-projects==1.0.0b12) (4.15.0)\n",
      "Requirement already satisfied: azure-storage-blob>=12.15.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from azure-ai-projects==1.0.0b12) (12.26.0)\n",
      "Requirement already satisfied: azure-ai-agents>=1.0.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from azure-ai-projects==1.0.0b12) (1.2.0b5)\n",
      "Requirement already satisfied: agent-framework-core in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from agent-framework) (1.0.0b251016)\n",
      "Requirement already satisfied: agent-framework-a2a in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from agent-framework) (1.0.0b251016)\n",
      "Requirement already satisfied: agent-framework-azure-ai in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from agent-framework) (1.0.0b251016)\n",
      "Requirement already satisfied: agent-framework-copilotstudio in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from agent-framework) (1.0.0b251016)\n",
      "Requirement already satisfied: agent-framework-mem0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from agent-framework) (1.0.0b251016)\n",
      "Requirement already satisfied: agent-framework-redis in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from agent-framework) (1.0.0b251016)\n",
      "Requirement already satisfied: agent-framework-devui in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from agent-framework) (1.0.0b251016)\n",
      "Requirement already satisfied: agent-framework-purview in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from agent-framework) (1.0.0b251016)\n",
      "Requirement already satisfied: requests>=2.21.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from azure-core>=1.30.0->azure-ai-projects==1.0.0b12) (2.32.5)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from azure-core>=1.30.0->azure-ai-projects==1.0.0b12) (1.17.0)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from azure-storage-blob>=12.15.0->azure-ai-projects==1.0.0b12) (46.0.2)\n",
      "Requirement already satisfied: cffi>=2.0.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from cryptography>=2.1.4->azure-storage-blob>=12.15.0->azure-ai-projects==1.0.0b12) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from cffi>=2.0.0->cryptography>=2.1.4->azure-storage-blob>=12.15.0->azure-ai-projects==1.0.0b12) (2.23)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-projects==1.0.0b12) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-projects==1.0.0b12) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-projects==1.0.0b12) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-projects==1.0.0b12) (2025.10.5)\n",
      "Requirement already satisfied: a2a-sdk>=0.3.5 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from agent-framework-a2a->agent-framework) (0.3.10)\n",
      "Requirement already satisfied: google-api-core>=1.26.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from a2a-sdk>=0.3.5->agent-framework-a2a->agent-framework) (2.26.0)\n",
      "Requirement already satisfied: httpx-sse>=0.4.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from a2a-sdk>=0.3.5->agent-framework-a2a->agent-framework) (0.4.1)\n",
      "Requirement already satisfied: httpx>=0.28.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from a2a-sdk>=0.3.5->agent-framework-a2a->agent-framework) (0.28.1)\n",
      "Requirement already satisfied: protobuf>=5.29.5 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from a2a-sdk>=0.3.5->agent-framework-a2a->agent-framework) (5.29.5)\n",
      "Requirement already satisfied: pydantic>=2.11.3 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from a2a-sdk>=0.3.5->agent-framework-a2a->agent-framework) (2.11.10)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from google-api-core>=1.26.0->a2a-sdk>=0.3.5->agent-framework-a2a->agent-framework) (1.71.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from google-api-core>=1.26.0->a2a-sdk>=0.3.5->agent-framework-a2a->agent-framework) (1.26.1)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from google-api-core>=1.26.0->a2a-sdk>=0.3.5->agent-framework-a2a->agent-framework) (2.41.1)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-api-core>=1.26.0->a2a-sdk>=0.3.5->agent-framework-a2a->agent-framework) (6.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-api-core>=1.26.0->a2a-sdk>=0.3.5->agent-framework-a2a->agent-framework) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-api-core>=1.26.0->a2a-sdk>=0.3.5->agent-framework-a2a->agent-framework) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-api-core>=1.26.0->a2a-sdk>=0.3.5->agent-framework-a2a->agent-framework) (0.6.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from httpx>=0.28.1->a2a-sdk>=0.3.5->agent-framework-a2a->agent-framework) (4.11.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from httpx>=0.28.1->a2a-sdk>=0.3.5->agent-framework-a2a->agent-framework) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.28.1->a2a-sdk>=0.3.5->agent-framework-a2a->agent-framework) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from pydantic>=2.11.3->a2a-sdk>=0.3.5->agent-framework-a2a->agent-framework) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from pydantic>=2.11.3->a2a-sdk>=0.3.5->agent-framework-a2a->agent-framework) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from pydantic>=2.11.3->a2a-sdk>=0.3.5->agent-framework-a2a->agent-framework) (0.4.2)\n",
      "Requirement already satisfied: aiohttp~=3.8 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from agent-framework-azure-ai->agent-framework) (3.12.15)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from aiohttp~=3.8->agent-framework-azure-ai->agent-framework) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from aiohttp~=3.8->agent-framework-azure-ai->agent-framework) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from aiohttp~=3.8->agent-framework-azure-ai->agent-framework) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from aiohttp~=3.8->agent-framework-azure-ai->agent-framework) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from aiohttp~=3.8->agent-framework-azure-ai->agent-framework) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from aiohttp~=3.8->agent-framework-azure-ai->agent-framework) (0.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from aiohttp~=3.8->agent-framework-azure-ai->agent-framework) (1.21.0)\n",
      "Requirement already satisfied: microsoft-agents-copilotstudio-client>=0.3.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from agent-framework-copilotstudio->agent-framework) (0.4.0)\n",
      "Requirement already satisfied: microsoft-agents-hosting-core==0.4.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from microsoft-agents-copilotstudio-client>=0.3.1->agent-framework-copilotstudio->agent-framework) (0.4.0)\n",
      "Requirement already satisfied: microsoft-agents-activity==0.4.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from microsoft-agents-hosting-core==0.4.0->microsoft-agents-copilotstudio-client>=0.3.1->agent-framework-copilotstudio->agent-framework) (0.4.0)\n",
      "Requirement already satisfied: pyjwt>=2.10.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from microsoft-agents-hosting-core==0.4.0->microsoft-agents-copilotstudio-client>=0.3.1->agent-framework-copilotstudio->agent-framework) (2.10.1)\n",
      "Requirement already satisfied: python-dotenv>=1.1.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from microsoft-agents-hosting-core==0.4.0->microsoft-agents-copilotstudio-client>=0.3.1->agent-framework-copilotstudio->agent-framework) (1.1.1)\n",
      "Requirement already satisfied: openai<2,>=1.99.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from agent-framework-core->agent-framework) (1.109.1)\n",
      "Requirement already satisfied: pydantic-settings<3,>=2 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from agent-framework-core->agent-framework) (2.11.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.24 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from agent-framework-core->agent-framework) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.24 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from agent-framework-core->agent-framework) (1.37.0)\n",
      "Requirement already satisfied: mcp>=1.13 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from mcp[ws]>=1.13->agent-framework-core->agent-framework) (1.16.0)\n",
      "Requirement already satisfied: azure-monitor-opentelemetry>=1.7.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from agent-framework-core->agent-framework) (1.8.1)\n",
      "Requirement already satisfied: azure-monitor-opentelemetry-exporter>=1.0.0b41 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from agent-framework-core->agent-framework) (1.0.0b42)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.36.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from agent-framework-core->agent-framework) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions-ai>=0.4.13 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from agent-framework-core->agent-framework) (0.4.13)\n",
      "Requirement already satisfied: aiofiles>=24.1.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from agent-framework-core->agent-framework) (24.1.0)\n",
      "Requirement already satisfied: azure-identity<2,>=1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from agent-framework-core->agent-framework) (1.25.0)\n",
      "Requirement already satisfied: msal>=1.30.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from azure-identity<2,>=1->agent-framework-core->agent-framework) (1.34.0b1)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from azure-identity<2,>=1->agent-framework-core->agent-framework) (1.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openai<2,>=1.99.0->agent-framework-core->agent-framework) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openai<2,>=1.99.0->agent-framework-core->agent-framework) (0.11.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openai<2,>=1.99.0->agent-framework-core->agent-framework) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openai<2,>=1.99.0->agent-framework-core->agent-framework) (4.67.1)\n",
      "Requirement already satisfied: azure-core-tracing-opentelemetry~=1.0.0b11 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from azure-monitor-opentelemetry>=1.7.0->agent-framework-core->agent-framework) (1.0.0b12)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-django~=0.57b0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from azure-monitor-opentelemetry>=1.7.0->agent-framework-core->agent-framework) (0.58b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi~=0.57b0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from azure-monitor-opentelemetry>=1.7.0->agent-framework-core->agent-framework) (0.58b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-flask~=0.57b0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from azure-monitor-opentelemetry>=1.7.0->agent-framework-core->agent-framework) (0.58b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-psycopg2~=0.57b0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from azure-monitor-opentelemetry>=1.7.0->agent-framework-core->agent-framework) (0.58b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-requests~=0.57b0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from azure-monitor-opentelemetry>=1.7.0->agent-framework-core->agent-framework) (0.58b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-urllib~=0.57b0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from azure-monitor-opentelemetry>=1.7.0->agent-framework-core->agent-framework) (0.58b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-urllib3~=0.57b0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from azure-monitor-opentelemetry>=1.7.0->agent-framework-core->agent-framework) (0.58b0)\n",
      "Requirement already satisfied: opentelemetry-resource-detector-azure~=0.1.5 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from azure-monitor-opentelemetry>=1.7.0->agent-framework-core->agent-framework) (0.1.5)\n",
      "Requirement already satisfied: fixedint==0.1.6 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from azure-monitor-opentelemetry-exporter>=1.0.0b41->agent-framework-core->agent-framework) (0.1.6)\n",
      "Requirement already satisfied: msrest>=0.6.10 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from azure-monitor-opentelemetry-exporter>=1.0.0b41->agent-framework-core->agent-framework) (0.7.1)\n",
      "Requirement already satisfied: psutil<8,>=5.9 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from azure-monitor-opentelemetry-exporter>=1.0.0b41->agent-framework-core->agent-framework) (7.1.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from opentelemetry-api>=1.24->agent-framework-core->agent-framework) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.24->agent-framework-core->agent-framework) (3.23.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-wsgi==0.58b0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-django~=0.57b0->azure-monitor-opentelemetry>=1.7.0->agent-framework-core->agent-framework) (0.58b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.58b0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-django~=0.57b0->azure-monitor-opentelemetry>=1.7.0->agent-framework-core->agent-framework) (0.58b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-django~=0.57b0->azure-monitor-opentelemetry>=1.7.0->agent-framework-core->agent-framework) (0.58b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.58b0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-django~=0.57b0->azure-monitor-opentelemetry>=1.7.0->agent-framework-core->agent-framework) (0.58b0)\n",
      "Requirement already satisfied: packaging>=18.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from opentelemetry-instrumentation==0.58b0->opentelemetry-instrumentation-django~=0.57b0->azure-monitor-opentelemetry>=1.7.0->agent-framework-core->agent-framework) (25.0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from opentelemetry-instrumentation==0.58b0->opentelemetry-instrumentation-django~=0.57b0->azure-monitor-opentelemetry>=1.7.0->agent-framework-core->agent-framework) (1.17.3)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.58b0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-fastapi~=0.57b0->azure-monitor-opentelemetry>=1.7.0->agent-framework-core->agent-framework) (0.58b0)\n",
      "Requirement already satisfied: asgiref~=3.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.58b0->opentelemetry-instrumentation-fastapi~=0.57b0->azure-monitor-opentelemetry>=1.7.0->agent-framework-core->agent-framework) (3.10.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-dbapi==0.58b0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from opentelemetry-instrumentation-psycopg2~=0.57b0->azure-monitor-opentelemetry>=1.7.0->agent-framework-core->agent-framework) (0.58b0)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from mcp>=1.13->mcp[ws]>=1.13->agent-framework-core->agent-framework) (4.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from mcp>=1.13->mcp[ws]>=1.13->agent-framework-core->agent-framework) (0.0.20)\n",
      "Requirement already satisfied: pywin32>=310 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from mcp>=1.13->mcp[ws]>=1.13->agent-framework-core->agent-framework) (311)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from mcp>=1.13->mcp[ws]>=1.13->agent-framework-core->agent-framework) (3.0.2)\n",
      "Requirement already satisfied: starlette>=0.27 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from mcp>=1.13->mcp[ws]>=1.13->agent-framework-core->agent-framework) (0.48.0)\n",
      "Requirement already satisfied: uvicorn>=0.31.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from mcp>=1.13->mcp[ws]>=1.13->agent-framework-core->agent-framework) (0.37.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from jsonschema>=4.20.0->mcp>=1.13->mcp[ws]>=1.13->agent-framework-core->agent-framework) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from jsonschema>=4.20.0->mcp>=1.13->mcp[ws]>=1.13->agent-framework-core->agent-framework) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from jsonschema>=4.20.0->mcp>=1.13->mcp[ws]>=1.13->agent-framework-core->agent-framework) (0.27.1)\n",
      "Requirement already satisfied: websockets>=15.0.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from mcp[ws]>=1.13->agent-framework-core->agent-framework) (15.0.1)\n",
      "Requirement already satisfied: portalocker<3,>=1.4 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from msal-extensions>=1.2.0->azure-identity<2,>=1->agent-framework-core->agent-framework) (2.10.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from msrest>=0.6.10->azure-monitor-opentelemetry-exporter>=1.0.0b41->agent-framework-core->agent-framework) (2.0.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.66.2 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.36.0->agent-framework-core->agent-framework) (1.76.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.36.0->agent-framework-core->agent-framework) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.37.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.36.0->agent-framework-core->agent-framework) (1.37.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.10->azure-monitor-opentelemetry-exporter>=1.0.0b41->agent-framework-core->agent-framework) (3.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from tqdm>4->openai<2,>=1.99.0->agent-framework-core->agent-framework) (0.4.6)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from uvicorn>=0.31.1->mcp>=1.13->mcp[ws]>=1.13->agent-framework-core->agent-framework) (8.3.0)\n",
      "Requirement already satisfied: fastapi>=0.104.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from agent-framework-devui->agent-framework) (0.118.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.24.0->agent-framework-devui->agent-framework) (0.6.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.24.0->agent-framework-devui->agent-framework) (6.0.3)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from uvicorn[standard]>=0.24.0->agent-framework-devui->agent-framework) (1.1.0)\n",
      "Requirement already satisfied: mem0ai>=0.1.117 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from agent-framework-mem0->agent-framework) (1.0.0)\n",
      "Requirement already satisfied: posthog>=3.5.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from mem0ai>=0.1.117->agent-framework-mem0->agent-framework) (6.7.8)\n",
      "Requirement already satisfied: pytz>=2024.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from mem0ai>=0.1.117->agent-framework-mem0->agent-framework) (2025.2)\n",
      "Requirement already satisfied: qdrant-client>=1.9.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from mem0ai>=0.1.117->agent-framework-mem0->agent-framework) (1.15.1)\n",
      "Requirement already satisfied: sqlalchemy>=2.0.31 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from mem0ai>=0.1.117->agent-framework-mem0->agent-framework) (2.0.44)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from posthog>=3.5.0->mem0ai>=0.1.117->agent-framework-mem0->agent-framework) (2.9.0.post0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from posthog>=3.5.0->mem0ai>=0.1.117->agent-framework-mem0->agent-framework) (2.2.1)\n",
      "Requirement already satisfied: numpy>=2.1.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from qdrant-client>=1.9.1->mem0ai>=0.1.117->agent-framework-mem0->agent-framework) (2.3.3)\n",
      "Requirement already satisfied: h2<5,>=3 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from httpx[http2]>=0.20.0->qdrant-client>=1.9.1->mem0ai>=0.1.117->agent-framework-mem0->agent-framework) (4.3.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client>=1.9.1->mem0ai>=0.1.117->agent-framework-mem0->agent-framework) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client>=1.9.1->mem0ai>=0.1.117->agent-framework-mem0->agent-framework) (4.1.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from sqlalchemy>=2.0.31->mem0ai>=0.1.117->agent-framework-mem0->agent-framework) (3.2.4)\n",
      "Requirement already satisfied: redis>=6.4.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from agent-framework-redis->agent-framework) (6.4.0)\n",
      "Requirement already satisfied: redisvl>=0.8.2 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from agent-framework-redis->agent-framework) (0.10.0)\n",
      "Requirement already satisfied: jsonpath-ng>=1.5.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from redisvl>=0.8.2->agent-framework-redis->agent-framework) (1.7.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.4.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from redisvl>=0.8.2->agent-framework-redis->agent-framework) (0.5.3)\n",
      "Requirement already satisfied: python-ulid>=3.0.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from redisvl>=0.8.2->agent-framework-redis->agent-framework) (3.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.2 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from redisvl>=0.8.2->agent-framework-redis->agent-framework) (9.1.2)\n",
      "Requirement already satisfied: ply in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from jsonpath-ng>=1.5.0->redisvl>=0.8.2->agent-framework-redis->agent-framework) (3.11)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Ensure you have the latest version of the Azure AI Projects package\n",
    "# This is required for the MCP client to work properly with the Azure AI Foundry service if you want to run the AI Agent Service demo\n",
    "%pip install azure-ai-projects==1.0.0b12 agent-framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "### 1ï¸âƒ£ Verify the Azure CLI and the connected Azure subscription\n",
    "\n",
    "The following commands ensure that you have the latest version of the Azure CLI and that the Azure CLI is connected to your Azure subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸ \u001b[1;34mRunning: az account show \u001b[0m\n",
      "âœ… \u001b[1;32mRetrieved az account\u001b[0m âŒš 10:37:15.427472 [0m:3s]\n",
      "ğŸ‘‰ğŸ½ \u001b[1;34mCurrent user: lproux@microsoft.com\u001b[0m\n",
      "ğŸ‘‰ğŸ½ \u001b[1;34mTenant ID: 2b9d9f47-1fb6-400a-a438-39fe7d768649\u001b[0m\n",
      "ğŸ‘‰ğŸ½ \u001b[1;34mSubscription ID: d334f2cd-3efd-494e-9fd3-2470b1a13e4c\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "output = utils.run(\"az account show\", \"Retrieved az account\", \"Failed to get the current az account\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    current_user = output.json_data['user']['name']\n",
    "    tenant_id = output.json_data['tenantId']\n",
    "    subscription_id = output.json_data['id']\n",
    "\n",
    "    utils.print_info(f\"Current user: {current_user}\")\n",
    "    utils.print_info(f\"Tenant ID: {tenant_id}\")\n",
    "    utils.print_info(f\"Subscription ID: {subscription_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### 2ï¸âƒ£ Create deployment using ğŸ¦¾ Bicep\n",
    "\n",
    "This lab uses [Bicep](https://learn.microsoft.com/azure/azure-resource-manager/bicep/overview?tabs=bicep) to declarative define all the resources that will be deployed in the specified resource group. Change the parameters or the [main.bicep](main.bicep) directly to try different configurations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸ \u001b[1;34mRunning: az group show --name lab-model-context-protocol \u001b[0m\n",
      "ğŸ‘‰ğŸ½ \u001b[1;34mUsing existing resource group 'lab-model-context-protocol'\u001b[0m\n",
      "âš™ï¸ \u001b[1;34mRunning: az deployment group create --name model-context-protocol --resource-group lab-model-context-protocol --template-file main.bicep --parameters params.json \u001b[0m\n",
      "âœ… \u001b[1;32mDeployment 'model-context-protocol' succeeded\u001b[0m âŒš 10:40:08.485204 [2m:48s]\n"
     ]
    }
   ],
   "source": [
    "# Create the resource group if doesn't exist\n",
    "utils.create_resource_group(resource_group_name, resource_group_location)\n",
    "\n",
    "# Define the Bicep parameters\n",
    "bicep_parameters = {\n",
    "    \"$schema\": \"https://schema.management.azure.com/schemas/2019-04-01/deploymentParameters.json#\",\n",
    "    \"contentVersion\": \"1.0.0.0\",\n",
    "    \"parameters\": {\n",
    "        \"apimSku\": { \"value\": apim_sku },\n",
    "        \"aiServicesConfig\": { \"value\": aiservices_config },\n",
    "        \"modelsConfig\": { \"value\": models_config },\n",
    "        \"apimSubscriptionsConfig\": { \"value\": apim_subscriptions_config },\n",
    "        \"inferenceAPIPath\": { \"value\": inference_api_path },\n",
    "        \"inferenceAPIType\": { \"value\": inference_api_type },\n",
    "        \"foundryProjectName\": { \"value\": foundry_project_name },\n",
    "    }\n",
    "}\n",
    "\n",
    "# Write the parameters to the params.json file\n",
    "with open('params.json', 'w') as bicep_parameters_file:\n",
    "    bicep_parameters_file.write(json.dumps(bicep_parameters))\n",
    "\n",
    "# Run the deployment\n",
    "output = utils.run(f\"az deployment group create --name {deployment_name} --resource-group {resource_group_name} --template-file main.bicep --parameters params.json\",\n",
    "    f\"Deployment '{deployment_name}' succeeded\", f\"Deployment '{deployment_name}' failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### 3ï¸âƒ£ Get the deployment outputs\n",
    "\n",
    "Retrieve the required outputs from the Bicep deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸ \u001b[1;34mRunning: az deployment group show --name model-context-protocol -g lab-model-context-protocol \u001b[0m\n",
      "âœ… \u001b[1;32mRetrieved deployment: model-context-protocol\u001b[0m âŒš 10:40:13.573455 [0m:5s]\n",
      "ğŸ‘‰ğŸ½ \u001b[1;34mAI Foundry Project Endpoint: https://foundry1-3ilfnkpe2evck.services.ai.azure.com/api/projects/model-context-protocol-foundry1\u001b[0m\n",
      "ğŸ‘‰ğŸ½ \u001b[1;34mLog Analytics Id: 2c912e65-0d89-4116-9fda-00191d72d81c\u001b[0m\n",
      "ğŸ‘‰ğŸ½ \u001b[1;34mAPIM Resource Name: apim-3ilfnkpe2evck\u001b[0m\n",
      "ğŸ‘‰ğŸ½ \u001b[1;34mAPIM Service Id: /subscriptions/d334f2cd-3efd-494e-9fd3-2470b1a13e4c/resourceGroups/lab-model-context-protocol/providers/Microsoft.ApiManagement/service/apim-3ilfnkpe2evck\u001b[0m\n",
      "ğŸ‘‰ğŸ½ \u001b[1;34mAPIM API Gateway URL: https://apim-3ilfnkpe2evck.azure-api.net\u001b[0m\n",
      "ğŸ‘‰ğŸ½ \u001b[1;34mSubscription Name: subscription1\u001b[0m\n",
      "ğŸ‘‰ğŸ½ \u001b[1;34mSubscription Key: ****a052\u001b[0m\n",
      "ğŸ‘‰ğŸ½ \u001b[1;34mSubscription Name: subscription2\u001b[0m\n",
      "ğŸ‘‰ğŸ½ \u001b[1;34mSubscription Key: ****7658\u001b[0m\n",
      "ğŸ‘‰ğŸ½ \u001b[1;34mSubscription Name: subscription3\u001b[0m\n",
      "ğŸ‘‰ğŸ½ \u001b[1;34mSubscription Key: ****48be\u001b[0m\n",
      "ğŸ‘‰ğŸ½ \u001b[1;34mApplication Insights Name: insights-3ilfnkpe2evck\u001b[0m\n",
      "ğŸ‘‰ğŸ½ \u001b[1;34mContainer Registry Name: acr3ilfnkpe2evck\u001b[0m\n",
      "ğŸ‘‰ğŸ½ \u001b[1;34mWeather Container App Resource Name: aca-weather-3ilfnkpe2evck\u001b[0m\n",
      "ğŸ‘‰ğŸ½ \u001b[1;34mOncall Container App Resource Name: aca-oncall-3ilfnkpe2evck\u001b[0m\n",
      "ğŸ‘‰ğŸ½ \u001b[1;34mGitHub Container App Resource Name: aca-github-3ilfnkpe2evck\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Obtain all of the outputs from the deployment\n",
    "output = utils.run(f\"az deployment group show --name {deployment_name} -g {resource_group_name}\", f\"Retrieved deployment: {deployment_name}\", f\"Failed to retrieve deployment: {deployment_name}\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    ai_foundry_project_endpoint = utils.get_deployment_output(output, 'foundryProjectEndpoint', 'AI Foundry Project Endpoint')\n",
    "    log_analytics_id = utils.get_deployment_output(output, 'logAnalyticsWorkspaceId', 'Log Analytics Id')\n",
    "    apim_resource_name = utils.get_deployment_output(output, 'apimResourceName', 'APIM Resource Name')\n",
    "    apim_service_id = utils.get_deployment_output(output, 'apimServiceId', 'APIM Service Id')\n",
    "    apim_resource_gateway_url = utils.get_deployment_output(output, 'apimResourceGatewayURL', 'APIM API Gateway URL')\n",
    "    apim_subscriptions = json.loads(utils.get_deployment_output(output, 'apimSubscriptions').replace(\"\\'\", \"\\\"\"))\n",
    "    for subscription in apim_subscriptions:\n",
    "        subscription_name = subscription['name']\n",
    "        subscription_key = subscription['key']\n",
    "        utils.print_info(f\"Subscription Name: {subscription_name}\")\n",
    "        utils.print_info(f\"Subscription Key: ****{subscription_key[-4:]}\")\n",
    "    api_key = apim_subscriptions[0].get(\"key\") # default api key to the first subscription key\n",
    "    app_insights_name = utils.get_deployment_output(output, 'applicationInsightsName', 'Application Insights Name')\n",
    "    container_registry_name = utils.get_deployment_output(output, 'containerRegistryName', 'Container Registry Name')\n",
    "    weather_containerapp_resource_name = utils.get_deployment_output(output, 'weatherMCPServerContainerAppResourceName', 'Weather Container App Resource Name')\n",
    "    oncall_containerapp_resource_name = utils.get_deployment_output(output, 'oncallMCPServerContainerAppResourceName', 'Oncall Container App Resource Name')\n",
    "    github_containerapp_resource_name = utils.get_deployment_output(output, 'gitHubMCPServerContainerAppResourceName', 'GitHub Container App Resource Name')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "### 4ï¸âƒ£ Build and deploy the MCP Servers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸ \u001b[1;34mRunning: az acr build --image weather-mcp-server:v0.2 --resource-group lab-model-context-protocol --registry acr3ilfnkpe2evck --file ../../shared/mcp-servers/weather/http/Dockerfile ../../shared/mcp-servers/weather/http/. --no-logs \u001b[0m\n",
      "âœ… \u001b[1;32mWeather MCP Server image was successfully built\u001b[0m âŒš 10:41:24.435224 [1m:10s]\n",
      "âš™ï¸ \u001b[1;34mRunning: az containerapp update -n aca-weather-3ilfnkpe2evck -g lab-model-context-protocol --image \"acr3ilfnkpe2evck.azurecr.io/weather-mcp-server:v0.2\" \u001b[0m\n",
      "âœ… \u001b[1;32mWeather MCP Server deployment succeeded\u001b[0m âŒš 10:41:50.813990 [0m:26s]\n",
      "âš™ï¸ \u001b[1;34mRunning: az acr build --image oncall-mcp-server:v0.2 --resource-group lab-model-context-protocol --registry acr3ilfnkpe2evck --file ../../shared/mcp-servers/oncall/http/Dockerfile ../../shared/mcp-servers/oncall/http/. --no-logs \u001b[0m\n",
      "âœ… \u001b[1;32mOncall MCP Server image was successfully built\u001b[0m âŒš 10:43:02.784150 [1m:11s]\n",
      "âš™ï¸ \u001b[1;34mRunning: az containerapp update -n aca-oncall-3ilfnkpe2evck -g lab-model-context-protocol --image \"acr3ilfnkpe2evck.azurecr.io/oncall-mcp-server:v0.2\" \u001b[0m\n",
      "âœ… \u001b[1;32mOncall MCP Server deployment succeeded\u001b[0m âŒš 10:43:29.920402 [0m:27s]\n",
      "âš™ï¸ \u001b[1;34mRunning: az acr build --image github-mcp-server:v0.2 --resource-group lab-model-context-protocol --registry acr3ilfnkpe2evck --file ../../shared/mcp-servers/github/http/Dockerfile ../../shared/mcp-servers/github/http/. --no-logs \u001b[0m\n",
      "âœ… \u001b[1;32mGitHub MCP Server image was successfully built\u001b[0m âŒš 10:44:41.019862 [1m:11s]\n",
      "âš™ï¸ \u001b[1;34mRunning: az containerapp update -n aca-github-3ilfnkpe2evck -g lab-model-context-protocol --image \"acr3ilfnkpe2evck.azurecr.io/github-mcp-server:v0.2\" \u001b[0m\n",
      "âœ… \u001b[1;32mGitHub MCP Server deployment succeeded\u001b[0m âŒš 10:45:05.059501 [0m:24s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<utils.Output at 0x22bb0467920>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build = build + 1 # increment the build number\n",
    "\n",
    "utils.run(f\"az acr build --image {weather_mcp_server_image}:v0.{build} --resource-group {resource_group_name} --registry {container_registry_name} --file {weather_mcp_server_src}/Dockerfile {weather_mcp_server_src}/. --no-logs\", \n",
    "          \"Weather MCP Server image was successfully built\", \"Failed to build the Weather MCP Server image\")\n",
    "utils.run(f'az containerapp update -n {weather_containerapp_resource_name} -g {resource_group_name} --image \"{container_registry_name}.azurecr.io/{weather_mcp_server_image}:v0.{build}\"', \n",
    "          \"Weather MCP Server deployment succeeded\", \"Weather MCP Server deployment failed\")\n",
    "\n",
    "utils.run(f\"az acr build --image {oncall_mcp_server_image}:v0.{build} --resource-group {resource_group_name} --registry {container_registry_name} --file {oncall_mcp_server_src}/Dockerfile {oncall_mcp_server_src}/. --no-logs\", \n",
    "          \"Oncall MCP Server image was successfully built\", \"Failed to build the Oncall MCP Server image\")\n",
    "utils.run(f'az containerapp update -n {oncall_containerapp_resource_name} -g {resource_group_name} --image \"{container_registry_name}.azurecr.io/{oncall_mcp_server_image}:v0.{build}\"', \n",
    "          \"Oncall MCP Server deployment succeeded\", \"Oncall MCP Server deployment failed\")\n",
    "\n",
    "utils.run(f\"az acr build --image {github_mcp_server_image}:v0.{build} --resource-group {resource_group_name} --registry {container_registry_name} --file {github_mcp_server_src}/Dockerfile {github_mcp_server_src}/. --no-logs\", \n",
    "          \"GitHub MCP Server image was successfully built\", \"Failed to build the GitHub MCP Server image\")\n",
    "utils.run(f'az containerapp update -n {github_containerapp_resource_name} -g {resource_group_name} --image \"{container_registry_name}.azurecr.io/{github_mcp_server_image}:v0.{build}\"', \n",
    "          \"GitHub MCP Server deployment succeeded\", \"GitHub MCP Server deployment failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='testconnection'></a>\n",
    "### ğŸ§ª Test the connection to the MCP servers and List Tools\n",
    "\n",
    "ğŸ’¡ To integrate MCP servers in VS Code, use the MCP server URL  `../mcp ` for configuration in GitHub Copilot Agent Mode\n",
    "\n",
    "If the notebook is run again, the JWT validation that gets applied to the policies later on must first be removed. Otherwise, the next calls below will fail as auth is not yet expected to be in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸ \u001b[1;34mRunning: az account get-access-token --resource https://management.azure.com/ \u001b[0m\n",
      "âœ… \u001b[1;32mSuccessfully obtained access token\u001b[0m âŒš 10:45:26.534939 [0m:21s]\n",
      "Updating the API policy...\n",
      "Response status: \u001b[1;31m400 - Bad Request\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "policy_xml_file = \"src/github/apim-api/no-auth-client-policy.xml\"\n",
    "\n",
    "with open(policy_xml_file, 'r') as file:\n",
    "    policy_xml = file.read()\n",
    "    utils.update_api_operation_policy(subscription_id, resource_group_name, apim_resource_name, \"github-mcp-tools\", \"mcp\", policy_xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Connected to server https://apim-3ilfnkpe2evck.azure-api.net/weather\n",
      "âš™ï¸ Tools:\n",
      "  - get_cities\n",
      "     Input Schema: {'properties': {'country': {'type': 'string'}}, 'required': ['country'], 'type': 'object'}\n",
      "  - get_weather\n",
      "     Input Schema: {'properties': {'city': {'type': 'string'}}, 'required': ['city'], 'type': 'object'}\n",
      "âœ… Connected to server https://apim-3ilfnkpe2evck.azure-api.net/oncall\n",
      "âš™ï¸ Tools:\n",
      "  - get_oncall_list\n",
      "     Input Schema: {'properties': {}, 'type': 'object'}\n",
      "âœ… Connected to server https://apim-3ilfnkpe2evck.azure-api.net/github\n",
      "âš™ï¸ Tools:\n",
      "  - authorize_github\n",
      "     Input Schema: {'properties': {}, 'type': 'object'}\n",
      "  - get_user\n",
      "     Input Schema: {'properties': {}, 'type': 'object'}\n",
      "  - get_issues\n",
      "     Input Schema: {'properties': {'username': {'type': 'string'}, 'repo': {'type': 'string'}}, 'required': ['username', 'repo'], 'type': 'object'}\n",
      "âœ… Connection closed\n"
     ]
    }
   ],
   "source": [
    "import os, json, asyncio, time, requests\n",
    "from mcp import ClientSession\n",
    "from mcp.client.sse import sse_client\n",
    "from mcp.client.streamable_http import streamablehttp_client\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def list_tools(server_url, authorization_header = None):\n",
    "    headers = {\"Authorization\": authorization_header} if authorization_header else None\n",
    "    streams = None\n",
    "    session = None\n",
    "    tools = []\n",
    "    try:\n",
    "        streams_ctx = streamablehttp_client(server_url, headers)\n",
    "        streams = await streams_ctx.__aenter__()\n",
    "        session_ctx = ClientSession(streams[0], streams[1])\n",
    "        session = await session_ctx.__aenter__()\n",
    "        await session.initialize()\n",
    "        response = await session.list_tools()\n",
    "        tools = response.tools\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {e}\")\n",
    "    finally:\n",
    "        # Ensure session and streams are closed if they were opened\n",
    "        if session is not None:\n",
    "            await session_ctx.__aexit__(None, None, None) # type: ignore\n",
    "        if streams is not None:\n",
    "            await streams_ctx.__aexit__(None, None, None) # type: ignore\n",
    "    if tools:\n",
    "        print(f\"âœ… Connected to server {server_url}\")\n",
    "        print(\"âš™ï¸ Tools:\")\n",
    "        for tool in tools:\n",
    "            print(f\"  - {tool.name}\")\n",
    "            print(f\"     Input Schema: {tool.inputSchema}\")\n",
    "\n",
    "try:    \n",
    "    asyncio.run(list_tools(f\"{apim_resource_gateway_url}/weather\"))\n",
    "    asyncio.run(list_tools(f\"{apim_resource_gateway_url}/oncall\"))\n",
    "    asyncio.run(list_tools(f\"{apim_resource_gateway_url}/github\"))\n",
    "\n",
    "finally:\n",
    "    print(f\"âœ… Connection closed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='inspector'></a>\n",
    "### ğŸ§ª (optional) Use the [MCP Inspector](https://modelcontextprotocol.io/docs/tools/inspector) for testing and debugging the MCP servers\n",
    "\n",
    "#### Execute the following steps:\n",
    "1. Execute `npx @modelcontextprotocol/inspector` in a terminal\n",
    "2. Open the provided URL in a browser\n",
    "3. Set the transport type as SSE\n",
    "4. Provide the MCP server url and click connect\n",
    "5. Select the \"Tools\" tab to see and run the available tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='functioncalling'></a>\n",
    "### ğŸ§ª Run an OpenAI completion with MCP tools\n",
    "\n",
    "ğŸ‘‰ Both the calls to Azure OpenAI and the MCP tools will be managed through Azure API Management.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Connected to server https://apim-3ilfnkpe2evck.azure-api.net/weather\n",
      "â–¶ï¸ Step 1: start a completion to identify the appropriate functions to invoke based on the prompt\n",
      "â–¶ï¸ Step 2: call the functions\n",
      "   Function Name: get_weather Function Args: {'city': 'Lisbon'}\n",
      "   Function response: [TextContent(type='text', text=\"{'city': 'Lisbon', 'condition': 'Snowy', 'temperature': 24.15, 'humidity': 23.78}\", annotations=None, meta=None)]\n",
      "â–¶ï¸ Step 3: finish with a completion to anwser the user prompt using the function response\n",
      "ğŸ’¬ The current weather in Lisbon is snowy, with a temperature of 24.15Â°C and a humidity level of 23.78%.\n",
      "âœ… Connected to server https://apim-3ilfnkpe2evck.azure-api.net/oncall\n",
      "â–¶ï¸ Step 1: start a completion to identify the appropriate functions to invoke based on the prompt\n",
      "â–¶ï¸ Step 2: call the functions\n",
      "   Function Name: get_oncall_list Function Args: {}\n",
      "   Function response: [TextContent(type='text', text=\"[{'id': 1, 'firstName': 'Julia', 'lastName': 'Smith', 'alias': 'jsmith', 'status': 'on', 'timezone': 'PST'}, {'id': 2, 'firstName': 'Alex', 'lastName': 'Johnson', 'alias': 'ajohnson', 'status': 'on', 'timezone': 'EST'}, {'id': 3, 'firstName': 'Maria', 'lastName': 'Garcia', 'alias': 'mgarcia', 'status': 'off', 'timezone': 'CET'}, {'id': 4, 'firstName': 'David', 'lastName': 'Wilson', 'alias': 'dwilson', 'status': 'on', 'timezone': 'CET'}, {'id': 5, 'firstName': 'Sarah', 'lastName': 'Chen', 'alias': 'schen', 'status': 'on', 'timezone': 'CET'}, {'id': 6, 'firstName': 'Michael', 'lastName': 'Brown', 'alias': 'mbrown', 'status': 'off', 'timezone': 'PST'}, {'id': 7, 'firstName': 'Emma', 'lastName': 'Taylor', 'alias': 'etaylor', 'status': 'on', 'timezone': 'PST'}]\", annotations=None, meta=None)]\n",
      "â–¶ï¸ Step 3: finish with a completion to anwser the user prompt using the function response\n",
      "ğŸ’¬ The following individuals are on call in CET today:\n",
      "\n",
      "1. **David Wilson** (Alias: dwilson)\n",
      "2. **Sarah Chen** (Alias: schen)\n",
      "\n",
      "Maria Garcia (Alias: mgarcia) is off today.\n"
     ]
    }
   ],
   "source": [
    "# type: ignore\n",
    "import json, asyncio\n",
    "from mcp import ClientSession\n",
    "from mcp.client.streamable_http import streamablehttp_client\n",
    "from openai import AzureOpenAI\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def call_tool(mcp_session, function_name, function_args):\n",
    "    try:\n",
    "        func_response = await mcp_session.call_tool(function_name, function_args)\n",
    "        func_response_content = func_response.content\n",
    "    except Exception as e:\n",
    "        func_response_content = json.dumps({\"error\": str(e)})\n",
    "    return str(func_response_content)\n",
    "\n",
    "async def run_completion_with_tools(server_url, prompt):\n",
    "    streams = None\n",
    "    session = None\n",
    "    try:\n",
    "        streams_ctx = streamablehttp_client(server_url)\n",
    "        streams = await streams_ctx.__aenter__()\n",
    "        session_ctx = ClientSession(streams[0], streams[1])\n",
    "        session = await session_ctx.__aenter__()\n",
    "        await session.initialize()\n",
    "        response = await session.list_tools()\n",
    "        tools = response.tools\n",
    "        print(f\"âœ… Connected to server {server_url}\")\n",
    "        openai_tools = [{\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": tool.name,\n",
    "                    \"parameters\": tool.inputSchema\n",
    "                },\n",
    "            } for tool in tools]\n",
    "\n",
    "        # Step 1: send the conversation and available functions to the model\n",
    "        print(\"â–¶ï¸ Step 1: start a completion to identify the appropriate functions to invoke based on the prompt\")\n",
    "        client = AzureOpenAI(\n",
    "            azure_endpoint=f\"{apim_resource_gateway_url}/{inference_api_path}\",\n",
    "            api_key=api_key,\n",
    "            api_version=inference_api_version\n",
    "        )            \n",
    "        messages = [ {\"role\": \"user\", \"content\": prompt} ]\n",
    "        response = client.chat.completions.create(\n",
    "            model=models_config[0]['name'],\n",
    "            messages=messages,\n",
    "            tools=openai_tools,\n",
    "        )\n",
    "        response_message = response.choices[0].message\n",
    "        tool_calls = response_message.tool_calls\n",
    "        if tool_calls:\n",
    "            # Step 2: call the function\n",
    "            messages.append(response_message)  # extend conversation with assistant's reply\n",
    "            # send the info for each function call and function response to the model\n",
    "            print(\"â–¶ï¸ Step 2: call the functions\")\n",
    "            for tool_call in tool_calls:\n",
    "                function_name = tool_call.function.name\n",
    "                function_args = json.loads(tool_call.function.arguments)\n",
    "                print(f\"   Function Name: {function_name} Function Args: {function_args}\")\n",
    "\n",
    "                function_response = await call_tool(session, function_name, function_args)\n",
    "                # Add the tool response\n",
    "                print(f\"   Function response: {function_response}\")\n",
    "                messages.append(\n",
    "                    {\n",
    "                        \"tool_call_id\": tool_call.id,\n",
    "                        \"role\": \"tool\",\n",
    "                        \"name\": function_name,\n",
    "                        \"content\": function_response,\n",
    "                    }\n",
    "                )  # extend conversation with function response\n",
    "            print(\"â–¶ï¸ Step 3: finish with a completion to anwser the user prompt using the function response\")\n",
    "            second_response = client.chat.completions.create(\n",
    "                model=models_config[0]['name'],\n",
    "                messages=messages,\n",
    "            )  # get a new response from the model where it can see the function response\n",
    "            print(\"ğŸ’¬\", second_response.choices[0].message.content)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {e}\")\n",
    "    finally:\n",
    "        if session is not None:\n",
    "            await session_ctx.__aexit__(None, None, None)\n",
    "        if streams is not None:\n",
    "            await streams_ctx.__aexit__(None, None, None)\n",
    "\n",
    "asyncio.run(run_completion_with_tools(f\"{apim_resource_gateway_url}/weather\", \"What's the current weather in Lisbon?\"))\n",
    "asyncio.run(run_completion_with_tools(f\"{apim_resource_gateway_url}/oncall\", \"Who's oncall in CET today?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Microsoft Agent Framework'></a>\n",
    "### ğŸ§ª Execute an [Agent Framework Agent using MCP Tools](https://learn.microsoft.com/en-us/agent-framework/user-guide/overview) via Azure API Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Basic Azure Chat Client Agent Example ===\n",
      "=== Non-streaming Response Example ===\n",
      "User: What's the weather like in Seattle?\n",
      "Result: The weather in Seattle is currently rainy, with a temperature of 20.38Â°C and humidity at 26.44%.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "from agent_framework import MCPStreamableHTTPTool\n",
    "from pydantic import Field\n",
    "\n",
    "async def non_streaming_example() -> None:\n",
    "    \"\"\"Example of non-streaming response (get the complete result at once).\"\"\"\n",
    "    print(\"=== Non-streaming Response Example ===\")\n",
    "\n",
    "    async with (\n",
    "        MCPStreamableHTTPTool(\n",
    "            name=\"weather\",\n",
    "            url=f\"{apim_resource_gateway_url}/weather\",\n",
    "            headers={\"Authorization\": \"Bearer token\"},\n",
    "            description=\"Weather Plugin\",\n",
    "        )\n",
    "    ) as mcp_tool:\n",
    "        chatClient = AzureOpenAIChatClient(\n",
    "            deployment_name=models_config[0]['name'],\n",
    "            endpoint=f\"{apim_resource_gateway_url}/{inference_api_path}\",\n",
    "            api_key=api_key,\n",
    "            api_version=inference_api_version,\n",
    "        )\n",
    "        agent = chatClient.create_agent(\n",
    "            instructions=\"You are a helpful weather agent.\",\n",
    "            tools=[mcp_tool],\n",
    "            # deployment_name=models_config[0]['name'],\n",
    "        )\n",
    "\n",
    "        query = \"What's the weather like in Seattle?\"\n",
    "        print(f\"User: {query}\")\n",
    "        result = await agent.run(query)\n",
    "        print(f\"Result: {result}\\n\")\n",
    "\n",
    "\n",
    "async def main() -> None:\n",
    "    print(\"=== Basic Azure Chat Client Agent Example ===\")\n",
    "    await non_streaming_example()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Azure AI Agents'></a>\n",
    "### ğŸ§ª Execute an [Azure AI Foundry Agent using MCP Tools](https://learn.microsoft.com/en-us/azure/ai-foundry/agents/how-to/tools/model-context-protocol) via Azure API Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‰ Created agent, agent ID: asst_ThLQTEaslyUFYiTdE1o08U5y\n",
      "âœ¨ MCP Server: weather at https://apim-3ilfnkpe2evck.azure-api.net/weather\n",
      "ğŸ§µ Created thread, thread ID: thread_pQthOmOsyb29UelXtPwklDgP\n",
      "ğŸ’¬ Created message, message ID: msg_U6dsdub37dYC4IY2QgZxAcfd\n",
      "â³ Run status: RunStatus.IN_PROGRESS\n",
      "â³ Run status: RunStatus.IN_PROGRESS\n",
      "â³ Run status: RunStatus.COMPLETED\n",
      "\n",
      "ğŸ”„ Run step: step_2drtQ7GtrJ38t2CDiNFXAOUE, status: RunStepStatus.COMPLETED, type: RunStepType.MESSAGE_CREATION\n",
      "ğŸ”„ Run step: step_NGazDlphlS4bHd6uIix7SXTJ, status: RunStepStatus.COMPLETED, type: RunStepType.TOOL_CALLS\n",
      "ğŸ› ï¸ Tool call details:\n",
      "{\n",
      "     \"id\": \"call_OSEohSgUE8mBPrOGmWem8Hfa\",\n",
      "     \"type\": \"mcp\",\n",
      "     \"arguments\": \"{\\\"city\\\":\\\"London\\\"}\",\n",
      "     \"name\": \"get_weather\",\n",
      "     \"server_label\": \"weather\",\n",
      "     \"output\": \"{'city': 'London', 'condition': 'Cloudy', 'temperature': -0.05, 'humidity': 44.09}\"\n",
      "}\n",
      "ğŸ”„ Run step: step_LsciCXGKXVZBYuM3iETCv0mg, status: RunStepStatus.COMPLETED, type: RunStepType.TOOL_CALLS\n",
      "ğŸ› ï¸ Tool call details:\n",
      "{\n",
      "     \"id\": \"call_VUYbC6paf03GqfxdC4JlaTgZ\",\n",
      "     \"type\": \"mcp\",\n",
      "     \"arguments\": \"{\\\"city\\\":\\\"Cairo\\\"}\",\n",
      "     \"name\": \"get_weather\",\n",
      "     \"server_label\": \"weather\",\n",
      "     \"output\": \"{'city': 'Cairo', 'condition': 'Cloudy', 'temperature': 11.97, 'humidity': 90.18}\"\n",
      "}\n",
      "ğŸ”„ Run step: step_0kMKJqQxAgIh63VyBkN2PHCK, status: RunStepStatus.COMPLETED, type: RunStepType.TOOL_CALLS\n",
      "ğŸ› ï¸ Tool call details:\n",
      "{\n",
      "     \"id\": \"call_PV0XUavQK1d1KkQ84DEpcMWW\",\n",
      "     \"type\": \"mcp\",\n",
      "     \"arguments\": \"{\\\"city\\\":\\\"Lisbon\\\"}\",\n",
      "     \"name\": \"get_weather\",\n",
      "     \"server_label\": \"weather\",\n",
      "     \"output\": \"{'city': 'Lisbon', 'condition': 'Rainy', 'temperature': -6.96, 'humidity': 74.92}\"\n",
      "}\n",
      "\n",
      "ğŸ“œ Messages in the thread:\n",
      "ğŸ—¨ï¸ MessageRole.USER: What's the weather in Lisbon, Cairo and London?\n",
      "ğŸ—¨ï¸ MessageRole.AGENT: Here's the weather in these three fabulous destinationsâ€”prepare to be overwhelmed:\n",
      "\n",
      "**Lisbon:** Oh joy, it's rainy with a lovely temperature of -6.96Â°C. Bring your umbrella and maybe a winter coat? Sounds like perfect beach weatherâ€”if you enjoy hypothermia, that is. Humidity's sitting at a cozy 74.92%, so enjoy that dampness!\n",
      "\n",
      "**Cairo:** Now thatâ€™s a treat! Itâ€™s a balmy 11.97Â°C with a lovely cloudy dispositionâ€”perfect for an existential crisis but maybe not for sunbathing. The humidity is at a staggering 90.18%, so you're basically swimming through the air there.\n",
      "\n",
      "**London:** Surprise! More clouds await you in London, with a refreshing temperature of -0.05Â°C. Don't forget to add layers, because who doesnâ€™t want to feel like a walking marshmallow? Humidity is a delicate 44.09%, which is just dry enough to keep your hopes of seeing the sun alive.\n",
      "\n",
      "Enjoy your weather adventures! ğŸŒ§ï¸â˜ï¸ğŸ§¤\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.agents.models import ListSortOrder, MessageTextContent, McpTool, RequiredMcpToolCall, SubmitToolApprovalAction, ToolApproval\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "project_client = AIProjectClient(endpoint=ai_foundry_project_endpoint,\n",
    "            credential=DefaultAzureCredential())\n",
    "agents_client = project_client.agents\n",
    "\n",
    "# MCP tool definition\n",
    "mcp_tool = McpTool(\n",
    "    server_label=\"weather\",\n",
    "    server_url=f\"{apim_resource_gateway_url}/weather\",\n",
    "    #allowed_tools=[],          # Optional initial allowâ€‘list\n",
    ")\n",
    "\n",
    "#mcp_tool.update_headers({\"Authorization\": f\"Bearer {apim_subscription_key}\"})\n",
    "\n",
    "prompt = \"What's the weather in Lisbon, Cairo and London?\"\n",
    "\n",
    "# Agent creation\n",
    "agent = agents_client.create_agent(\n",
    "    model=str(models_config[0].get('name')),\n",
    "    name=\"agent-mcp\",\n",
    "    instructions=\"You are a sarcastic AI agent. Use the tools provided to answer the user's questions. Be sure to cite your sources and answer in details.\",\n",
    "    tools=mcp_tool.definitions\n",
    ")\n",
    "print(f\"ğŸ‰ Created agent, agent ID: {agent.id}\")\n",
    "print(f\"âœ¨ MCP Server: {mcp_tool.server_label} at {mcp_tool.server_url}\")\n",
    "\n",
    "# Thread creation\n",
    "thread = agents_client.threads.create()\n",
    "print(f\"ğŸ§µ Created thread, thread ID: {thread.id}\")\n",
    "\n",
    "# Message creation\n",
    "message = agents_client.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=prompt,\n",
    ")\n",
    "print(f\"ğŸ’¬ Created message, message ID: {message.id}\")\n",
    "\n",
    "mcp_tool.set_approval_mode(\"never\")          # Disable human approval\n",
    "\n",
    "# Run\n",
    "run = agents_client.runs.create(thread_id=thread.id, agent_id=agent.id, tool_resources=mcp_tool.resources)\n",
    "while run.status in [\"queued\", \"in_progress\", \"requires_action\"]:\n",
    "    time.sleep(2)\n",
    "    run = agents_client.runs.get(thread_id=thread.id, run_id=run.id)\n",
    "    print(f\"â³ Run status: {run.status}\")\n",
    "if run.status == \"failed\":\n",
    "    print(f\"âŒ Run error: {run.last_error}\")\n",
    "\n",
    "# Get Run steps\n",
    "run_steps = agents_client.run_steps.list(thread_id=thread.id, run_id=run.id)\n",
    "print()\n",
    "\n",
    "for step in run_steps:\n",
    "    print(f\"ğŸ”„ Run step: {step.id}, status: {step.status}, type: {step.type}\")\n",
    "    if step.type == \"tool_calls\":\n",
    "        print(f\"ğŸ› ï¸ Tool call details:\")\n",
    "        for tool_call in step.step_details.tool_calls:\n",
    "            print(json.dumps(tool_call.as_dict(), indent=5))\n",
    "\n",
    "# Get the messages in the thread\n",
    "print(\"\\nğŸ“œ Messages in the thread:\")\n",
    "messages = agents_client.messages.list(thread_id=thread.id, order=ListSortOrder.ASCENDING)\n",
    "\n",
    "for item in messages:\n",
    "    last_message_content = item.content[-1]\n",
    "    if isinstance(last_message_content, MessageTextContent):\n",
    "        print(f\"ğŸ—¨ï¸ {item.role}: {last_message_content.text.value}\")\n",
    "\n",
    "# Clean up resources\n",
    "# agents_client.delete_agent(agent.id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sk'></a>\n",
    "### ğŸ§ª Execute a [Semantic Kernel Agent using MCP Tools](https://devblogs.microsoft.com/semantic-kernel/integrating-model-context-protocol-tools-with-semantic-kernel-a-step-by-step-guide/) via Azure API Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# User: What's the current weather in Paris?\n",
      "# IssueAgent: The current weather in Paris is snowy, with a temperature of -9.7Â°C and humidity at 27.59%. \n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from semantic_kernel.agents import ChatCompletionAgent, ChatHistoryAgentThread\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.connectors.mcp import MCPStreamableHttpPlugin\n",
    "\n",
    "user_input = \"What's the current weather in Paris?\"\n",
    "\n",
    "async def main():\n",
    "    # 1. Create the agent\n",
    "    async with MCPStreamableHttpPlugin(\n",
    "        name=\"Weather\",\n",
    "        url=f\"{apim_resource_gateway_url}/weather\",\n",
    "        description=\"Weather Plugin\",\n",
    "    ) as weather_plugin:\n",
    "        agent = ChatCompletionAgent(\n",
    "            service=AzureChatCompletion(\n",
    "                endpoint=f\"{apim_resource_gateway_url}/{inference_api_path}\",\n",
    "                api_key=api_key,\n",
    "                api_version=inference_api_version,                \n",
    "                deployment_name=models_config[0]['name']  # Use the first model from the models_config\n",
    "            ),\n",
    "            name=\"IssueAgent\",\n",
    "            instructions=\"Answer questions about the Weather.\",\n",
    "            plugins=[weather_plugin],\n",
    "        )\n",
    "\n",
    "        thread: ChatHistoryAgentThread | None = None\n",
    "\n",
    "        print(f\"# User: {user_input}\")\n",
    "        # 2. Invoke the agent for a response\n",
    "        response = await agent.get_response(messages=user_input, thread=thread)\n",
    "        print(f\"# {response.name}: {response} \")\n",
    "        thread = response.thread # type: ignore\n",
    "\n",
    "        # 3. Cleanup: Clear the thread\n",
    "        await thread.delete() if thread else None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='autogen'></a>\n",
    "### ğŸ§ª Execute an [AutoGen Agent using MCP Tools](https://microsoft.github.io/autogen/stable/reference/python/autogen_ext.tools.mcp.html) via Azure API Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "What's the weather in Lisbon, Cairo and London?\n",
      "---------- ToolCallRequestEvent (weather) ----------\n",
      "[FunctionCall(id='call_XR8cBG5QOBGnIBc8I6gcna4v', arguments='{\"city\": \"Lisbon\"}', name='get_weather'), FunctionCall(id='call_FIpFxv4sxRax5b1cjHNLUXCT', arguments='{\"city\": \"Cairo\"}', name='get_weather'), FunctionCall(id='call_AjnxFriWGFWXC8gqCOX6CKVX', arguments='{\"city\": \"London\"}', name='get_weather')]\n",
      "---------- ToolCallExecutionEvent (weather) ----------\n",
      "[FunctionExecutionResult(content='[{\"type\": \"text\", \"text\": \"{\\'city\\': \\'Lisbon\\', \\'condition\\': \\'Sunny\\', \\'temperature\\': 14.25, \\'humidity\\': 56.53}\", \"annotations\": null}]', name='get_weather', call_id='call_XR8cBG5QOBGnIBc8I6gcna4v', is_error=False), FunctionExecutionResult(content='[{\"type\": \"text\", \"text\": \"{\\'city\\': \\'Cairo\\', \\'condition\\': \\'Snowy\\', \\'temperature\\': 15.87, \\'humidity\\': 75.2}\", \"annotations\": null}]', name='get_weather', call_id='call_FIpFxv4sxRax5b1cjHNLUXCT', is_error=False), FunctionExecutionResult(content='[{\"type\": \"text\", \"text\": \"{\\'city\\': \\'London\\', \\'condition\\': \\'Snowy\\', \\'temperature\\': 28.57, \\'humidity\\': 25.45}\", \"annotations\": null}]', name='get_weather', call_id='call_AjnxFriWGFWXC8gqCOX6CKVX', is_error=False)]\n",
      "---------- TextMessage (weather) ----------\n",
      "Here's the current weather for each city:\n",
      "\n",
      "- **Lisbon**: Sunny, with a temperature of 14.25Â°C and humidity at 56.53%.\n",
      "- **Cairo**: Snowy, with a temperature of 15.87Â°C and humidity at 75.2%.\n",
      "- **London**: Snowy, with a temperature of 28.57Â°C and humidity at 25.45%.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "from autogen_ext.tools.mcp import mcp_server_tools, StreamableHttpServerParams\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_core import CancellationToken\n",
    "\n",
    "async def run_agent(url, prompt) -> None:\n",
    "    # Create server params for the remote MCP service\n",
    "    server_params = StreamableHttpServerParams(\n",
    "        url=url,\n",
    "        headers={\"Content-Type\": \"application/json\"},\n",
    "        timeout=30,  # Connection timeout in seconds\n",
    "    )\n",
    "\n",
    "    # Get all available tools\n",
    "    tools = await mcp_server_tools(server_params)\n",
    "\n",
    "    # Create an agent that can use the translation tool\n",
    "    model_client = AzureOpenAIChatCompletionClient(azure_deployment=models_config[0]['name'], model=models_config[0]['name'],\n",
    "                azure_endpoint=f\"{apim_resource_gateway_url}/{inference_api_path}\",\n",
    "                api_key=api_key,\n",
    "                api_version=inference_api_version\n",
    "    )\n",
    "    agent = AssistantAgent(\n",
    "        name=\"weather\",\n",
    "        model_client=model_client,\n",
    "        reflect_on_tool_use=True,\n",
    "        tools=tools, # type: ignore\n",
    "        system_message=\"You are a helpful assistant.\",\n",
    "    )\n",
    "    await Console(\n",
    "        agent.run_stream(task=prompt)\n",
    "    )\n",
    "\n",
    "asyncio.run(run_agent(f\"{apim_resource_gateway_url}/weather\", \"What's the weather in Lisbon, Cairo and London?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='githubconfig'></a>\n",
    "### 5ï¸âƒ£ Create a GitHub OAuth app and configure the credential provider\n",
    "\n",
    "#### Step 1 - [Register the application in GitHub](https://learn.microsoft.com/en-us/azure/api-management/credentials-how-to-github#step-1-register-an-application-in-github)\n",
    "\n",
    "ğŸ‘‰ Use the Authorization callback URL that is provided below  \n",
    "ğŸ‘‰ Copy the Client ID and Client secret\n",
    "\n",
    "#### Step 2 - [Configure the credential provider in API Management](https://learn.microsoft.com/en-us/azure/api-management/credentials-how-to-github#step-2-configure-a-credential-provider-in-api-management)\n",
    "\n",
    "ğŸ‘‰ You just need to update the Client ID and Client secret on the existing `github` credential manager provider  \n",
    "ğŸ‘‰ Disregard the remaining steps outlined in the documentation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='servicenowconfig'></a>\n",
    "### 6ï¸âƒ£ Create a ServiceNow OAuth app and configure the credential provider\n",
    "\n",
    "â„¹ï¸ If you do not wish to use ServiceNow, please skip these steps\n",
    "\n",
    "#### Step 1 - [Register the application in ServiceNow](https://www.servicenow.com/docs/bundle/yokohama-application-development/page/build/pipelines-and-deployments/task/create-oauth-api-endpoints-for-external-clients.html)\n",
    "\n",
    "ğŸ‘‰ Use the Authorization callback URL that is provided bellow  \n",
    "ğŸ‘‰ Copy the Client ID and Client secret\n",
    "\n",
    "#### Step 2 - Configure the credential provider in API Management\n",
    "\n",
    "ğŸ‘‰ You just need to update the Client ID and Client secret on the existing `servicenonw` credential manager provider  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authorization callback URL: https://authorization-manager.consent.azure-apim.net/redirect/apim/apim-3ilfnkpe2evck\n"
     ]
    }
   ],
   "source": [
    "print(f\"Authorization callback URL: https://authorization-manager.consent.azure-apim.net/redirect/apim/{apim_resource_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='githubtest'></a>\n",
    "### ğŸ§ª Run the GitHub MCP Server with VS Code to retrieve GitHub Issues\n",
    "\n",
    "1. [Configure the GitHub MCP Server in VS Code](https://code.visualstudio.com/docs/copilot/chat/mcp-servers#_add-an-mcp-server) \n",
    "2. Type in the chat the following prompt: `Please list all the issues assigned to me in the GitHub repository {your-repo-name} under the organization {your-org-name}`\n",
    "3. The agent will suggest running the `authorize_github` tool.\n",
    "4. Once the user accepts to run the tool, the agent will call the `authorize_github` and provide an URL to proceed with the authentication and authorization on GitHub.\n",
    "5. After the user confirms that it's done, the agent will suggest running the `get_user` tool.\n",
    "6. Once the user accepts to run the `get_user` tool, the agent will call the tool, return user information as context and suggest running the `get_issues` tool.\n",
    "7. Once the user accepts to run the `get_issues` tool, the agent will provide the list of issues from the given repo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='servicenowtest'></a>\n",
    "### ğŸ§ª Run the ServiceNow MCP Server with VS Code to manage ServiceNow incidents\n",
    "\n",
    "1. [Configure the ServiceNow MCP Server in VS Code](https://code.visualstudio.com/docs/copilot/chat/mcp-servers#_add-an-mcp-server) \n",
    "2. Type in the chat the following prompt: `Please list my servicenow incidents`\n",
    "3. The agent will suggest running the `authorize_servicenow` tool.\n",
    "4. Once the user accepts to run the tool, the agent will call the `authorize_servicenow` and provide an URL to proceed with the authentication and authorization on ServiceNow.\n",
    "5. After the user confirms that it's done, the agent will suggest running the `list_incidents` tool.\n",
    "6. Once the user accepts to run the `list_incidents` tool, the agent will provide the list of incidents for the connected ServiceNow instance.\n",
    "7. You can also retrieve details for a specific incident or create a new one.\n",
    "\n",
    "âœ¨ Type in the chat the following prompt: `Create a ServiceNow incident for each GitHub issue`. To combine GitHub and ServiceNow MCP Servers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='validate-jwt'></a>\n",
    "### ğŸ” (Optional) Implement [authorization policies](src/github/apim-api/auth-client-policy.xml) on MCP endpoints\n",
    "\n",
    "ğŸ‘‰ To ensure the enforcement of valid security tokens, we apply the `validate-jwt` policy to the `/sse` and `/messages` endpoints. The following code snippet demonstrates the application of this policy to GitHub API operations for token validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_xml_file = \"src/github/apim-api/auth-client-policy.xml\"\n",
    "\n",
    "with open(policy_xml_file, 'r') as file:\n",
    "    policy_xml = file.read()\n",
    "    utils.update_api_operation_policy(subscription_id, resource_group_name, apim_resource_name, \"github-mcp\", \"sse\", policy_xml)\n",
    "    utils.update_api_operation_policy(subscription_id, resource_group_name, apim_resource_name, \"github-mcp\", \"messages\", policy_xml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='unauthorizedtest'></a>\n",
    "### ğŸ§ª Test the authorization **WITHOUT** a valid token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unauthenticated call should fail with 401 Unauthorized\n",
    "import requests\n",
    "utils.print_info(\"Calling sse endpoint WITHOUT authorization...\")\n",
    "response = requests.get(f\"{apim_resource_gateway_url}/github/sse\", headers={\"Content-Type\": \"application/json\"})\n",
    "if response.status_code == 401:\n",
    "    utils.print_ok(\"Received 401 Unauthorized as expected\")\n",
    "elif response.status_code == 200:\n",
    "    utils.print_error(\"Call succeeded. Double check that validate-jwt policy has been deployed to sse endpoint\")\n",
    "else:\n",
    "    utils.print_error(f\"Unexpected status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='authorizedtest'></a>\n",
    "### ğŸ§ª Test the authorization **WITH** a valid token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# Authenticated call should succeed\n",
    "utils.print_info(\"Calling sse endpoint WITH authorization...\")\n",
    "output = utils.run(\"az account get-access-token --resource \\\"https://azure-api.net/authorization-manager\\\"\")\n",
    "if output.success and output.json_data:\n",
    "    access_token = output.json_data.get('accessToken')\n",
    "    response = requests.get(f\"{apim_resource_gateway_url}/github/sse\", stream=True,\n",
    "                            headers={\"Content-Type\": \"application/json\", \"Authorization\": \"Bearer \" + str(access_token)})\n",
    "    if response.status_code == 200:\n",
    "        utils.print_ok(\"Received status code 200 as expected\")\n",
    "    else:\n",
    "        utils.print_error(f\"Unexpected status code: {response.status_code}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "### ğŸ—‘ï¸ Clean up resources\n",
    "\n",
    "When you're finished with the lab, you should remove all your deployed resources from Azure to avoid extra charges and keep your Azure subscription uncluttered.\n",
    "Use the [clean-up-resources notebook](clean-up-resources.ipynb) for that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
