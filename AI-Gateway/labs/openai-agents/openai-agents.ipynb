{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIM ‚ù§Ô∏è AI Agents\n",
    "\n",
    "## OpenAI Agents Lab\n",
    "\n",
    "![flow](../../images/openai-agents.gif)\n",
    "\n",
    "Playground to try the [OpenAI Agents](https://openai.github.io/openai-agents-python/) with Azure OpenAI models and API based tools through Azure API Management. This enables limitless opportunities for AI agents while maintaining control through Azure API Management!\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- [Python 3.12 or later version](https://www.python.org/) installed\n",
    "- [VS Code](https://code.visualstudio.com/) installed with the [Jupyter notebook extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) enabled\n",
    "- [Python environment](https://code.visualstudio.com/docs/python/environments#_creating-environments) with the [requirements.txt](../../requirements.txt) or run `pip install -r requirements.txt` in your terminal\n",
    "- [An Azure Subscription](https://azure.microsoft.com/free/) with [Contributor](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#contributor) + [RBAC Administrator](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#role-based-access-control-administrator) or [Owner](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#owner) roles\n",
    "- [Azure CLI](https://learn.microsoft.com/cli/azure/install-azure-cli) installed and [Signed into your Azure subscription](https://learn.microsoft.com/cli/azure/authenticate-azure-cli-interactively)\n",
    "\n",
    "‚ñ∂Ô∏è Click `Run All` to execute all steps sequentially, or execute them `Step by Step`...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "### 0Ô∏è‚É£ Initialize notebook variables\n",
    "\n",
    "- Resources will be suffixed by a unique string based on your subscription id.\n",
    "- Adjust the location parameters according your preferences and on the [product availability by Azure region.](https://azure.microsoft.com/explore/global-infrastructure/products-by-region/?cdn=disable&products=cognitive-services,api-management) \n",
    "- Adjust the OpenAI model and version according the [availability by region.](https://learn.microsoft.com/azure/ai-services/openai/concepts/models) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ \u001b[1;32mNotebook initialized\u001b[0m ‚åö 10:36:25.979872 \n"
     ]
    }
   ],
   "source": [
    "import os, sys, json\n",
    "sys.path.insert(1, '../../shared')  # add the shared directory to the Python path\n",
    "import utils\n",
    "\n",
    "deployment_name = os.path.basename(os.path.dirname(globals()['__vsc_ipynb_file__']))\n",
    "resource_group_name = f\"lab-{deployment_name}\" # change the name to match your naming style\n",
    "resource_group_location = \"uksouth\"\n",
    "\n",
    "aiservices_config = [{\"name\": \"foundry1\", \"location\": \"uksouth\"}]\n",
    "\n",
    "models_config = [{\"name\": \"gpt-4.1-mini\", \"publisher\": \"OpenAI\", \"version\": \"2025-04-14\", \"sku\": \"GlobalStandard\", \"capacity\": 20}]\n",
    "\n",
    "apim_sku = 'Basicv2'\n",
    "apim_subscriptions_config = [{\"name\": \"subscription1\", \"displayName\": \"Subscription 1\"}]\n",
    "\n",
    "inference_api_path = \"inference\"  # path to the inference API in the APIM service\n",
    "inference_api_type = \"AzureOpenAI\"  # options: AzureOpenAI, AzureAI, OpenAI, PassThrough\n",
    "inference_api_version = \"2024-05-01-preview\"\n",
    "foundry_project_name = deployment_name\n",
    "\n",
    "utils.print_ok('Notebook initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "### 1Ô∏è‚É£ Verify the Azure CLI and the connected Azure subscription\n",
    "\n",
    "The following commands ensure that you have the latest version of the Azure CLI and that the Azure CLI is connected to your Azure subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az account show \u001b[0m\n",
      "‚úÖ \u001b[1;32mRetrieved az account\u001b[0m ‚åö 10:36:29.753473 [0m:3s]\n",
      "üëâüèΩ \u001b[1;34mCurrent user: lproux@microsoft.com\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mTenant ID: 2b9d9f47-1fb6-400a-a438-39fe7d768649\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mSubscription ID: d334f2cd-3efd-494e-9fd3-2470b1a13e4c\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "output = utils.run(\"az account show\", \"Retrieved az account\", \"Failed to get the current az account\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    current_user = output.json_data['user']['name']\n",
    "    tenant_id = output.json_data['tenantId']\n",
    "    subscription_id = output.json_data['id']\n",
    "\n",
    "    utils.print_info(f\"Current user: {current_user}\")\n",
    "    utils.print_info(f\"Tenant ID: {tenant_id}\")\n",
    "    utils.print_info(f\"Subscription ID: {subscription_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### 2Ô∏è‚É£ Create deployment using ü¶æ Bicep\n",
    "\n",
    "This lab uses [Bicep](https://learn.microsoft.com/azure/azure-resource-manager/bicep/overview?tabs=bicep) to declarative define all the resources that will be deployed in the specified resource group. Change the parameters or the [main.bicep](main.bicep) directly to try different configurations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az group show --name lab-openai-agents \u001b[0m\n",
      "üëâüèΩ \u001b[1;34mResource group lab-openai-agents does not yet exist. Creating the resource group now...\u001b[0m\n",
      "‚öôÔ∏è \u001b[1;34mRunning: az group create --name lab-openai-agents --location uksouth --tags source=ai-gateway \u001b[0m\n",
      "‚úÖ \u001b[1;32mResource group 'lab-openai-agents' created\u001b[0m ‚åö 10:36:40.148368 [0m:4s]\n",
      "‚öôÔ∏è \u001b[1;34mRunning: az deployment group create --name openai-agents --resource-group lab-openai-agents --template-file main.bicep --parameters params.json \u001b[0m\n",
      "‚úÖ \u001b[1;32mDeployment 'openai-agents' succeeded\u001b[0m ‚åö 11:06:48.864962 [30m:8s]\n"
     ]
    }
   ],
   "source": [
    "# Create the resource group if doesn't exist\n",
    "utils.create_resource_group(resource_group_name, resource_group_location)\n",
    "\n",
    "# Define the Bicep parameters\n",
    "bicep_parameters = {\n",
    "    \"$schema\": \"https://schema.management.azure.com/schemas/2019-04-01/deploymentParameters.json#\",\n",
    "    \"contentVersion\": \"1.0.0.0\",\n",
    "    \"parameters\": {\n",
    "        \"apimSku\": { \"value\": apim_sku },\n",
    "        \"aiServicesConfig\": { \"value\": aiservices_config },\n",
    "        \"modelsConfig\": { \"value\": models_config },\n",
    "        \"apimSubscriptionsConfig\": { \"value\": apim_subscriptions_config },\n",
    "        \"inferenceAPIPath\": { \"value\": inference_api_path },\n",
    "        \"inferenceAPIType\": { \"value\": inference_api_type },\n",
    "        \"foundryProjectName\": { \"value\": foundry_project_name }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Write the parameters to the params.json file\n",
    "with open('params.json', 'w') as bicep_parameters_file:\n",
    "    bicep_parameters_file.write(json.dumps(bicep_parameters))\n",
    "\n",
    "# Run the deployment\n",
    "output = utils.run(f\"az deployment group create --name {deployment_name} --resource-group {resource_group_name} --template-file main.bicep --parameters params.json\",\n",
    "    f\"Deployment '{deployment_name}' succeeded\", f\"Deployment '{deployment_name}' failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### 3Ô∏è‚É£ Get the deployment outputs\n",
    "\n",
    "Retrieve the required outputs from the Bicep deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az deployment group show --name openai-agents -g lab-openai-agents \u001b[0m\n",
      "‚úÖ \u001b[1;32mRetrieved deployment: openai-agents\u001b[0m ‚åö 11:06:54.488145 [0m:5s]\n",
      "üëâüèΩ \u001b[1;34mLog Analytics Id: 49884bbf-0f01-4177-9045-4b656d924336\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mAPIM Service Id: /subscriptions/d334f2cd-3efd-494e-9fd3-2470b1a13e4c/resourceGroups/lab-openai-agents/providers/Microsoft.ApiManagement/service/apim-5qrhe3oqnpr6m\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mAPIM API Gateway URL: https://apim-5qrhe3oqnpr6m.azure-api.net\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mSubscription Name: subscription1\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mSubscription Key: ****19e3\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mApplication Insights Name: insights-5qrhe3oqnpr6m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Obtain all of the outputs from the deployment\n",
    "output = utils.run(f\"az deployment group show --name {deployment_name} -g {resource_group_name}\", f\"Retrieved deployment: {deployment_name}\", f\"Failed to retrieve deployment: {deployment_name}\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    log_analytics_id = utils.get_deployment_output(output, 'logAnalyticsWorkspaceId', 'Log Analytics Id')\n",
    "    apim_service_id = utils.get_deployment_output(output, 'apimServiceId', 'APIM Service Id')\n",
    "    apim_resource_gateway_url = utils.get_deployment_output(output, 'apimResourceGatewayURL', 'APIM API Gateway URL')\n",
    "    apim_subscriptions = json.loads(utils.get_deployment_output(output, 'apimSubscriptions').replace(\"\\'\", \"\\\"\"))\n",
    "    for subscription in apim_subscriptions:\n",
    "        subscription_name = subscription['name']\n",
    "        subscription_key = subscription['key']\n",
    "        utils.print_info(f\"Subscription Name: {subscription_name}\")\n",
    "        utils.print_info(f\"Subscription Key: ****{subscription_key[-4:]}\")\n",
    "    api_key = apim_subscriptions[0].get(\"key\") # default api key to the first subscription key\n",
    "    app_insights_name = utils.get_deployment_output(output, 'applicationInsightsName', 'Application Insights Name')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Install OpenAI Agents SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai-agents\n",
      "  Downloading openai_agents-0.4.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting griffe<2,>=1.5.6 (from openai-agents)\n",
      "  Downloading griffe-1.14.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: mcp<2,>=1.11.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openai-agents) (1.16.0)\n",
      "Collecting openai<3,>=2.2 (from openai-agents)\n",
      "  Downloading openai-2.6.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: pydantic<3,>=2.10 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openai-agents) (2.11.10)\n",
      "Requirement already satisfied: requests<3,>=2.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openai-agents) (2.32.5)\n",
      "Collecting types-requests<3,>=2.0 (from openai-agents)\n",
      "  Downloading types_requests-2.32.4.20250913-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.12.2 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openai-agents) (4.15.0)\n",
      "Requirement already satisfied: colorama>=0.4 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from griffe<2,>=1.5.6->openai-agents) (0.4.6)\n",
      "Requirement already satisfied: anyio>=4.5 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from mcp<2,>=1.11.0->openai-agents) (4.11.0)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from mcp<2,>=1.11.0->openai-agents) (0.4.1)\n",
      "Requirement already satisfied: httpx>=0.27.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from mcp<2,>=1.11.0->openai-agents) (0.28.1)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from mcp<2,>=1.11.0->openai-agents) (4.25.1)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from mcp<2,>=1.11.0->openai-agents) (2.11.0)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from mcp<2,>=1.11.0->openai-agents) (0.0.20)\n",
      "Requirement already satisfied: pywin32>=310 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from mcp<2,>=1.11.0->openai-agents) (311)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from mcp<2,>=1.11.0->openai-agents) (3.0.2)\n",
      "Requirement already satisfied: starlette>=0.27 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from mcp<2,>=1.11.0->openai-agents) (0.48.0)\n",
      "Requirement already satisfied: uvicorn>=0.31.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from mcp<2,>=1.11.0->openai-agents) (0.37.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openai<3,>=2.2->openai-agents) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openai<3,>=2.2->openai-agents) (0.11.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openai<3,>=2.2->openai-agents) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openai<3,>=2.2->openai-agents) (4.67.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from anyio>=4.5->mcp<2,>=1.11.0->openai-agents) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from httpx>=0.27.1->mcp<2,>=1.11.0->openai-agents) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from httpx>=0.27.1->mcp<2,>=1.11.0->openai-agents) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.1->mcp<2,>=1.11.0->openai-agents) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from pydantic<3,>=2.10->openai-agents) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from pydantic<3,>=2.10->openai-agents) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from pydantic<3,>=2.10->openai-agents) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from requests<3,>=2.0->openai-agents) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from requests<3,>=2.0->openai-agents) (2.5.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (0.27.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from pydantic-settings>=2.5.2->mcp<2,>=1.11.0->openai-agents) (1.1.1)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from uvicorn>=0.31.1->mcp<2,>=1.11.0->openai-agents) (8.3.0)\n",
      "Downloading openai_agents-0.4.1-py3-none-any.whl (215 kB)\n",
      "Downloading griffe-1.14.0-py3-none-any.whl (144 kB)\n",
      "Downloading openai-2.6.0-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 8.4 MB/s  0:00:00\n",
      "Downloading types_requests-2.32.4.20250913-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: types-requests, griffe, openai, openai-agents\n",
      "\n",
      "   ---------- ----------------------------- 1/4 [griffe]\n",
      "   ---------- ----------------------------- 1/4 [griffe]\n",
      "   ---------- ----------------------------- 1/4 [griffe]\n",
      "   ---------- ----------------------------- 1/4 [griffe]\n",
      "  Attempting uninstall: openai\n",
      "   ---------- ----------------------------- 1/4 [griffe]\n",
      "    Found existing installation: openai 1.109.1\n",
      "   ---------- ----------------------------- 1/4 [griffe]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "    Uninstalling openai-1.109.1:\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "      Successfully uninstalled openai-1.109.1\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   -------------------- ------------------- 2/4 [openai]\n",
      "   ------------------------------ --------- 3/4 [openai-agents]\n",
      "   ------------------------------ --------- 3/4 [openai-agents]\n",
      "   ------------------------------ --------- 3/4 [openai-agents]\n",
      "   ------------------------------ --------- 3/4 [openai-agents]\n",
      "   ------------------------------ --------- 3/4 [openai-agents]\n",
      "   ------------------------------ --------- 3/4 [openai-agents]\n",
      "   ------------------------------ --------- 3/4 [openai-agents]\n",
      "   ------------------------------ --------- 3/4 [openai-agents]\n",
      "   ---------------------------------------- 4/4 [openai-agents]\n",
      "\n",
      "Successfully installed griffe-1.14.0 openai-2.6.0 openai-agents-0.4.1 types-requests-2.32.4.20250913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "agent-framework-core 1.0.0b251016 requires openai<2,>=1.99.0, but you have openai 2.6.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "! pip install openai-agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sdk'></a>\n",
    "### üß™ Test the API using the OpenAI SDK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨  Oh sure, let me just check my magical internal clock that‚Äôs perfectly synced with your timezone. Or, you know, you could just look at your phone or computer like a normal person. But no, you needed me to do it.\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=f\"{apim_resource_gateway_url}/{inference_api_path}\",\n",
    "    api_key=api_key,\n",
    "    api_version=inference_api_version\n",
    ")\n",
    "response = client.chat.completions.create(model=models_config[0]['name'], messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a sarcastic, unhelpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": \"Can you tell me the time, please?\"}\n",
    "])\n",
    "print(\"üí¨ \",response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='basic'></a>\n",
    "### üß™ Basic test with the Agents SDK\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ Oh sure, let me just reach into my imaginary pocket and grab a clock for you. Or, you know, you could look at your phone, computer, microwave, or literally anything with a screen. But hey, here‚Äôs my answer: it‚Äôs ‚Äútime to learn how to check the time yourself.‚Äù You're welcome!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[non-fatal] Tracing client error 401: {\n",
      "  \"error\": {\n",
      "    \"message\": \"Incorrect API key provided: bb272f3a********************19e3. You can find your API key at https://platform.openai.com/account/api-keys.\",\n",
      "    \"type\": \"invalid_request_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": \"invalid_api_key\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from openai import AsyncAzureOpenAI\n",
    "from agents import Agent, Runner, set_default_openai_client, set_default_openai_api, set_tracing_disabled\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "client = AsyncAzureOpenAI(azure_endpoint=f\"{apim_resource_gateway_url}/{inference_api_path}\",\n",
    "                            api_key=api_key,\n",
    "                            api_version=inference_api_version)\n",
    "set_default_openai_client(client)\n",
    "set_default_openai_api(\"chat_completions\")\n",
    "agent = Agent(name=\"Sarcastic Assistant\", instructions=\"You are a sarcastic, unhelpful assistant.\", model=models_config[0]['name'])\n",
    "\n",
    "result = Runner.run_sync(agent, \"Can you tell me the time, please?\")\n",
    "print(\"üí¨\", result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='handoffs'></a>\n",
    "### üß™ Handoffs example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ ¬°Hola! Estoy bien, gracias. ¬øY t√∫, c√≥mo est√°s? ¬øEn qu√© puedo ayudarte hoy?\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent, Runner\n",
    "import asyncio\n",
    "\n",
    "spanish_agent = Agent(\n",
    "    name=\"Spanish agent\",\n",
    "    instructions=\"You only speak Spanish.\",\n",
    "    model=models_config[0]['name']\n",
    ")\n",
    "\n",
    "english_agent = Agent(\n",
    "    name=\"English agent\",\n",
    "    instructions=\"You only speak English\",\n",
    "    model=models_config[0]['name']\n",
    ")\n",
    "\n",
    "triage_agent = Agent(\n",
    "    name=\"Triage agent\",\n",
    "    instructions=\"Handoff to the appropriate agent based on the language of the request.\",\n",
    "    handoffs=[spanish_agent, english_agent],\n",
    "    model=models_config[0]['name']\n",
    ")\n",
    "\n",
    "async def main():\n",
    "    client = AsyncAzureOpenAI(azure_endpoint=f\"{apim_resource_gateway_url}/{inference_api_path}\",\n",
    "                              api_key=api_key,\n",
    "                                api_version=inference_api_version)\n",
    "    set_default_openai_client(client)\n",
    "    set_default_openai_api(\"chat_completions\")\n",
    "    set_tracing_disabled(True)\n",
    "    \n",
    "    result = await Runner.run(triage_agent, input=\"Hola, ¬øc√≥mo est√°s?\")\n",
    "    print(\"üí¨\", result.final_output)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='weatherapi'></a>\n",
    "### üß™ Run agent with Weather API from Azure API Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ Here is a summary of the temperatures in Seattle and three sister cities in Europe:\n",
      "\n",
      "- Seattle: Approximately 18.5¬∞C (converted from 65.3¬∞F), overcast.\n",
      "- London: 24.5¬∞C, clear skies.\n",
      "- Paris: 5.4¬∞C, clear skies.\n",
      "- Berlin: 28.7¬∞C, partly cloudy.\n",
      "\n",
      "If you need more detailed information about the weather conditions in these cities, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "import asyncio, requests\n",
    "from agents import Agent, Runner, function_tool\n",
    "\n",
    "@function_tool\n",
    "def get_weather(city: str) -> str:\n",
    "    response = requests.get(f\"{apim_resource_gateway_url}/weatherservice/weather?city={city}\", headers = {'api-key':api_key})\n",
    "    return response.text\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"weather agent\",\n",
    "    instructions=\"You are a helpful assistant that provides wheather information. Always provide the temperature in Celsius.\",\n",
    "    tools=[get_weather],\n",
    "    model=models_config[0]['name']\n",
    ")\n",
    "\n",
    "async def main():\n",
    "    client = AsyncAzureOpenAI(azure_endpoint=f\"{apim_resource_gateway_url}/{inference_api_path}\",\n",
    "                              api_key=api_key,\n",
    "                              api_version=inference_api_version)\n",
    "    set_default_openai_client(client)\n",
    "    set_default_openai_api(\"chat_completions\")\n",
    "    set_tracing_disabled(True)\n",
    "\n",
    "    result = await Runner.run(agent, input=\"Return a summary of the temperature in Seattle and 3 other sister cities in Europe?\")\n",
    "    print(\"üí¨\", result.final_output)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='logicapp'></a>\n",
    "### üß™ Run agent with OpenAPI Backend and Logic Apps workflow\n",
    "\n",
    "‚öôÔ∏è **Tools**:\n",
    "- Get Product Catalog - OpenAPI Backend mocked with an APIM policy.\n",
    "- Place Order - A Logic Apps workflow that processes orders with a maximum of five items.\n",
    "\n",
    "‚ú® **Expected Behavior**:\n",
    "- The agent receives a user request to order 11 smartphones.\n",
    "- The agent calls the product catalog API to retrieve the product SKU and available stock quantity.\n",
    "- If the order quantity exceeds available stock, the agent will respond that the order cannot be processed due to insufficient stock.\n",
    "- If stock is available, the agent will initiate the order workflow, which will fail because the quantity exceeds the maximum limit of five items.\n",
    "- As the agent was instructed to recover from errors, it will place multiple orders, each with a quantity below the maximum limit, ensuring the total equals the desired order quantity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ I have placed the order for one smartphone for you and one for each of your ten friends, totaling eleven smartphones. The order was split into three separate orders due to quantity limits. Is there anything else you would like to order?\n"
     ]
    }
   ],
   "source": [
    "import asyncio, requests\n",
    "from agents import Agent, Runner, function_tool\n",
    "\n",
    "@function_tool\n",
    "def get_product_catalog(category: str) -> str:\n",
    "    response = requests.get(f\"{apim_resource_gateway_url}/catalogservice/product?category={category}\", headers = {'api-key':api_key})\n",
    "    return response.text\n",
    "\n",
    "@function_tool\n",
    "def place_order(sku: str, quantity: int) -> str:\n",
    "    response = requests.post(f\"{apim_resource_gateway_url}/orderservice/PlaceOrder/paths/invoke\", headers = {'api-key':api_key}, json={\"sku\": sku, \"quantity\": quantity})\n",
    "    return response.text\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"sales agent\",\n",
    "    instructions=\"You are a helpful sales assistant that helps users order products. Recover from errors if any and proceed with multiple orders if needed without user confirmation to fulfill the total order.\",\n",
    "    tools=[get_product_catalog, place_order],\n",
    "    model=models_config[0]['name']\n",
    ")\n",
    "\n",
    "async def main():\n",
    "    client = AsyncAzureOpenAI(azure_endpoint=f\"{apim_resource_gateway_url}/{inference_api_path}\",\n",
    "                              api_key=api_key,\n",
    "                              api_version=inference_api_version)\n",
    "    set_default_openai_client(client)\n",
    "    set_default_openai_api(\"chat_completions\")\n",
    "    set_tracing_disabled(True)\n",
    "\n",
    "    result = await Runner.run(agent, input=\"Please order one smartphone for me and one for each of my ten friends.\")\n",
    "    print(\"üí¨\", result.final_output)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='kql'></a>\n",
    "### üîç Analyze Application Insights custom metrics with a KQL query\n",
    "\n",
    "With this query you can get the custom metrics that were emitted by Azure APIM. Note that it may take a few minutes for data to become available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az monitor app-insights query --app insights-5qrhe3oqnpr6m -g lab-openai-agents --analytics-query \"customMetrics | where name == 'Total Tokens' | where timestamp >= ago(1h) | extend parsedCustomDimensions = parse_json(customDimensions) | extend apimSubscription = tostring(parsedCustomDimensions.['Subscription ID']) | summarize TotalValue = sum(value) by apimSubscription, bin(timestamp, 1m) | order by timestamp asc\" \u001b[0m\n",
      "‚úÖ \u001b[1;32mApp Insights query succeeded\u001b[0m ‚åö 13:42:12.321513 [1m:21s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "apimSubscription",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "timestamp",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "TotalValue",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "5b8d3168-40b8-4bdf-ac74-842227393b3a",
       "rows": [],
       "shape": {
        "columns": 3,
        "rows": 0
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apimSubscription</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>TotalValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [apimSubscription, timestamp, TotalValue]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "query = \"\\\"\" + \"customMetrics \\\n",
    "| where name == 'Total Tokens' \\\n",
    "| where timestamp >= ago(1h) \\\n",
    "| extend parsedCustomDimensions = parse_json(customDimensions) \\\n",
    "| extend apimSubscription = tostring(parsedCustomDimensions.['Subscription ID']) \\\n",
    "| summarize TotalValue = sum(value) by apimSubscription, bin(timestamp, 1m) \\\n",
    "| order by timestamp asc\" + \"\\\"\"\n",
    "\n",
    "output = utils.run(f\"az monitor app-insights query --app {app_insights_name} -g {resource_group_name} --analytics-query {query}\",\n",
    "    f\"App Insights query succeeded\", f\"App Insights query  failed\")\n",
    "\n",
    "table = output.json_data['tables'][0]\n",
    "df = pd.DataFrame(table.get(\"rows\"), columns = [col.get(\"name\") for col in table.get('columns')])\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp']).dt.strftime('%H:%M')\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='plot'></a>\n",
    "### üîç Plot the custom metrics results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data to plot\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = [15, 7]\n",
    "if df.empty:\n",
    "    print(\"No data to plot\")\n",
    "else:\n",
    "    df_pivot = df.pivot(index='timestamp', columns='apimSubscription', values='TotalValue')\n",
    "    ax = df_pivot.plot(kind='bar', stacked=True)\n",
    "    plt.title('Total token usage over time by APIM Subscription')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Tokens')\n",
    "    plt.legend(title='APIM Subscription')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "### üóëÔ∏è Clean up resources\n",
    "\n",
    "When you're finished with the lab, you should remove all your deployed resources from Azure to avoid extra charges and keep your Azure subscription uncluttered.\n",
    "Use the [clean-up-resources notebook](clean-up-resources.ipynb) for that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
