{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIM ‚ù§Ô∏è OpenAI\n",
    "\n",
    "## Azure OpenAI Realtime Audio lab\n",
    "![flow](../../images/realtime-audio.gif)\n",
    "\n",
    "Playground to try the APIM integration with the [Azure OpenAI Realtime API](https://learn.microsoft.com/en-us/azure/ai-services/openai/realtime-audio-reference) for text and audio.\n",
    "\n",
    "### Result\n",
    "![result](result.png)\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- [Python 3.12 or later version](https://www.python.org/) installed\n",
    "- [VS Code](https://code.visualstudio.com/) installed with the [Jupyter notebook extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) enabled\n",
    "- [Python environment](https://code.visualstudio.com/docs/python/environments#_creating-environments) with the [requirements.txt](../../requirements.txt) or run `pip install -r requirements.txt` in your terminal\n",
    "- [An Azure Subscription](https://azure.microsoft.com/free/) with [Contributor](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#contributor) + [RBAC Administrator](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#role-based-access-control-administrator) or [Owner](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#owner) roles\n",
    "- [Azure CLI](https://learn.microsoft.com/cli/azure/install-azure-cli) installed and [Signed into your Azure subscription](https://learn.microsoft.com/cli/azure/authenticate-azure-cli-interactively)\n",
    "\n",
    "‚ñ∂Ô∏è Click `Run All` to execute all steps sequentially, or execute them `Step by Step`...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "### 0Ô∏è‚É£ Initialize notebook variables\n",
    "\n",
    "- Resources will be suffixed by a unique string based on your subscription id.\n",
    "- Adjust the location parameters according your preferences and on the [product availability by Azure region.](https://azure.microsoft.com/explore/global-infrastructure/products-by-region/?cdn=disable&products=cognitive-services,api-management)\n",
    "- Adjust the OpenAI model and version according the [availability by region.](https://learn.microsoft.com/azure/ai-services/openai/concepts/models) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ \u001b[1;32mNotebook initialized\u001b[0m ‚åö 10:04:48.548094 \n"
     ]
    }
   ],
   "source": [
    "import os, sys, json\n",
    "sys.path.insert(1, '../../shared')  # add the shared directory to the Python path\n",
    "import utils\n",
    "\n",
    "deployment_name = os.path.basename(os.path.dirname(globals()['__vsc_ipynb_file__']))\n",
    "resource_group_name = f\"lab-{deployment_name}\" # change the name to match your naming style\n",
    "resource_group_location = \"eastus2\"\n",
    "\n",
    "aiservices_config = [{\"name\": \"foundry1\", \"location\": \"eastus2\"}]\n",
    "\n",
    "models_config = [{\"name\": \"gpt-realtime\", \"publisher\": \"OpenAI\", \"version\": \"2025-08-28\", \"sku\": \"GlobalStandard\", \"capacity\": 10}]\n",
    "\n",
    "apim_sku = 'Basicv2'\n",
    "apim_subscriptions_config = [{\"name\": \"subscription1\", \"displayName\": \"Subscription 1\"}]\n",
    "\n",
    "inference_api_path = 'inference'  # path to the inference API in the APIM service\n",
    "inference_api_type = \"websocket\"  \n",
    "inference_api_version = \"2024-10-01-preview\"\n",
    "foundry_project_name = deployment_name\n",
    "\n",
    "utils.print_ok('Notebook initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "### 1Ô∏è‚É£ Verify the Azure CLI and the connected Azure subscription\n",
    "\n",
    "The following commands ensure that you have the latest version of the Azure CLI and that the Azure CLI is connected to your Azure subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az account show \u001b[0m\n",
      "‚úÖ \u001b[1;32mRetrieved az account\u001b[0m ‚åö 10:04:50.982281 [0m:2s]\n",
      "üëâüèΩ \u001b[1;34mCurrent user: lproux@microsoft.com\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mTenant ID: 2b9d9f47-1fb6-400a-a438-39fe7d768649\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mSubscription ID: d334f2cd-3efd-494e-9fd3-2470b1a13e4c\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "output = utils.run(\"az account show\", \"Retrieved az account\", \"Failed to get the current az account\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    current_user = output.json_data['user']['name']\n",
    "    tenant_id = output.json_data['tenantId']\n",
    "    subscription_id = output.json_data['id']\n",
    "\n",
    "    utils.print_info(f\"Current user: {current_user}\")\n",
    "    utils.print_info(f\"Tenant ID: {tenant_id}\")\n",
    "    utils.print_info(f\"Subscription ID: {subscription_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### 2Ô∏è‚É£ Create deployment using ü¶æ Bicep\n",
    "\n",
    "This lab uses [Bicep](https://learn.microsoft.com/azure/azure-resource-manager/bicep/overview?tabs=bicep) to declarative define all the resources that will be deployed in the specified resource group. Change the parameters or the [main.bicep](main.bicep) directly to try different configurations.\n",
    "\n",
    "`openAIModelCapacity` is set intentionally low to `6` (6k tokens per minute) to trigger the retry logic in the load balancer (transparent to the user) as well as the priority failover from priority 1 to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az group show --name lab-realtime-audio \u001b[0m\n",
      "üëâüèΩ \u001b[1;34mResource group lab-realtime-audio does not yet exist. Creating the resource group now...\u001b[0m\n",
      "‚öôÔ∏è \u001b[1;34mRunning: az group create --name lab-realtime-audio --location eastus2 --tags source=ai-gateway \u001b[0m\n",
      "‚úÖ \u001b[1;32mResource group 'lab-realtime-audio' created\u001b[0m ‚åö 10:05:02.730050 [0m:5s]\n",
      "‚öôÔ∏è \u001b[1;34mRunning: az deployment group create --name realtime-audio --resource-group lab-realtime-audio --template-file main.bicep --parameters params.json \u001b[0m\n",
      "‚úÖ \u001b[1;32mDeployment 'realtime-audio' succeeded\u001b[0m ‚åö 10:08:23.672788 [3m:20s]\n"
     ]
    }
   ],
   "source": [
    "# Create the resource group if doesn't exist\n",
    "utils.create_resource_group(resource_group_name, resource_group_location)\n",
    "\n",
    "# Define the Bicep parameters\n",
    "bicep_parameters = {\n",
    "    \"$schema\": \"https://schema.management.azure.com/schemas/2019-04-01/deploymentParameters.json#\",\n",
    "    \"contentVersion\": \"1.0.0.0\",\n",
    "    \"parameters\": {\n",
    "        \"apimSku\": { \"value\": apim_sku },\n",
    "        \"aiServicesConfig\": { \"value\": aiservices_config },\n",
    "        \"modelsConfig\": { \"value\": models_config },\n",
    "        \"apimSubscriptionsConfig\": { \"value\": apim_subscriptions_config },\n",
    "        \"inferenceAPIPath\": { \"value\": inference_api_path },\n",
    "        \"inferenceAPIType\": { \"value\": inference_api_type },\n",
    "        \"foundryProjectName\": { \"value\": foundry_project_name }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Write the parameters to the params.json file\n",
    "with open('params.json', 'w') as bicep_parameters_file:\n",
    "    bicep_parameters_file.write(json.dumps(bicep_parameters))\n",
    "\n",
    "# Run the deployment\n",
    "output = utils.run(f\"az deployment group create --name {deployment_name} --resource-group {resource_group_name} --template-file main.bicep --parameters params.json\",\n",
    "    f\"Deployment '{deployment_name}' succeeded\", f\"Deployment '{deployment_name}' failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### 3Ô∏è‚É£ Get the deployment outputs\n",
    "\n",
    "Retrieve the required outputs from the Bicep deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az deployment group show --name realtime-audio -g lab-realtime-audio \u001b[0m\n",
      "‚úÖ \u001b[1;32mRetrieved deployment: realtime-audio\u001b[0m ‚åö 10:08:28.935587 [0m:5s]\n",
      "üëâüèΩ \u001b[1;34mLog Analytics Id: 9d8f293f-341b-420b-addb-949653a124e3\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mAPIM Service Id: /subscriptions/d334f2cd-3efd-494e-9fd3-2470b1a13e4c/resourceGroups/lab-realtime-audio/providers/Microsoft.ApiManagement/service/apim-isdgntznknl52\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mAPIM API Gateway URL: https://apim-isdgntznknl52.azure-api.net\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mSubscription Name: subscription1\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mSubscription Key: ****a24c\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Obtain all of the outputs from the deployment\n",
    "output = utils.run(f\"az deployment group show --name {deployment_name} -g {resource_group_name}\", f\"Retrieved deployment: {deployment_name}\", f\"Failed to retrieve deployment: {deployment_name}\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    log_analytics_id = utils.get_deployment_output(output, 'logAnalyticsWorkspaceId', 'Log Analytics Id')\n",
    "    apim_service_id = utils.get_deployment_output(output, 'apimServiceId', 'APIM Service Id')\n",
    "    apim_resource_gateway_url = utils.get_deployment_output(output, 'apimResourceGatewayURL', 'APIM API Gateway URL')\n",
    "    apim_subscriptions = json.loads(utils.get_deployment_output(output, 'apimSubscriptions').replace(\"\\'\", \"\\\"\"))\n",
    "    for subscription in apim_subscriptions:\n",
    "        subscription_name = subscription['name']\n",
    "        subscription_key = subscription['key']\n",
    "        utils.print_info(f\"Subscription Name: {subscription_name}\")\n",
    "        utils.print_info(f\"Subscription Key: ****{subscription_key[-4:]}\")\n",
    "    api_key = apim_subscriptions[0].get(\"key\") # default api key to the first subscription key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "### 4 Install Python library requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: aiohttp in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from -r requirements.txt (line 1)) (3.12.15)\n",
      "Requirement already satisfied: openai in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from -r requirements.txt (line 2)) (1.109.1)\n",
      "Requirement already satisfied: azure-identity in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from -r requirements.txt (line 5)) (1.25.0)\n",
      "Requirement already satisfied: fastrtc[vad] in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from -r requirements.txt (line 4)) (0.0.33)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from aiohttp->-r requirements.txt (line 1)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from aiohttp->-r requirements.txt (line 1)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from aiohttp->-r requirements.txt (line 1)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from aiohttp->-r requirements.txt (line 1)) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from aiohttp->-r requirements.txt (line 1)) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from aiohttp->-r requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from aiohttp->-r requirements.txt (line 1)) (1.21.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp->-r requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 2)) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 2)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 2)) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 2)) (0.11.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 2)) (2.11.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 2)) (4.15.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 2)) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 2)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 2)) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 2)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 2)) (0.4.2)\n",
      "Requirement already satisfied: websockets<16,>=13 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openai[realtime]->-r requirements.txt (line 3)) (15.0.1)\n",
      "Requirement already satisfied: aioice>=0.10.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from fastrtc[vad]->-r requirements.txt (line 4)) (0.10.1)\n",
      "Requirement already satisfied: aiortc in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from fastrtc[vad]->-r requirements.txt (line 4)) (1.13.0)\n",
      "Requirement already satisfied: audioop-lts in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from fastrtc[vad]->-r requirements.txt (line 4)) (0.2.2)\n",
      "Requirement already satisfied: gradio<6.0,>=4.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from fastrtc[vad]->-r requirements.txt (line 4)) (5.49.0)\n",
      "Requirement already satisfied: librosa in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from fastrtc[vad]->-r requirements.txt (line 4)) (0.11.0)\n",
      "Requirement already satisfied: numba>=0.60.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from fastrtc[vad]->-r requirements.txt (line 4)) (0.62.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from fastrtc[vad]->-r requirements.txt (line 4)) (2.3.3)\n",
      "Requirement already satisfied: standard-aifc in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from fastrtc[vad]->-r requirements.txt (line 4)) (3.13.0)\n",
      "Requirement already satisfied: standard-sunau in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from fastrtc[vad]->-r requirements.txt (line 4)) (3.13.0)\n",
      "Requirement already satisfied: onnxruntime>=1.20.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from fastrtc[vad]->-r requirements.txt (line 4)) (1.23.0)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (24.1.0)\n",
      "Requirement already satisfied: brotli>=1.1.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (1.1.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.118.0)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.6.1)\n",
      "Requirement already satisfied: gradio-client==1.13.3 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (1.13.3)\n",
      "Requirement already satisfied: groovy~=0.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.35.3)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (3.0.3)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (3.11.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (25.0)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (2.3.3)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (11.3.0)\n",
      "Requirement already satisfied: pydub in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (6.0.3)\n",
      "Requirement already satisfied: ruff>=0.9.3 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.13.3)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.48.0)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.19.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.37.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio-client==1.13.3->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (2025.9.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (3.19.1)\n",
      "Requirement already satisfied: requests in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (2.32.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (2025.2)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from typer<1.0,>=0.12->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (8.3.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from typer<1.0,>=0.12->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from typer<1.0,>=0.12->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (14.1.0)\n",
      "Requirement already satisfied: azure-core>=1.31.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from azure-identity->-r requirements.txt (line 5)) (1.35.1)\n",
      "Requirement already satisfied: cryptography>=2.5 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from azure-identity->-r requirements.txt (line 5)) (46.0.2)\n",
      "Requirement already satisfied: msal>=1.30.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from azure-identity->-r requirements.txt (line 5)) (1.34.0b1)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from azure-identity->-r requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from aioice>=0.10.1->fastrtc[vad]->-r requirements.txt (line 4)) (2.8.0)\n",
      "Requirement already satisfied: ifaddr>=0.2.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from aioice>=0.10.1->fastrtc[vad]->-r requirements.txt (line 4)) (0.2.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from azure-core>=1.31.0->azure-identity->-r requirements.txt (line 5)) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.4.6)\n",
      "Requirement already satisfied: cffi>=2.0.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from cryptography>=2.5->azure-identity->-r requirements.txt (line 5)) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from cffi>=2.0.0->cryptography>=2.5->azure-identity->-r requirements.txt (line 5)) (2.23)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity->-r requirements.txt (line 5)) (2.10.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (2.5.0)\n",
      "Requirement already satisfied: portalocker<3,>=1.4 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from msal-extensions>=1.2.0->azure-identity->-r requirements.txt (line 5)) (2.10.1)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from portalocker<3,>=1.4->msal-extensions>=1.2.0->azure-identity->-r requirements.txt (line 5)) (311)\n",
      "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from numba>=0.60.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.45.1)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from onnxruntime>=1.20.1->fastrtc[vad]->-r requirements.txt (line 4)) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from onnxruntime>=1.20.1->fastrtc[vad]->-r requirements.txt (line 4)) (25.9.23)\n",
      "Requirement already satisfied: protobuf in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from onnxruntime>=1.20.1->fastrtc[vad]->-r requirements.txt (line 4)) (5.29.5)\n",
      "Requirement already satisfied: sympy in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from onnxruntime>=1.20.1->fastrtc[vad]->-r requirements.txt (line 4)) (1.14.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.1.2)\n",
      "Requirement already satisfied: av<15.0.0,>=14.0.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from aiortc->fastrtc[vad]->-r requirements.txt (line 4)) (14.4.0)\n",
      "Requirement already satisfied: google-crc32c>=1.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from aiortc->fastrtc[vad]->-r requirements.txt (line 4)) (1.7.1)\n",
      "Requirement already satisfied: pyee>=13.0.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from aiortc->fastrtc[vad]->-r requirements.txt (line 4)) (13.0.0)\n",
      "Requirement already satisfied: pylibsrtp>=0.10.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from aiortc->fastrtc[vad]->-r requirements.txt (line 4)) (0.12.0)\n",
      "Requirement already satisfied: pyopenssl>=25.0.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from aiortc->fastrtc[vad]->-r requirements.txt (line 4)) (25.3.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from coloredlogs->onnxruntime>=1.20.1->fastrtc[vad]->-r requirements.txt (line 4)) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.20.1->fastrtc[vad]->-r requirements.txt (line 4)) (3.5.4)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from librosa->fastrtc[vad]->-r requirements.txt (line 4)) (3.0.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from librosa->fastrtc[vad]->-r requirements.txt (line 4)) (1.16.2)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from librosa->fastrtc[vad]->-r requirements.txt (line 4)) (1.7.2)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from librosa->fastrtc[vad]->-r requirements.txt (line 4)) (1.5.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from librosa->fastrtc[vad]->-r requirements.txt (line 4)) (5.2.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from librosa->fastrtc[vad]->-r requirements.txt (line 4)) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from librosa->fastrtc[vad]->-r requirements.txt (line 4)) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from librosa->fastrtc[vad]->-r requirements.txt (line 4)) (1.0.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from librosa->fastrtc[vad]->-r requirements.txt (line 4)) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from librosa->fastrtc[vad]->-r requirements.txt (line 4)) (1.1.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from pooch>=1.1->librosa->fastrtc[vad]->-r requirements.txt (line 4)) (4.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from scikit-learn>=1.1.0->librosa->fastrtc[vad]->-r requirements.txt (line 4)) (3.6.0)\n",
      "Requirement already satisfied: standard-chunk in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from standard-aifc->fastrtc[vad]->-r requirements.txt (line 4)) (3.13.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from sympy->onnxruntime>=1.20.1->fastrtc[vad]->-r requirements.txt (line 4)) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='text'></a>\n",
    "### üß™ Test the Realtime API using just text\n",
    "\n",
    "üëâ Based on this [sample](https://github.com/openai/openai-python/blob/main/examples/realtime/azure_realtime.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Portugal is Lisbon! It's a beautiful city known for its stunning architecture, rich history, and vibrant culture. If you ever get the chance to visit, you'll find charming streets, delicious food, and incredible views.\n"
     ]
    }
   ],
   "source": [
    "from azure.identity.aio import DefaultAzureCredential\n",
    "from openai import AsyncAzureOpenAI\n",
    "import asyncio, nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def main() -> None:\n",
    "    credential = DefaultAzureCredential()\n",
    "    client = AsyncAzureOpenAI(\n",
    "            azure_endpoint=f\"{apim_resource_gateway_url}/{inference_api_path}\",\n",
    "            api_key=api_key,\n",
    "            api_version=inference_api_version)\n",
    "    async with client.realtime.connect(model=models_config[0]['name']) as connection:\n",
    "        await connection.session.update(session={\"modalities\": [\"text\"]})  # type: ignore\n",
    "        await connection.conversation.item.create(\n",
    "            item={\n",
    "                \"type\": \"message\",\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [{\"type\": \"input_text\", \"text\": \"What is the capital of Portugal?\"}],\n",
    "            }\n",
    "        )\n",
    "        await connection.response.create()\n",
    "        async for event in connection:\n",
    "            if event.type == \"response.text.delta\":\n",
    "                print(event.delta, flush=True, end=\"\")\n",
    "            elif event.type == \"response.text.done\":\n",
    "                print()\n",
    "            elif event.type == \"response.done\":\n",
    "                break\n",
    "    await connection.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fastrtc'></a>\n",
    "### üß™ Test the Realtime API using FastRTC + Gradio\n",
    "\n",
    "‚ö° FastRTC is an elegant realtime library communication library to enable you to easily and quickly build RTC application both using websockets and WebRTC.\n",
    "\n",
    "Please ensure you have run the pip command succefully to install all required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lproux\\OneDrive - Microsoft\\bkp\\Documents\\GitHub\\.venv\\Lib\\site-packages\\uvicorn\\server.py:67: RuntimeWarning: coroutine 'Server.serve' was never awaited\n",
      "  return asyncio_run(self.serve(sockets=sockets), loop_factory=self.config.get_loop_factory())\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "Exception in thread Thread-7 (run):\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.2544.0_x64__qbz5n2kfra8p0\\Lib\\threading.py\"\u001b[0m, line \u001b[35m1043\u001b[0m, in \u001b[35m_bootstrap_inner\u001b[0m\n",
      "    \u001b[31mself.run\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "    \u001b[31m~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"c:\\Users\\lproux\\OneDrive - Microsoft\\bkp\\Documents\\GitHub\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\"\u001b[0m, line \u001b[35m772\u001b[0m, in \u001b[35mrun_closure\u001b[0m\n",
      "    \u001b[31m_threading_Thread_run\u001b[0m\u001b[1;31m(self)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_3.13.2544.0_x64__qbz5n2kfra8p0\\Lib\\threading.py\"\u001b[0m, line \u001b[35m994\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "    \u001b[31mself._target\u001b[0m\u001b[1;31m(*self._args, **self._kwargs)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"c:\\Users\\lproux\\OneDrive - Microsoft\\bkp\\Documents\\GitHub\\.venv\\Lib\\site-packages\\uvicorn\\server.py\"\u001b[0m, line \u001b[35m67\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "    return asyncio_run(self.serve(sockets=sockets), loop_factory=self.config.get_loop_factory())\n",
      "\u001b[1;35mTypeError\u001b[0m: \u001b[35m_patch_asyncio.<locals>.run() got an unexpected keyword argument 'loop_factory'\u001b[0m\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot find empty port in range: 7990-7990. You can specify a different port by setting the GRADIO_SERVER_PORT environment variable or passing the `server_port` parameter to `launch()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 164\u001b[39m\n\u001b[32m    153\u001b[39m stream = Stream(\n\u001b[32m    154\u001b[39m     OpenAIHandler(),\n\u001b[32m    155\u001b[39m     mode=\u001b[33m\"\u001b[39m\u001b[33msend-receive\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    160\u001b[39m     ui_args=ui_args,\n\u001b[32m    161\u001b[39m )\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     \u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mui\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_port\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m7990\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lproux\\OneDrive - Microsoft\\bkp\\Documents\\GitHub\\.venv\\Lib\\site-packages\\fastrtc\\stream.py:276\u001b[39m, in \u001b[36mStream._wrap_gradio_launch.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    274\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mapp_kwargs\u001b[39m\u001b[33m\"\u001b[39m] = {}\n\u001b[32m    275\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mapp_kwargs\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mlifespan\u001b[39m\u001b[33m\"\u001b[39m] = new_lifespan\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lproux\\OneDrive - Microsoft\\bkp\\Documents\\GitHub\\.venv\\Lib\\site-packages\\gradio\\blocks.py:2635\u001b[39m, in \u001b[36mBlocks.launch\u001b[39m\u001b[34m(self, inline, inbrowser, share, debug, max_threads, auth, auth_message, prevent_thread_lock, show_error, server_name, server_port, height, width, favicon_path, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_verify, quiet, show_api, allowed_paths, blocked_paths, root_path, app_kwargs, state_session_capacity, share_server_address, share_server_protocol, share_server_tls_certificate, auth_dependency, max_file_size, enable_monitoring, strict_cors, node_server_name, node_port, ssr_mode, pwa, mcp_server, _frontend, i18n)\u001b[39m\n\u001b[32m   2627\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2628\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgradio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m http_server\n\u001b[32m   2630\u001b[39m     (\n\u001b[32m   2631\u001b[39m         server_name,\n\u001b[32m   2632\u001b[39m         server_port,\n\u001b[32m   2633\u001b[39m         local_url,\n\u001b[32m   2634\u001b[39m         server,\n\u001b[32m-> \u001b[39m\u001b[32m2635\u001b[39m     ) = \u001b[43mhttp_server\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart_server\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2636\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapp\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2637\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2638\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_port\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_port\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2639\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_keyfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mssl_keyfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2640\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_certfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mssl_certfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2641\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_keyfile_password\u001b[49m\u001b[43m=\u001b[49m\u001b[43mssl_keyfile_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2642\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2643\u001b[39m     \u001b[38;5;28mself\u001b[39m.server_name = server_name\n\u001b[32m   2644\u001b[39m     \u001b[38;5;28mself\u001b[39m.local_url = local_url\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lproux\\OneDrive - Microsoft\\bkp\\Documents\\GitHub\\.venv\\Lib\\site-packages\\gradio\\http_server.py:157\u001b[39m, in \u001b[36mstart_server\u001b[39m\u001b[34m(app, server_name, server_port, ssl_keyfile, ssl_certfile, ssl_keyfile_password)\u001b[39m\n\u001b[32m    155\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m    158\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot find empty port in range: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmin\u001b[39m(server_ports)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmax\u001b[39m(server_ports)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. You can specify a different port by setting the GRADIO_SERVER_PORT environment variable or passing the `server_port` parameter to `launch()`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    159\u001b[39m     )\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ssl_keyfile \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    162\u001b[39m     path_to_local_server = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl_host_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mport\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mOSError\u001b[39m: Cannot find empty port in range: 7990-7990. You can specify a different port by setting the GRADIO_SERVER_PORT environment variable or passing the `server_port` parameter to `launch()`."
     ]
    }
   ],
   "source": [
    "import asyncio, base64, json, openai\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from openai import AsyncAzureOpenAI\n",
    "from fastapi import FastAPI\n",
    "from fastapi.responses import HTMLResponse, StreamingResponse\n",
    "from fastrtc import (\n",
    "    AdditionalOutputs,\n",
    "    AsyncStreamHandler,\n",
    "    Stream,\n",
    "    wait_for_item,\n",
    "    UIArgs\n",
    ")\n",
    "from gradio.utils import get_space\n",
    "\n",
    "SAMPLE_RATE = 24000\n",
    "\n",
    "AZURE_OPENAI_API_ENDPOINT = f\"{apim_resource_gateway_url}/{inference_api_path}\"\n",
    "AZURE_OPENAI_API_KEY = api_key\n",
    "AZURE_OPENAI_API_VERSION = inference_api_version\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME = models_config[0]['name']\n",
    "SESSION_CONFIG={\n",
    "    \"input_audio_transcription\": {\n",
    "      \"model\": \"whisper-1\"\n",
    "    },\n",
    "    \"turn_detection\": {\n",
    "      \"threshold\": 0.4,\n",
    "      \"silence_duration_ms\": 600,\n",
    "      \"type\": \"server_vad\"\n",
    "    },\n",
    "    \"instructions\": \"Your name is Amy. You're a helpful agent who responds initially with a clam British accent, but also can speak in any language as the user chooses to. Always start the conversation with a cheery hello\",\n",
    "    \"voice\": \"shimmer\",\n",
    "    \"modalities\": [\"text\", \"audio\"] ## required to solicit the initial welcome message\n",
    "    }\n",
    "\n",
    "def on_open(ws):\n",
    "    print(\"Connected to server.\")\n",
    "\n",
    "def on_message(ws, message):\n",
    "    data = json.loads(message)\n",
    "    print(\"Received event:\", json.dumps(data, indent=2))\n",
    "\n",
    "class OpenAIHandler(AsyncStreamHandler):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(\n",
    "            expected_layout=\"mono\",\n",
    "            output_sample_rate=SAMPLE_RATE,\n",
    "            output_frame_size=480,  # In this example we choose 480 samples per frame.\n",
    "            input_sample_rate=SAMPLE_RATE,\n",
    "        )\n",
    "        self.connection = None\n",
    "        self.output_queue = asyncio.Queue()\n",
    "\n",
    "    def copy(self):\n",
    "        return OpenAIHandler()\n",
    "\n",
    "    async def welcome(self):\n",
    "        await self.connection.conversation.item.create( # type: ignore\n",
    "            item={\n",
    "                \"type\": \"message\",\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [{\"type\": \"input_text\", \"text\": \"what's your name?\"}],\n",
    "            }\n",
    "        )\n",
    "        await self.connection.response.create() # type: ignore\n",
    "\n",
    "    async def start_up(self):\n",
    "        \"\"\"\n",
    "        Establish a persistent realtime connection to the Azure OpenAI backend.\n",
    "        The connection is configured for server‚Äêside Voice Activity Detection.\n",
    "        \"\"\"\n",
    "        self.client = openai.AsyncAzureOpenAI(\n",
    "            azure_endpoint=AZURE_OPENAI_API_ENDPOINT,\n",
    "            azure_deployment=AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "            api_key=AZURE_OPENAI_API_KEY,\n",
    "            api_version=AZURE_OPENAI_API_VERSION,\n",
    "        )\n",
    "        # When using Azure OpenAI realtime (beta), set the model/deployment identifier\n",
    "        async with self.client.realtime.connect(\n",
    "            model=AZURE_OPENAI_DEPLOYMENT_NAME  # Replace with your deployed realtime model id on Azure OpenAI.\n",
    "        ) as conn:\n",
    "            # Configure the session to use server-based voice activity detection (VAD)\n",
    "            await conn.session.update(session=SESSION_CONFIG) # type: ignore\n",
    "            self.connection = conn\n",
    "\n",
    "            # Uncomment the following line to send a welcome message to the assistant.\n",
    "            # await self.welcome()\n",
    "\n",
    "            async for event in self.connection:\n",
    "                # Handle interruptions\n",
    "                if event.type == \"input_audio_buffer.speech_started\":\n",
    "                    self.clear_queue()\n",
    "                if event.type == \"conversation.item.input_audio_transcription.completed\":\n",
    "                    # This event signals that an input audio transcription is completed.\n",
    "                    await self.output_queue.put(AdditionalOutputs(event))\n",
    "                if event.type == \"response.audio_transcript.done\":\n",
    "                    # This event signals that a response audio transcription is completed.\n",
    "                    await self.output_queue.put(AdditionalOutputs(event))\n",
    "                if event.type == \"response.audio.delta\":\n",
    "                    # For incremental audio output events, decode the delta.\n",
    "                    await self.output_queue.put(\n",
    "                        (\n",
    "                            self.output_sample_rate,\n",
    "                            np.frombuffer(base64.b64decode(event.delta), dtype=np.int16).reshape(1, -1),\n",
    "                        ),\n",
    "                    )\n",
    "\n",
    "    async def receive(self, frame: tuple[int, np.ndarray]) -> None:\n",
    "        \"\"\"\n",
    "        Receives an audio frame from the stream and sends it into the realtime API.\n",
    "        The audio data is encoded as Base64 before appending to the connection's input.\n",
    "        \"\"\"\n",
    "        if not self.connection:\n",
    "            return\n",
    "        _, array = frame\n",
    "        array = array.squeeze()\n",
    "        # Encode audio as Base64 string\n",
    "        audio_message = base64.b64encode(array.tobytes()).decode(\"utf-8\")\n",
    "        await self.connection.input_audio_buffer.append(audio=audio_message)  # type: ignore\n",
    "\n",
    "    async def emit(self) -> tuple[int, np.ndarray] | AdditionalOutputs | None:\n",
    "        \"\"\"\n",
    "        Waits for and returns the next output from the output queue.\n",
    "        The output may be an audio chunk or an additional output such as transcription.\n",
    "        \"\"\"\n",
    "        return await wait_for_item(self.output_queue)\n",
    "\n",
    "    async def shutdown(self) -> None: # type: ignore\n",
    "        if self.connection:\n",
    "            await self.connection.close()\n",
    "            self.connection = None\n",
    "\n",
    "def update_chatbot(chatbot: list[dict], content):\n",
    "    \"\"\"\n",
    "    Append the completed transcription to the chatbot messages.\n",
    "    \"\"\"\n",
    "    if content.type == \"conversation.item.input_audio_transcription.completed\":\n",
    "        chatbot.append({\"role\": \"user\", \"content\": content.transcript})\n",
    "    elif content.type == \"response.audio_transcript.done\":\n",
    "        chatbot.append({\"role\": \"assistant\", \"content\": content.transcript})\n",
    "    return chatbot\n",
    "\n",
    "\n",
    "# Create the Gradio Chatbot component for displaying conversation messages.\n",
    "ui_args: UIArgs = UIArgs(\n",
    "    title=\"APIM ‚ù§Ô∏è OpenAI - Contoso Assistant ü§ñ\",\n",
    ")\n",
    "chatbot = gr.Chatbot(type=\"messages\")\n",
    "latest_message = gr.Textbox(type=\"text\", visible=True)\n",
    "\n",
    "# Instantiate the Stream object that uses the OpenAIHandler.\n",
    "stream = Stream(\n",
    "    OpenAIHandler(),\n",
    "    mode=\"send-receive\",\n",
    "    modality=\"audio\",\n",
    "    additional_inputs=[chatbot],\n",
    "    additional_outputs=[chatbot],\n",
    "    additional_outputs_handler=update_chatbot,\n",
    "    ui_args=ui_args,\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    stream.ui.launch(server_port=7990)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='kql'></a>\n",
    "### üîç Display model usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "query = \"model_usage\"\n",
    "\n",
    "output = utils.run(f\"az monitor log-analytics query -w {log_analytics_id} --analytics-query \\\"{query}\\\"\", \"Retrieved log analytics query output\", \"Failed to retrieve log analytics query output\") \n",
    "if output.success and output.json_data:\n",
    "    table = output.json_data\n",
    "    display(pd.DataFrame(table))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "### üóëÔ∏è Clean up resources\n",
    "\n",
    "When you're finished with the lab, you should remove all your deployed resources from Azure to avoid extra charges and keep your Azure subscription uncluttered.\n",
    "Use the [clean-up-resources notebook](clean-up-resources.ipynb) for that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
