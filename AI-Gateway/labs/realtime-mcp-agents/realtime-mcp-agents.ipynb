{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIM ‚ù§Ô∏è AI Agents\n",
    "\n",
    "## Realtime Audio with MCP tools and Agents lab\n",
    "![flow](../../images/realtime-mcp-agents.gif)\n",
    "\n",
    "Playground to experiment the with [Azure OpenAI Realtime API](https://learn.microsoft.com/en-us/azure/ai-services/openai/realtime-audio-reference) for text and audio with integrations via [Model Context Protocol](https://modelcontextprotocol.io/) with Azure API Management to enable plug & play of tools to LLMs. Leverages the [credential manager](https://learn.microsoft.com/en-us/azure/api-management/credentials-overview) for  managing OAuth 2.0 tokens to backend tools and [client token validation](https://learn.microsoft.com/en-us/azure/api-management/validate-jwt-policy) to ensure end-to-end authentication and authorization.   \n",
    "This lab includes the following MCP servers:\n",
    "- Basic weather service: provide tools to get cities for a given country and retrieve random weather information for a specified city.\n",
    "- Spotify service: provide tools to authenticate on Spotify using the APIM Credential Manager, retrieves Playlists, Latest releases, start/stop music playing, and more. \n",
    "- ServiceNow incidents MCP Server: provides tools to authenticates on ServiceNow using the APIM Credential Manager, lists incidents, retrieves a particular incident and create a new one.\n",
    "\n",
    "### Result\n",
    "![result](result.png)\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- [Python 3.12 or later version](https://www.python.org/) installed\n",
    "- [VS Code](https://code.visualstudio.com/) installed with the [Jupyter notebook extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) enabled\n",
    "- [Python environment](https://code.visualstudio.com/docs/python/environments#_creating-environments) with the [requirements.txt](../../requirements.txt) or run `pip install -r requirements.txt` in your terminal\n",
    "- [An Azure Subscription](https://azure.microsoft.com/free/) with [Contributor](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#contributor) + [RBAC Administrator](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#role-based-access-control-administrator) or [Owner](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#owner) roles\n",
    "- [Azure CLI](https://learn.microsoft.com/cli/azure/install-azure-cli) installed and [Signed into your Azure subscription](https://learn.microsoft.com/cli/azure/authenticate-azure-cli-interactively)\n",
    "\n",
    "‚ñ∂Ô∏è Click `Run All` to execute all steps sequentially, or execute them `Step by Step`...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "### 0Ô∏è‚É£ Initialize notebook variables\n",
    "\n",
    "- Resources will be suffixed by a unique string based on your subscription id.\n",
    "- Adjust the location parameters according your preferences and on the [product availability by Azure region.](https://azure.microsoft.com/explore/global-infrastructure/products-by-region/?cdn=disable&products=cognitive-services,api-management) \n",
    "- Adjust the OpenAI model and version according the [availability by region.](https://learn.microsoft.com/azure/ai-services/openai/concepts/models) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: aiohttp in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from -r requirements.txt (line 1)) (3.12.15)\n",
      "Requirement already satisfied: openai in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from -r requirements.txt (line 2)) (1.109.1)\n",
      "Requirement already satisfied: azure-identity in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from -r requirements.txt (line 5)) (1.25.0)\n",
      "Requirement already satisfied: mcp in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from -r requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: fastrtc[vad] in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from -r requirements.txt (line 4)) (0.0.33)\n",
      "Requirement already satisfied: semantic-kernel[mcp] in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from -r requirements.txt (line 7)) (1.37.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from aiohttp->-r requirements.txt (line 1)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from aiohttp->-r requirements.txt (line 1)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from aiohttp->-r requirements.txt (line 1)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from aiohttp->-r requirements.txt (line 1)) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from aiohttp->-r requirements.txt (line 1)) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from aiohttp->-r requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from aiohttp->-r requirements.txt (line 1)) (1.21.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp->-r requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 2)) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 2)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 2)) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 2)) (0.11.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 2)) (2.11.10)\n",
      "Requirement already satisfied: sniffio in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openai->-r requirements.txt (line 2)) (4.15.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 2)) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 2)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 2)) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 2)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 2)) (0.4.2)\n",
      "Requirement already satisfied: websockets<16,>=13 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openai[realtime]->-r requirements.txt (line 3)) (15.0.1)\n",
      "Requirement already satisfied: aioice>=0.10.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from fastrtc[vad]->-r requirements.txt (line 4)) (0.10.1)\n",
      "Requirement already satisfied: aiortc in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from fastrtc[vad]->-r requirements.txt (line 4)) (1.13.0)\n",
      "Requirement already satisfied: audioop-lts in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from fastrtc[vad]->-r requirements.txt (line 4)) (0.2.2)\n",
      "Requirement already satisfied: gradio<6.0,>=4.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from fastrtc[vad]->-r requirements.txt (line 4)) (5.49.0)\n",
      "Requirement already satisfied: librosa in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from fastrtc[vad]->-r requirements.txt (line 4)) (0.11.0)\n",
      "Requirement already satisfied: numba>=0.60.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from fastrtc[vad]->-r requirements.txt (line 4)) (0.62.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from fastrtc[vad]->-r requirements.txt (line 4)) (2.3.3)\n",
      "Requirement already satisfied: standard-aifc in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from fastrtc[vad]->-r requirements.txt (line 4)) (3.13.0)\n",
      "Requirement already satisfied: standard-sunau in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from fastrtc[vad]->-r requirements.txt (line 4)) (3.13.0)\n",
      "Requirement already satisfied: onnxruntime>=1.20.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from fastrtc[vad]->-r requirements.txt (line 4)) (1.23.0)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (24.1.0)\n",
      "Requirement already satisfied: brotli>=1.1.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (1.1.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.118.0)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.6.1)\n",
      "Requirement already satisfied: gradio-client==1.13.3 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (1.13.3)\n",
      "Requirement already satisfied: groovy~=0.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.35.3)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (3.0.3)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (3.11.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (25.0)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (2.3.3)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (11.3.0)\n",
      "Requirement already satisfied: pydub in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (6.0.3)\n",
      "Requirement already satisfied: ruff>=0.9.3 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.13.3)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.48.0)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.19.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.37.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from gradio-client==1.13.3->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (2025.9.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (3.19.1)\n",
      "Requirement already satisfied: requests in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (2.32.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (2025.2)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from typer<1.0,>=0.12->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (8.3.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from typer<1.0,>=0.12->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from typer<1.0,>=0.12->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (14.1.0)\n",
      "Requirement already satisfied: azure-core>=1.31.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from azure-identity->-r requirements.txt (line 5)) (1.35.1)\n",
      "Requirement already satisfied: cryptography>=2.5 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from azure-identity->-r requirements.txt (line 5)) (46.0.2)\n",
      "Requirement already satisfied: msal>=1.30.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from azure-identity->-r requirements.txt (line 5)) (1.34.0b1)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from azure-identity->-r requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from mcp->-r requirements.txt (line 6)) (0.4.1)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from mcp->-r requirements.txt (line 6)) (4.25.1)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from mcp->-r requirements.txt (line 6)) (2.11.0)\n",
      "Requirement already satisfied: pywin32>=310 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from mcp->-r requirements.txt (line 6)) (311)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from mcp->-r requirements.txt (line 6)) (3.0.2)\n",
      "Requirement already satisfied: azure-ai-projects>=1.0.0b12 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from semantic-kernel[mcp]->-r requirements.txt (line 7)) (1.0.0b12)\n",
      "Requirement already satisfied: azure-ai-agents>=1.2.0b3 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from semantic-kernel[mcp]->-r requirements.txt (line 7)) (1.2.0b5)\n",
      "Requirement already satisfied: cloudevents~=1.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from semantic-kernel[mcp]->-r requirements.txt (line 7)) (1.12.0)\n",
      "Requirement already satisfied: defusedxml~=0.7 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from semantic-kernel[mcp]->-r requirements.txt (line 7)) (0.7.1)\n",
      "Requirement already satisfied: openapi_core<0.20,>=0.18 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from semantic-kernel[mcp]->-r requirements.txt (line 7)) (0.19.4)\n",
      "Requirement already satisfied: opentelemetry-api~=1.24 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from semantic-kernel[mcp]->-r requirements.txt (line 7)) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-sdk~=1.24 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from semantic-kernel[mcp]->-r requirements.txt (line 7)) (1.37.0)\n",
      "Requirement already satisfied: prance<25.4.9,>=23.6.21 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from semantic-kernel[mcp]->-r requirements.txt (line 7)) (25.4.8.0)\n",
      "Requirement already satisfied: pybars4~=0.9 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from semantic-kernel[mcp]->-r requirements.txt (line 7)) (0.9.13)\n",
      "Requirement already satisfied: nest-asyncio~=1.6 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from semantic-kernel[mcp]->-r requirements.txt (line 7)) (1.6.0)\n",
      "Requirement already satisfied: scipy>=1.15.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from semantic-kernel[mcp]->-r requirements.txt (line 7)) (1.16.2)\n",
      "Requirement already satisfied: protobuf in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from semantic-kernel[mcp]->-r requirements.txt (line 7)) (5.29.5)\n",
      "Requirement already satisfied: deprecation<3.0,>=2.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from cloudevents~=1.0->semantic-kernel[mcp]->-r requirements.txt (line 7)) (2.1.0)\n",
      "Requirement already satisfied: isodate in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel[mcp]->-r requirements.txt (line 7)) (0.7.2)\n",
      "Requirement already satisfied: jsonschema-path<0.4.0,>=0.3.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel[mcp]->-r requirements.txt (line 7)) (0.3.4)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel[mcp]->-r requirements.txt (line 7)) (10.8.0)\n",
      "Requirement already satisfied: openapi-schema-validator<0.7.0,>=0.6.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel[mcp]->-r requirements.txt (line 7)) (0.6.3)\n",
      "Requirement already satisfied: openapi-spec-validator<0.8.0,>=0.7.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel[mcp]->-r requirements.txt (line 7)) (0.7.2)\n",
      "Requirement already satisfied: parse in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel[mcp]->-r requirements.txt (line 7)) (1.20.2)\n",
      "Requirement already satisfied: werkzeug in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel[mcp]->-r requirements.txt (line 7)) (3.1.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from jsonschema>=4.20.0->mcp->-r requirements.txt (line 6)) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from jsonschema>=4.20.0->mcp->-r requirements.txt (line 6)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from jsonschema>=4.20.0->mcp->-r requirements.txt (line 6)) (0.27.1)\n",
      "Requirement already satisfied: pathable<0.5.0,>=0.4.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel[mcp]->-r requirements.txt (line 7)) (0.4.4)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.20,>=0.18->semantic-kernel[mcp]->-r requirements.txt (line 7)) (0.1.4)\n",
      "Requirement already satisfied: lazy-object-proxy<2.0.0,>=1.7.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from openapi-spec-validator<0.8.0,>=0.7.1->openapi_core<0.20,>=0.18->semantic-kernel[mcp]->-r requirements.txt (line 7)) (1.12.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from opentelemetry-api~=1.24->semantic-kernel[mcp]->-r requirements.txt (line 7)) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api~=1.24->semantic-kernel[mcp]->-r requirements.txt (line 7)) (3.23.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from opentelemetry-sdk~=1.24->semantic-kernel[mcp]->-r requirements.txt (line 7)) (0.58b0)\n",
      "Requirement already satisfied: chardet>=5.2 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from prance<25.4.9,>=23.6.21->semantic-kernel[mcp]->-r requirements.txt (line 7)) (5.2.0)\n",
      "Requirement already satisfied: ruamel.yaml>=0.18.10 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from prance<25.4.9,>=23.6.21->semantic-kernel[mcp]->-r requirements.txt (line 7)) (0.18.15)\n",
      "Requirement already satisfied: PyMeta3>=0.5.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from pybars4~=0.9->semantic-kernel[mcp]->-r requirements.txt (line 7)) (0.5.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from pydantic-settings>=2.5.2->mcp->-r requirements.txt (line 6)) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (2.5.0)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from aioice>=0.10.1->fastrtc[vad]->-r requirements.txt (line 4)) (2.8.0)\n",
      "Requirement already satisfied: ifaddr>=0.2.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from aioice>=0.10.1->fastrtc[vad]->-r requirements.txt (line 4)) (0.2.0)\n",
      "Requirement already satisfied: av<15.0.0,>=14.0.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from aiortc->fastrtc[vad]->-r requirements.txt (line 4)) (14.4.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from aiortc->fastrtc[vad]->-r requirements.txt (line 4)) (2.0.0)\n",
      "Requirement already satisfied: google-crc32c>=1.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from aiortc->fastrtc[vad]->-r requirements.txt (line 4)) (1.7.1)\n",
      "Requirement already satisfied: pyee>=13.0.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from aiortc->fastrtc[vad]->-r requirements.txt (line 4)) (13.0.0)\n",
      "Requirement already satisfied: pylibsrtp>=0.10.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from aiortc->fastrtc[vad]->-r requirements.txt (line 4)) (0.12.0)\n",
      "Requirement already satisfied: pyopenssl>=25.0.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from aiortc->fastrtc[vad]->-r requirements.txt (line 4)) (25.3.0)\n",
      "Requirement already satisfied: azure-storage-blob>=12.15.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from azure-ai-projects>=1.0.0b12->semantic-kernel[mcp]->-r requirements.txt (line 7)) (12.26.0)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from azure-core>=1.31.0->azure-identity->-r requirements.txt (line 5)) (1.17.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from cffi>=1.0.0->aiortc->fastrtc[vad]->-r requirements.txt (line 4)) (2.23)\n",
      "Requirement already satisfied: colorama in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.4.6)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity->-r requirements.txt (line 5)) (2.10.1)\n",
      "Requirement already satisfied: portalocker<3,>=1.4 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from msal-extensions>=1.2.0->azure-identity->-r requirements.txt (line 5)) (2.10.1)\n",
      "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from numba>=0.60.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.45.1)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from onnxruntime>=1.20.1->fastrtc[vad]->-r requirements.txt (line 4)) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from onnxruntime>=1.20.1->fastrtc[vad]->-r requirements.txt (line 4)) (25.9.23)\n",
      "Requirement already satisfied: sympy in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from onnxruntime>=1.20.1->fastrtc[vad]->-r requirements.txt (line 4)) (1.14.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio<6.0,>=4.0->fastrtc[vad]->-r requirements.txt (line 4)) (0.1.2)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from ruamel.yaml>=0.18.10->prance<25.4.9,>=23.6.21->semantic-kernel[mcp]->-r requirements.txt (line 7)) (0.2.14)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from coloredlogs->onnxruntime>=1.20.1->fastrtc[vad]->-r requirements.txt (line 4)) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.20.1->fastrtc[vad]->-r requirements.txt (line 4)) (3.5.4)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from librosa->fastrtc[vad]->-r requirements.txt (line 4)) (3.0.1)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from librosa->fastrtc[vad]->-r requirements.txt (line 4)) (1.7.2)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from librosa->fastrtc[vad]->-r requirements.txt (line 4)) (1.5.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from librosa->fastrtc[vad]->-r requirements.txt (line 4)) (5.2.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from librosa->fastrtc[vad]->-r requirements.txt (line 4)) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from librosa->fastrtc[vad]->-r requirements.txt (line 4)) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from librosa->fastrtc[vad]->-r requirements.txt (line 4)) (1.0.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from librosa->fastrtc[vad]->-r requirements.txt (line 4)) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from librosa->fastrtc[vad]->-r requirements.txt (line 4)) (1.1.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from pooch>=1.1->librosa->fastrtc[vad]->-r requirements.txt (line 4)) (4.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from scikit-learn>=1.1.0->librosa->fastrtc[vad]->-r requirements.txt (line 4)) (3.6.0)\n",
      "Requirement already satisfied: standard-chunk in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from standard-aifc->fastrtc[vad]->-r requirements.txt (line 4)) (3.13.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\lproux\\onedrive - microsoft\\bkp\\documents\\github\\.venv\\lib\\site-packages (from sympy->onnxruntime>=1.20.1->fastrtc[vad]->-r requirements.txt (line 4)) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ \u001b[1;32mNotebook initialized\u001b[0m ‚åö 10:04:42.878217 \n"
     ]
    }
   ],
   "source": [
    "import os, sys, json\n",
    "sys.path.insert(1, '../../shared')  # add the shared directory to the Python path\n",
    "import utils\n",
    "\n",
    "deployment_name = os.path.basename(os.path.dirname(globals()['__vsc_ipynb_file__']))\n",
    "resource_group_name = f\"lab-{deployment_name}\" # change the name to match your naming style\n",
    "resource_group_location = \"uksouth\"\n",
    "\n",
    "aiservices_config = [{\"name\": \"foundry1\", \"location\": \"swedencentral\"}]\n",
    "\n",
    "models_config = [{\"name\": \"gpt-realtime\", \"publisher\": \"OpenAI\", \"version\": \"2025-08-28\", \"sku\": \"GlobalStandard\", \"capacity\": 10}]\n",
    "\n",
    "apim_sku = 'Basicv2'\n",
    "apim_subscriptions_config = [{\"name\": \"subscription1\", \"displayName\": \"Subscription 1\"}]\n",
    "\n",
    "inference_api_path = 'inference'  # path to the inference API in the APIM service\n",
    "inference_api_type = \"websocket\"  \n",
    "inference_api_version = \"2024-10-01-preview\"\n",
    "foundry_project_name = deployment_name\n",
    "\n",
    "build = 0\n",
    "weather_mcp_server_image = \"weather-mcp-server\"\n",
    "weather_mcp_server_src = \"src/weather/mcp-server\"\n",
    "\n",
    "spotify_mcp_server_image = \"spotify-mcp-server\"\n",
    "spotify_mcp_server_src = \"src/spotify/mcp-server\"\n",
    "\n",
    "utils.print_ok('Notebook initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "### 1Ô∏è‚É£ Verify the Azure CLI and the connected Azure subscription\n",
    "\n",
    "The following commands ensure that you have the latest version of the Azure CLI and that the Azure CLI is connected to your Azure subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az account show \u001b[0m\n",
      "‚úÖ \u001b[1;32mRetrieved az account\u001b[0m ‚åö 10:04:44.982387 [0m:2s]\n",
      "üëâüèΩ \u001b[1;34mCurrent user: lproux@microsoft.com\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mTenant ID: 2b9d9f47-1fb6-400a-a438-39fe7d768649\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mSubscription ID: d334f2cd-3efd-494e-9fd3-2470b1a13e4c\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "output = utils.run(\"az account show\", \"Retrieved az account\", \"Failed to get the current az account\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    current_user = output.json_data['user']['name']\n",
    "    tenant_id = output.json_data['tenantId']\n",
    "    subscription_id = output.json_data['id']\n",
    "\n",
    "    utils.print_info(f\"Current user: {current_user}\")\n",
    "    utils.print_info(f\"Tenant ID: {tenant_id}\")\n",
    "    utils.print_info(f\"Subscription ID: {subscription_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### 2Ô∏è‚É£ Create deployment using ü¶æ Bicep\n",
    "\n",
    "This lab uses [Bicep](https://learn.microsoft.com/azure/azure-resource-manager/bicep/overview?tabs=bicep) to declarative define all the resources that will be deployed in the specified resource group. Change the parameters or the [main.bicep](main.bicep) directly to try different configurations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az group show --name lab-realtime-mcp-agents \u001b[0m\n",
      "üëâüèΩ \u001b[1;34mResource group lab-realtime-mcp-agents does not yet exist. Creating the resource group now...\u001b[0m\n",
      "‚öôÔ∏è \u001b[1;34mRunning: az group create --name lab-realtime-mcp-agents --location uksouth --tags source=ai-gateway \u001b[0m\n",
      "‚úÖ \u001b[1;32mResource group 'lab-realtime-mcp-agents' created\u001b[0m ‚åö 10:04:54.470405 [0m:5s]\n",
      "‚öôÔ∏è \u001b[1;34mRunning: az deployment group create --name realtime-mcp-agents --resource-group lab-realtime-mcp-agents --template-file main.bicep --parameters params.json \u001b[0m\n",
      "‚úÖ \u001b[1;32mDeployment 'realtime-mcp-agents' succeeded\u001b[0m ‚åö 10:08:19.946562 [3m:25s]\n"
     ]
    }
   ],
   "source": [
    "# Create the resource group if doesn't exist\n",
    "utils.create_resource_group(resource_group_name, resource_group_location)\n",
    "\n",
    "# Define the Bicep parameters\n",
    "bicep_parameters = {\n",
    "    \"$schema\": \"https://schema.management.azure.com/schemas/2019-04-01/deploymentParameters.json#\",\n",
    "    \"contentVersion\": \"1.0.0.0\",\n",
    "    \"parameters\": {\n",
    "        \"apimSku\": { \"value\": apim_sku },\n",
    "        \"aiServicesConfig\": { \"value\": aiservices_config },\n",
    "        \"modelsConfig\": { \"value\": models_config },\n",
    "        \"apimSubscriptionsConfig\": { \"value\": apim_subscriptions_config },\n",
    "        \"inferenceAPIPath\": { \"value\": inference_api_path },\n",
    "        \"inferenceAPIType\": { \"value\": inference_api_type },\n",
    "        \"foundryProjectName\": { \"value\": foundry_project_name }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Write the parameters to the params.json file\n",
    "with open('params.json', 'w') as bicep_parameters_file:\n",
    "    bicep_parameters_file.write(json.dumps(bicep_parameters))\n",
    "\n",
    "# Run the deployment\n",
    "output = utils.run(f\"az deployment group create --name {deployment_name} --resource-group {resource_group_name} --template-file main.bicep --parameters params.json\",\n",
    "    f\"Deployment '{deployment_name}' succeeded\", f\"Deployment '{deployment_name}' failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### 3Ô∏è‚É£ Get the deployment outputs\n",
    "\n",
    "Retrieve the required outputs from the Bicep deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az deployment group show --name realtime-mcp-agents -g lab-realtime-mcp-agents \u001b[0m\n",
      "‚úÖ \u001b[1;32mRetrieved deployment: realtime-mcp-agents\u001b[0m ‚åö 10:08:24.342526 [0m:4s]\n",
      "üëâüèΩ \u001b[1;34mLog Analytics Id: 204b7fd8-5082-4477-9870-0bddcc51d833\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mAPIM Service Id: /subscriptions/d334f2cd-3efd-494e-9fd3-2470b1a13e4c/resourceGroups/lab-realtime-mcp-agents/providers/Microsoft.ApiManagement/service/apim-kxlc3jdme275s\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mAPIM API Gateway URL: https://apim-kxlc3jdme275s.azure-api.net\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mSubscription Name: subscription1\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mSubscription Key: ****291d\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mContainer Registry Name: acrkxlc3jdme275s\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mWeather Container App Resource Name: aca-weather-kxlc3jdme275s\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mSpotify Container App Resource Name: aca-spotify-kxlc3jdme275s\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Obtain all of the outputs from the deployment\n",
    "output = utils.run(f\"az deployment group show --name {deployment_name} -g {resource_group_name}\", f\"Retrieved deployment: {deployment_name}\", f\"Failed to retrieve deployment: {deployment_name}\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    log_analytics_id = utils.get_deployment_output(output, 'logAnalyticsWorkspaceId', 'Log Analytics Id')\n",
    "    apim_service_id = utils.get_deployment_output(output, 'apimServiceId', 'APIM Service Id')\n",
    "    apim_resource_gateway_url = utils.get_deployment_output(output, 'apimResourceGatewayURL', 'APIM API Gateway URL')\n",
    "    apim_subscriptions = json.loads(utils.get_deployment_output(output, 'apimSubscriptions').replace(\"\\'\", \"\\\"\"))\n",
    "    for subscription in apim_subscriptions:\n",
    "        subscription_name = subscription['name']\n",
    "        subscription_key = subscription['key']\n",
    "        utils.print_info(f\"Subscription Name: {subscription_name}\")\n",
    "        utils.print_info(f\"Subscription Key: ****{subscription_key[-4:]}\")\n",
    "    api_key = apim_subscriptions[0].get(\"key\") # default api key to the first subscription key\n",
    "    container_registry_name = utils.get_deployment_output(output, 'containerRegistryName', 'Container Registry Name')\n",
    "    weather_containerapp_resource_name = utils.get_deployment_output(output, 'weatherMCPServerContainerAppResourceName', 'Weather Container App Resource Name')\n",
    "    spotify_containerapp_resource_name = utils.get_deployment_output(output, 'spotifyMCPServerContainerAppResourceName', 'Spotify Container App Resource Name')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "### 4Ô∏è‚É£ Build and deploy the MCP Servers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az acr build --image weather-mcp-server:v0.1 --resource-group lab-realtime-mcp-agents --registry acrkxlc3jdme275s --file src/weather/mcp-server/Dockerfile src/weather/mcp-server/. --no-logs \u001b[0m\n",
      "‚úÖ \u001b[1;32mWeather MCP Server image was successfully built\u001b[0m ‚åö 10:09:06.781451 [0m:42s]\n",
      "‚öôÔ∏è \u001b[1;34mRunning: az containerapp update -n aca-weather-kxlc3jdme275s -g lab-realtime-mcp-agents --image \"acrkxlc3jdme275s.azurecr.io/weather-mcp-server:v0.1\" \u001b[0m\n",
      "‚úÖ \u001b[1;32mWeather MCP Server deployment succeeded\u001b[0m ‚åö 10:09:31.009307 [0m:24s]\n",
      "‚öôÔ∏è \u001b[1;34mRunning: az acr build --image spotify-mcp-server:v0.1 --resource-group lab-realtime-mcp-agents --registry acrkxlc3jdme275s --file src/spotify/mcp-server/Dockerfile src/spotify/mcp-server/. --no-logs \u001b[0m\n",
      "‚úÖ \u001b[1;32mSpotify MCP Server image was successfully built\u001b[0m ‚åö 10:12:28.212646 [2m:57s]\n",
      "‚öôÔ∏è \u001b[1;34mRunning: az containerapp update -n aca-spotify-kxlc3jdme275s -g lab-realtime-mcp-agents --image \"acrkxlc3jdme275s.azurecr.io/spotify-mcp-server:v0.1\" \u001b[0m\n",
      "‚úÖ \u001b[1;32mSpotify MCP Server deployment succeeded\u001b[0m ‚åö 10:12:47.942100 [0m:19s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<utils.Output at 0x1a117bc3350>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build = build + 1 # increment the build number\n",
    "\n",
    "utils.run(f\"az acr build --image {weather_mcp_server_image}:v0.{build} --resource-group {resource_group_name} --registry {container_registry_name} --file {weather_mcp_server_src}/Dockerfile {weather_mcp_server_src}/. --no-logs\", \n",
    "         \"Weather MCP Server image was successfully built\", \"Failed to build the Weather MCP Server image\")\n",
    "utils.run(f'az containerapp update -n {weather_containerapp_resource_name} -g {resource_group_name} --image \"{container_registry_name}.azurecr.io/{weather_mcp_server_image}:v0.{build}\"', \n",
    "         \"Weather MCP Server deployment succeeded\", \"Weather MCP Server deployment failed\")\n",
    "\n",
    "utils.run(f\"az acr build --image {spotify_mcp_server_image}:v0.{build} --resource-group {resource_group_name} --registry {container_registry_name} --file {spotify_mcp_server_src}/Dockerfile {spotify_mcp_server_src}/. --no-logs\", \n",
    "          \"Spotify MCP Server image was successfully built\", \"Failed to build the Spotify MCP Server image\")\n",
    "utils.run(f'az containerapp update -n {spotify_containerapp_resource_name} -g {resource_group_name} --image \"{container_registry_name}.azurecr.io/{spotify_mcp_server_image}:v0.{build}\"', \n",
    "          \"Spotify MCP Server deployment succeeded\", \"Spotify MCP Server deployment failed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='testconnection'></a>\n",
    "### üß™ Test the connection to the MCP servers and List Tools\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connected to server https://apim-kxlc3jdme275s.azure-api.net/spotify/mcp/sse\n",
      "‚öôÔ∏è Tools:\n",
      "  - authorize_spotify\n",
      "     Input Schema: {'properties': {}, 'title': 'authorize_spotifyArguments', 'type': 'object'}\n",
      "  - get_user_playlists\n",
      "     Input Schema: {'properties': {}, 'title': 'get_user_playlistsArguments', 'type': 'object'}\n",
      "  - get_player_queue\n",
      "     Input Schema: {'properties': {}, 'title': 'get_player_queueArguments', 'type': 'object'}\n",
      "  - get_playback_status\n",
      "     Input Schema: {'properties': {}, 'title': 'get_playback_statusArguments', 'type': 'object'}\n",
      "  - start_playback\n",
      "     Input Schema: {'properties': {}, 'title': 'start_playbackArguments', 'type': 'object'}\n",
      "  - pause_playback\n",
      "     Input Schema: {'properties': {}, 'title': 'pause_playbackArguments', 'type': 'object'}\n",
      "  - get_my_queue\n",
      "     Input Schema: {'properties': {}, 'title': 'get_my_queueArguments', 'type': 'object'}\n",
      "  - browse_new_releases\n",
      "     Input Schema: {'properties': {}, 'title': 'browse_new_releasesArguments', 'type': 'object'}\n",
      "  - search\n",
      "     Input Schema: {'properties': {'query': {'title': 'Query', 'type': 'string'}}, 'required': ['query'], 'title': 'searchArguments', 'type': 'object'}\n",
      "‚úÖ Connected to server https://apim-kxlc3jdme275s.azure-api.net/weather/sse\n",
      "‚öôÔ∏è Tools:\n",
      "  - get_cities\n",
      "     Input Schema: {'properties': {'country': {'title': 'Country', 'type': 'string'}}, 'required': ['country'], 'title': 'get_citiesArguments', 'type': 'object'}\n",
      "  - get_weather\n",
      "     Input Schema: {'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'get_weatherArguments', 'type': 'object'}\n"
     ]
    }
   ],
   "source": [
    "import os, json, asyncio, time, requests\n",
    "from mcp import ClientSession\n",
    "from mcp.client.sse import sse_client\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def list_tools(server_url, authorization_header = None):\n",
    "    headers = {\"Authorization\": authorization_header} if authorization_header else None\n",
    "    async with sse_client(server_url, headers) as streams:\n",
    "        async with ClientSession(streams[0], streams[1]) as session:\n",
    "            await session.initialize()\n",
    "\n",
    "            response = await session.list_tools()\n",
    "            tools = response.tools\n",
    "    print(f\"‚úÖ Connected to server {server_url}\")\n",
    "    print(\"‚öôÔ∏è Tools:\")\n",
    "    for tool in tools:\n",
    "        print(f\"  - {tool.name}\")\n",
    "        print(f\"     Input Schema: {tool.inputSchema}\")\n",
    "    \n",
    "asyncio.run(list_tools(f\"{apim_resource_gateway_url}/spotify/mcp/sse\"))\n",
    "asyncio.run(list_tools(f\"{apim_resource_gateway_url}/weather/sse\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='inspector'></a>\n",
    "### üß™ (optional) Use the [MCP Inspector](https://modelcontextprotocol.io/docs/tools/inspector) for testing and debugging the MCP servers\n",
    "\n",
    "#### Execute the following steps:\n",
    "1. Execute `npx @modelcontextprotocol/inspector` in a terminal\n",
    "2. Open the provided URL in a browser\n",
    "3. Set the transport type as SSE\n",
    "4. Provide the MCP server url and click connect\n",
    "5. Select the \"Tools\" tab to see and run the available tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sk'></a>\n",
    "### üß™ Execute a Realtime [Semantic Kernel Agent using MCP Tools](https://devblogs.microsoft.com/semantic-kernel/integrating-model-context-protocol-tools-with-semantic-kernel-a-step-by-step-guide/) via Azure API Management\n",
    "\n",
    "üëâ Use [this samples](https://github.com/microsoft/semantic-kernel/tree/main/python/samples/concepts/realtime) for more advanced use cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service_event=ResponseTextDoneEvent(content_index=0, event_id='event_CUAuPBrmdhM6z1j80Cr0i', item_id='item_CUAuPRBekF0RfPUCXynut', output_index=0, response_id='resp_CUAuPAAtGW08htLx0gLBE', text=\"Sure, let me find out the current weather in Paris. Could you hold on just a moment? I'll get that information for you right away.\", type='response.text.done') service_type='response.text.done'"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.connectors.ai.open_ai import (\n",
    "    AzureRealtimeWebsocket,\n",
    "    AzureRealtimeExecutionSettings,\n",
    "    ListenEvents,\n",
    "    TurnDetection\n",
    ")\n",
    "from semantic_kernel.contents import RealtimeTextEvent\n",
    "from semantic_kernel.contents.text_content import TextContent\n",
    "from semantic_kernel.connectors.mcp import MCPSsePlugin\n",
    "\n",
    "realtime_agent = AzureRealtimeWebsocket(\n",
    "            endpoint=f\"{apim_resource_gateway_url}/{inference_api_path}\",\n",
    "            deployment_name=models_config[0]['name'],\n",
    "            azure_openai_realtime_deployment_name=models_config[0]['name'],\n",
    "            api_key=api_key,\n",
    "            api_version=inference_api_version)\n",
    "\n",
    "weather_plugin = MCPSsePlugin(\n",
    "    name=\"Weather\",\n",
    "    url=f\"{apim_resource_gateway_url}/weather/sse\",\n",
    "    description=\"Weather Plugin\",\n",
    ")\n",
    "    \n",
    "settings = AzureRealtimeExecutionSettings(modalities=[\"text\"], turn_detection=TurnDetection(type=\"server_vad\", create_response=True, silence_duration_ms=800, threshold=0.8),\n",
    "\n",
    "                                          instructions=\"You are a helpful assistant that provides information about the weather, using just the text modality\",)\n",
    "async with realtime_agent(settings=settings, create_response=True, plugins=[weather_plugin]) as connection:\n",
    "    await connection.send(RealtimeTextEvent(text=TextContent(text=\"What's the weather like in Paris?\")))\n",
    "\n",
    "    async for event in connection.receive():\n",
    "        if event.service_type == \"response.text.done\":\n",
    "            print(event, flush=True, end=\"\")\n",
    "        elif event.service_type == \"response.done\":\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='spotifyconfig'></a>\n",
    "### 5Ô∏è‚É£ Create a Spotify OAuth app and configure the credential provider\n",
    "\n",
    "##### Step 1 - [Create an account on Spotify Developer portal](https://developer.spotify.com/) \n",
    "##### Step 2 - [Create an app with redirect URI from the next step](https://developer.spotify.com/dashboard)\n",
    "\n",
    "üëâ Use the Authorization callback URL that is provided below  \n",
    "üëâ Copy the Client ID and Client secret\n",
    "\n",
    "##### Step 3 - Configure the credential provider in API Management\n",
    "\n",
    "üëâ You just need to update the Client ID and Client secret on the existing `spotify` credential manager provider  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clientID = c849f23b016f4011a64e87caad48fe91\n",
    "\n",
    "clientsecret = e49032d67f68469a9d2710927b7ce2ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authorization callback URL: https://authorization-manager.consent.azure-apim.net/redirect/apim/apim-kxlc3jdme275s\n"
     ]
    }
   ],
   "source": [
    "print(f\"Authorization callback URL: https://authorization-manager.consent.azure-apim.net/redirect/apim/apim-kxlc3jdme275s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "apim_resource_name=\"apim-kxlc3jdme275s\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='rtfunctioncalling'></a>\n",
    "### üß™ Test the Realtime API using FastRTC + Gradio\n",
    "FastRTC is an elegant realtime library communication library to enable you to easily and quickly build RTC application both using websockets and WebRTC.\n",
    "\n",
    "Please ensure you have run the pip command succefully to install all required packages\n",
    "\n",
    "üëâ Tip: Restart the Python Kernel to stop the FastRTC server \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Initializing all MCPs\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot find empty port in range: 7897-7897. You can specify a different port by setting the GRADIO_SERVER_PORT environment variable or passing the `server_port` parameter to `launch()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 216\u001b[39m\n\u001b[32m    205\u001b[39m stream = Stream(\n\u001b[32m    206\u001b[39m     OpenAIHandler(),\n\u001b[32m    207\u001b[39m     mode=\u001b[33m\"\u001b[39m\u001b[33msend-receive\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    212\u001b[39m     ui_args=ui_args,\n\u001b[32m    213\u001b[39m )\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m     \u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mui\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_port\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m7897\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lproux\\OneDrive - Microsoft\\bkp\\Documents\\GitHub\\.venv\\Lib\\site-packages\\fastrtc\\stream.py:276\u001b[39m, in \u001b[36mStream._wrap_gradio_launch.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    274\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mapp_kwargs\u001b[39m\u001b[33m\"\u001b[39m] = {}\n\u001b[32m    275\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mapp_kwargs\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mlifespan\u001b[39m\u001b[33m\"\u001b[39m] = new_lifespan\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lproux\\OneDrive - Microsoft\\bkp\\Documents\\GitHub\\.venv\\Lib\\site-packages\\gradio\\blocks.py:2635\u001b[39m, in \u001b[36mBlocks.launch\u001b[39m\u001b[34m(self, inline, inbrowser, share, debug, max_threads, auth, auth_message, prevent_thread_lock, show_error, server_name, server_port, height, width, favicon_path, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_verify, quiet, show_api, allowed_paths, blocked_paths, root_path, app_kwargs, state_session_capacity, share_server_address, share_server_protocol, share_server_tls_certificate, auth_dependency, max_file_size, enable_monitoring, strict_cors, node_server_name, node_port, ssr_mode, pwa, mcp_server, _frontend, i18n)\u001b[39m\n\u001b[32m   2627\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2628\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgradio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m http_server\n\u001b[32m   2630\u001b[39m     (\n\u001b[32m   2631\u001b[39m         server_name,\n\u001b[32m   2632\u001b[39m         server_port,\n\u001b[32m   2633\u001b[39m         local_url,\n\u001b[32m   2634\u001b[39m         server,\n\u001b[32m-> \u001b[39m\u001b[32m2635\u001b[39m     ) = \u001b[43mhttp_server\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart_server\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2636\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapp\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2637\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2638\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_port\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_port\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2639\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_keyfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mssl_keyfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2640\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_certfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mssl_certfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2641\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_keyfile_password\u001b[49m\u001b[43m=\u001b[49m\u001b[43mssl_keyfile_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2642\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2643\u001b[39m     \u001b[38;5;28mself\u001b[39m.server_name = server_name\n\u001b[32m   2644\u001b[39m     \u001b[38;5;28mself\u001b[39m.local_url = local_url\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lproux\\OneDrive - Microsoft\\bkp\\Documents\\GitHub\\.venv\\Lib\\site-packages\\gradio\\http_server.py:157\u001b[39m, in \u001b[36mstart_server\u001b[39m\u001b[34m(app, server_name, server_port, ssl_keyfile, ssl_certfile, ssl_keyfile_password)\u001b[39m\n\u001b[32m    155\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m    158\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot find empty port in range: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmin\u001b[39m(server_ports)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmax\u001b[39m(server_ports)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. You can specify a different port by setting the GRADIO_SERVER_PORT environment variable or passing the `server_port` parameter to `launch()`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    159\u001b[39m     )\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ssl_keyfile \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    162\u001b[39m     path_to_local_server = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl_host_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mport\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mOSError\u001b[39m: Cannot find empty port in range: 7897-7897. You can specify a different port by setting the GRADIO_SERVER_PORT environment variable or passing the `server_port` parameter to `launch()`."
     ]
    }
   ],
   "source": [
    "import asyncio, base64, json, random, openai\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "from fastrtc import (\n",
    "    AdditionalOutputs,\n",
    "    AsyncStreamHandler,\n",
    "    Stream,\n",
    "    wait_for_item,\n",
    "    UIArgs\n",
    ")\n",
    "from gradio.utils import get_space\n",
    "from mcp_client import OAI_RT_SSEMCPClient\n",
    "\n",
    "# Define the sample rate (Hz)\n",
    "SAMPLE_RATE = 24000\n",
    "\n",
    "AZURE_OPENAI_API_ENDPOINT = f\"{apim_resource_gateway_url}/{inference_api_path}\"\n",
    "AZURE_OPENAI_API_KEY = api_key\n",
    "AZURE_OPENAI_API_VERSION = inference_api_version\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME = models_config[0]['name']\n",
    "\n",
    "class OpenAIHandler(AsyncStreamHandler):\n",
    "    mcp_config = {\n",
    "        'spotify': f\"{apim_resource_gateway_url}/spotify/mcp/sse\",\n",
    "        'weather': f\"{apim_resource_gateway_url}/weather/sse\"\n",
    "        }\n",
    "    mcp_servers = {}\n",
    "    tool_server_map = {}\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__(\n",
    "            expected_layout=\"mono\",\n",
    "            output_sample_rate=SAMPLE_RATE,\n",
    "            output_frame_size=480,  # In this example we choose 480 samples per frame.\n",
    "            input_sample_rate=SAMPLE_RATE,\n",
    "        )\n",
    "        self.connection = None\n",
    "        if len(self.mcp_config) > 0:\n",
    "            print (\"‚öôÔ∏è Initializing all MCPs\")\n",
    "            for name, url in self.mcp_config.items():\n",
    "                self.mcp_servers[name] = OAI_RT_SSEMCPClient(server_name=name, url=url)\n",
    "        else:\n",
    "            print (\"no MCPs\")\n",
    "        self.output_queue = asyncio.Queue()\n",
    "\n",
    "    async def start_up(self):\n",
    "        \"\"\"\n",
    "        Establish a persistent realtime connection to the Azure OpenAI backend.\n",
    "        The connection is configured for server‚Äêside Voice Activity Detection.\n",
    "        \"\"\"\n",
    "        self.client = openai.AsyncAzureOpenAI(\n",
    "            azure_endpoint=AZURE_OPENAI_API_ENDPOINT,\n",
    "            api_key=AZURE_OPENAI_API_KEY,\n",
    "            api_version=AZURE_OPENAI_API_VERSION,\n",
    "        )\n",
    "        for name, server in self.mcp_servers.items():\n",
    "                await server.start()\n",
    "        # When using Azure OpenAI realtime (beta), set the model/deployment identifier\n",
    "        async with self.client.realtime.connect(\n",
    "            model=AZURE_OPENAI_DEPLOYMENT_NAME  # Replace with your deployed realtime model id on Azure OpenAI.\n",
    "        ) as conn:\n",
    "            # Configure the session to use server-based voice activity detection (VAD)\n",
    "            session_config = await self.session_config()\n",
    "            await conn.session.update(session=session_config) # type: ignore\n",
    "            self.connection = conn\n",
    "\n",
    "            # Uncomment the following line to send a welcome message to the assistant.\n",
    "            # await self.welcome()\n",
    "\n",
    "            async for event in self.connection:\n",
    "                # Handle interruptions\n",
    "                if event.type == \"input_audio_buffer.speech_started\":\n",
    "                    self.clear_queue()\n",
    "                if event.type == \"conversation.item.input_audio_transcription.completed\":\n",
    "                    # This event signals that an input audio transcription is completed.\n",
    "                    await self.output_queue.put(AdditionalOutputs(event))\n",
    "                if event.type == \"response.audio_transcript.done\":\n",
    "                    # This event signals that a response audio transcription is completed.\n",
    "                    await self.output_queue.put(AdditionalOutputs(event))\n",
    "                if event.type == \"response.function_call_arguments.done\":\n",
    "                    await self.get_tool_response(event)\n",
    "                if event.type == \"conversation.item.created\":\n",
    "                    await self.output_queue.put(AdditionalOutputs(event))\n",
    "                if event.type == \"response.audio.delta\":\n",
    "                    # For incremental audio output events, decode the delta.\n",
    "                    await self.output_queue.put(\n",
    "                        (\n",
    "                            self.output_sample_rate,\n",
    "                            np.frombuffer(base64.b64decode(event.delta), dtype=np.int16).reshape(1, -1),\n",
    "                        ),\n",
    "                    )\n",
    "\n",
    "    def copy(self):\n",
    "        return OpenAIHandler()\n",
    "\n",
    "    async def welcome(self):\n",
    "        await self.connection.conversation.item.create( # type: ignore\n",
    "            item={\n",
    "                \"type\": \"message\",\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [{\"type\": \"input_text\", \"text\": \"what's your name?\"}],\n",
    "            }\n",
    "        )\n",
    "        await self.connection.response.create() # type: ignore\n",
    "\n",
    "    async def receive(self, frame: tuple[int, np.ndarray]) -> None:\n",
    "        \"\"\"\n",
    "        Receives an audio frame from the stream and sends it into the realtime API.\n",
    "        The audio data is encoded as Base64 before appending to the connection's input.\n",
    "        \"\"\"\n",
    "        if not self.connection:\n",
    "            return\n",
    "        _, array = frame\n",
    "        array = array.squeeze()\n",
    "        # Encode audio as Base64 string\n",
    "        audio_message = base64.b64encode(array.tobytes()).decode(\"utf-8\")\n",
    "        await self.connection.input_audio_buffer.append(audio=audio_message)  # type: ignore\n",
    "\n",
    "    async def emit(self) -> tuple[int, np.ndarray] | AdditionalOutputs | None:\n",
    "        \"\"\"\n",
    "        Waits for and returns the next output from the output queue.\n",
    "        The output may be an audio chunk or an additional output such as transcription.\n",
    "        \"\"\"\n",
    "        return await wait_for_item(self.output_queue)\n",
    "\n",
    "    async def shutdown(self) -> None: # type: ignore\n",
    "        # await self.weather_mcp.stop()\n",
    "        if self.connection:\n",
    "            await self.connection.close()\n",
    "            self.connection = None\n",
    "\n",
    "    async def session_config(self):\n",
    "        \"\"\"Returns a random value from the predefined list.\"\"\"\n",
    "        values = ['alloy', 'ash', 'ballad', 'coral', 'echo', 'sage', 'shimmer', 'verse']\n",
    "        tools = []\n",
    "        ### Get all tools from all active servers\n",
    "        for name, server in self.mcp_servers.items():\n",
    "                current_server_tools = await server.list_tools()\n",
    "                for tool in current_server_tools:\n",
    "                    self.tool_server_map[tool['name']]= name\n",
    "                tools = tools + current_server_tools\n",
    "        print(self.tool_server_map)\n",
    "        voice = random.choice(values)\n",
    "        print(voice)\n",
    "        ### for details on available param: https://platform.openai.com/docs/api-reference/realtime-sessions/create\n",
    "        SESSION_CONFIG={\n",
    "            \"input_audio_transcription\": {\n",
    "                \"model\": \"whisper-1\",\n",
    "            },\n",
    "            \"turn_detection\": {\n",
    "                \"threshold\": 0.4,\n",
    "                \"silence_duration_ms\": 600,\n",
    "                \"type\": \"server_vad\"\n",
    "            },\n",
    "            \"instructions\": f\"\"\"You are a DJ named {voice}! \n",
    "                                You are a helpful, calm and cheerful agent who responds with a clam accent, but also can speak in any language or accent. \n",
    "                                If you need to call a spotify tool, inform the user that you need first to call the authorization tool.\n",
    "                                After calling the authorization tool, send a text event with the link URL and don't read the link.\n",
    "                                After sending the event with the link, inform the user that he just needs to click on the provide link to get authorized on Spotify.\"\"\",\n",
    "            \"voice\": voice,\n",
    "            \"modalities\": [\"text\", \"audio\"], ## required to solicit the initial welcome message\n",
    "            \"tools\": tools\n",
    "        }\n",
    "        return SESSION_CONFIG\n",
    "\n",
    "    async def get_tool_response(self, event):\n",
    "        ### findout which MCP server to call\n",
    "        server_name = self.tool_server_map[event.name]\n",
    "        ### call the target\n",
    "        response = await self.mcp_servers[server_name].call_tool(tool_call=event.model_dump())\n",
    "        await self.connection.conversation.item.create(item=response) # type: ignore\n",
    "        await self.connection.response.create() # type: ignore\n",
    "\n",
    "def on_open(ws):\n",
    "    print(\"Connected to server.\")\n",
    "\n",
    "def on_message(ws, message):\n",
    "    data = json.loads(message)\n",
    "    print(\"Received event:\", json.dumps(data, indent=2))\n",
    "\n",
    "def update_chatbot(chatbot: list[dict], event):\n",
    "    \"\"\"\n",
    "    Append the completed transcription to the chatbot messages.\n",
    "    \"\"\"\n",
    "    if event.type == \"conversation.item.input_audio_transcription.completed\":\n",
    "        chatbot.append({\"role\": \"user\", \"content\": event.transcript})\n",
    "    elif event.type == \"response.audio_transcript.done\":\n",
    "        chatbot.append({\"role\": \"assistant\", \"content\": event.transcript})\n",
    "    elif event.type == \"conversation.item.created\":\n",
    "        if event.item and event.item.type == \"function_call_output\":\n",
    "            output = str(event.item.output)\n",
    "            expected_output = \"Please authorize by opening this link:\" # this string must match what was coded in the mcp server\n",
    "            if expected_output in output:\n",
    "                link = f'<a href=\"{output.replace(expected_output, \"\").strip()}\">üëâ Click here to authorize</a>'\n",
    "                chatbot.append({\"role\": \"assistant\", \"content\": link})\n",
    "    return chatbot\n",
    "\n",
    "ui_args: UIArgs = UIArgs(\n",
    "    title=\"APIM ‚ù§Ô∏è MCP - DJ Contoso Assistant üéß\",\n",
    ")\n",
    "chatbot = gr.Chatbot(type=\"messages\")\n",
    "latest_message = gr.Textbox(type=\"text\", visible=True)\n",
    "\n",
    "# Instantiate the Stream object that uses the OpenAIHandler.\n",
    "stream = Stream(\n",
    "    OpenAIHandler(),\n",
    "    mode=\"send-receive\",\n",
    "    modality=\"audio\",\n",
    "    additional_inputs=[chatbot],\n",
    "    additional_outputs=[chatbot],\n",
    "    additional_outputs_handler=update_chatbot,\n",
    "    ui_args=ui_args,\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    stream.ui.launch(server_port=7897)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='servicenowconfig'></a>\n",
    "### 6Ô∏è‚É£ Create a ServiceNow OAuth app and configure the credential provider\n",
    "\n",
    "‚ÑπÔ∏è If you do not wish to use ServiceNow, please skip these steps\n",
    "\n",
    "#### Step 1 - [Register the application in ServiceNow](https://www.servicenow.com/docs/bundle/yokohama-application-development/page/build/pipelines-and-deployments/task/create-oauth-api-endpoints-for-external-clients.html)\n",
    "\n",
    "üëâ Use the Authorization callback URL that is provided bellow  \n",
    "üëâ Copy the Client ID and Client secret\n",
    "\n",
    "#### Step 2 - Configure the credential provider in API Management\n",
    "\n",
    "üëâ You just need to update the Client ID and Client secret on the existing `servicenonw` credential manager provider  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Authorization callback URL: https://authorization-manager.consent.azure-apim.net/redirect/apim/{apim_resource_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='servicenowtest'></a>\n",
    "### üß™ Run the ServiceNow MCP Server with VS Code to manage ServiceNow incidents\n",
    "\n",
    "1. [Configure the ServiceNow MCP Server in VS Code](https://code.visualstudio.com/docs/copilot/chat/mcp-servers#_add-an-mcp-server) \n",
    "2. Type in the chat the following prompt: `Please list my servicenow incidents`\n",
    "3. The agent will suggest running the `authorize_servicenow` tool.\n",
    "4. Once the user accepts to run the tool, the agent will call the `authorize_servicenow` and provide an URL to proceed with the authentication and authorization on ServiceNow.\n",
    "5. After the user confirms that it's done, the agent will suggest running the `list_incidents` tool.\n",
    "6. Once the user accepts to run the `list_incidents` tool, the agent will provide the list of incidents for the connected ServiceNow instance.\n",
    "7. You can also retrieve details for a specific incident or create a new one.\n",
    "\n",
    "‚ú® Type in the chat the following prompt: `Create a ServiceNow incident for each GitHub issue`. To combine GitHub and ServiceNow MCP Servers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='validate-jwt'></a>\n",
    "### üîê (Optional) Implement [authorization policies](src/github/apim-api/auth-client-policy.xml) on MCP endpoints\n",
    "\n",
    "üëâ To ensure the enforcement of valid security tokens, we apply the `validate-jwt` policy to the `/sse` and `/messages` endpoints. The following code snippet demonstrates the application of this policy to GitHub API operations for token validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az account get-access-token --resource https://management.azure.com/ \u001b[0m\n",
      "‚úÖ \u001b[1;32mSuccessfully obtained access token\u001b[0m ‚åö 13:25:51.861279 [0m:6s]\n",
      "Updating the API policy...\n",
      "Response status: \u001b[1;31m400 - Bad Request\u001b[0m\n",
      "‚öôÔ∏è \u001b[1;34mRunning: az account get-access-token --resource https://management.azure.com/ \u001b[0m\n",
      "‚úÖ \u001b[1;32mSuccessfully obtained access token\u001b[0m ‚åö 13:25:56.034547 [0m:2s]\n",
      "Updating the API policy...\n",
      "Response status: \u001b[1;31m400 - Bad Request\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "policy_xml_file = \"policy.xml\"\n",
    "\n",
    "with open(policy_xml_file, 'r') as file:\n",
    "    policy_xml = file.read()\n",
    "    utils.update_api_operation_policy(subscription_id, resource_group_name, apim_resource_name, \"github-mcp\", \"sse\", policy_xml)\n",
    "    utils.update_api_operation_policy(subscription_id, resource_group_name, apim_resource_name, \"github-mcp\", \"messages\", policy_xml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='unauthorizedtest'></a>\n",
    "### üß™ Test the authorization **WITHOUT** a valid token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëâüèΩ \u001b[1;34mCalling sse endpoint WITHOUT authorization...\u001b[0m\n",
      "‚ùå \u001b[1;33mUnexpected status code: 404\u001b[0m ‚åö 13:21:05.145202 \n"
     ]
    }
   ],
   "source": [
    "# Unauthenticated call should fail with 401 Unauthorized\n",
    "import requests\n",
    "utils.print_info(\"Calling sse endpoint WITHOUT authorization...\")\n",
    "response = requests.get(f\"{apim_resource_gateway_url}/github/sse\", headers={\"Content-Type\": \"application/json\"})\n",
    "if response.status_code == 401:\n",
    "    utils.print_ok(\"Received 401 Unauthorized as expected\")\n",
    "elif response.status_code == 200:\n",
    "    utils.print_error(\"Call succeeded. Double check that validate-jwt policy has been deployed to sse endpoint\")\n",
    "else:\n",
    "    utils.print_error(f\"Unexpected status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='authorizedtest'></a>\n",
    "### üß™ Test the authorization **WITH** a valid token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëâüèΩ \u001b[1;34mCalling sse endpoint WITH authorization...\u001b[0m\n",
      "‚öôÔ∏è \u001b[1;34mRunning: az account get-access-token --resource \"https://azure-api.net/authorization-manager\" \u001b[0m\n",
      "‚ùå \u001b[1;33mUnexpected status code: 404\u001b[0m ‚åö 13:26:33.484788 \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "# Authenticated call should succeed\n",
    "utils.print_info(\"Calling sse endpoint WITH authorization...\")\n",
    "output = utils.run(\"az account get-access-token --resource \\\"https://azure-api.net/authorization-manager\\\"\")\n",
    "if output.success and output.json_data:\n",
    "    access_token = output.json_data.get('accessToken')\n",
    "    response = requests.get(f\"{apim_resource_gateway_url}/github/sse\", stream=True,\n",
    "                            headers={\"Content-Type\": \"application/json\", \"Authorization\": \"Bearer \" + str(access_token)})\n",
    "    if response.status_code == 200:\n",
    "        utils.print_ok(\"Received status code 200 as expected\")\n",
    "    else:\n",
    "        utils.print_error(f\"Unexpected status code: {response.status_code}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='kql'></a>\n",
    "### üîç Display model usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az monitor log-analytics query -w 204b7fd8-5082-4477-9870-0bddcc51d833 --analytics-query \"model_usage\" \u001b[0m\n",
      "‚úÖ \u001b[1;32mRetrieved log analytics query output\u001b[0m ‚åö 13:28:57.517269 [0m:43s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "DeploymentName",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "SubscriptionId",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "SumCompletionTokens",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "SumPromptTokens",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "SumTotalTokens",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "TableName",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "d4e7ad3c-9890-4ca7-9658-34e8f6910cd6",
       "rows": [
        [
         "0",
         "gpt-realtime",
         "subscription1",
         "82",
         "47",
         "129",
         "PrimaryResult"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DeploymentName</th>\n",
       "      <th>SubscriptionId</th>\n",
       "      <th>SumCompletionTokens</th>\n",
       "      <th>SumPromptTokens</th>\n",
       "      <th>SumTotalTokens</th>\n",
       "      <th>TableName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-realtime</td>\n",
       "      <td>subscription1</td>\n",
       "      <td>82</td>\n",
       "      <td>47</td>\n",
       "      <td>129</td>\n",
       "      <td>PrimaryResult</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DeploymentName SubscriptionId SumCompletionTokens SumPromptTokens  \\\n",
       "0   gpt-realtime  subscription1                  82              47   \n",
       "\n",
       "  SumTotalTokens      TableName  \n",
       "0            129  PrimaryResult  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "query = \"model_usage\"\n",
    "\n",
    "output = utils.run(f\"az monitor log-analytics query -w {log_analytics_id} --analytics-query \\\"{query}\\\"\", \"Retrieved log analytics query output\", \"Failed to retrieve log analytics query output\") \n",
    "if output.success and output.json_data:\n",
    "    table = output.json_data\n",
    "    display(pd.DataFrame(table))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "### üóëÔ∏è Clean up resources\n",
    "\n",
    "When you're finished with the lab, you should remove all your deployed resources from Azure to avoid extra charges and keep your Azure subscription uncluttered.\n",
    "Use the [clean-up-resources notebook](clean-up-resources.ipynb) for that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
