{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIM ‚ù§Ô∏è AI Foundry\n",
    "\n",
    "## Secure Responses API lab\n",
    "![flow](../../images/built-in-logging.gif)\n",
    "\n",
    "Playground to try the [Azure OpenAI Responses API](https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/responses?tabs=python-secure) in a secure manner.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- [Python 3.12 or later version](https://www.python.org/) installed\n",
    "- [VS Code](https://code.visualstudio.com/) installed with the [Jupyter notebook extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) enabled\n",
    "- [Python environment](https://code.visualstudio.com/docs/python/environments#_creating-environments) with the [requirements.txt](../../requirements.txt) or run `pip install -r requirements.txt` in your terminal\n",
    "- [An Azure Subscription](https://azure.microsoft.com/free/) with [Contributor](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#contributor) + [RBAC Administrator](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#role-based-access-control-administrator) or [Owner](https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/privileged#owner) roles\n",
    "- [Azure CLI](https://learn.microsoft.com/cli/azure/install-azure-cli) installed and [Signed into your Azure subscription](https://learn.microsoft.com/cli/azure/authenticate-azure-cli-interactively)\n",
    "\n",
    "‚ñ∂Ô∏è Click `Run All` to execute all steps sequentially, or execute them `Step by Step`... \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "### 0Ô∏è‚É£ Initialize notebook variables\n",
    "\n",
    "- Resources will be suffixed by a unique string based on your subscription id.\n",
    "- Adjust the location parameters according your preferences and on the [product availability by Azure region.](https://azure.microsoft.com/explore/global-infrastructure/products-by-region/?cdn=disable&products=cognitive-services,api-management) \n",
    "- Adjust the models and versions according the [availability by region.](https://learn.microsoft.com/azure/ai-services/openai/concepts/models) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ \u001b[1;32mNotebook initialized\u001b[0m ‚åö 12:52:50.337847 \n"
     ]
    }
   ],
   "source": [
    "import os, sys, json\n",
    "sys.path.insert(1, '../../shared')  # add the shared directory to the Python path\n",
    "import utils\n",
    "\n",
    "deployment_name = os.path.basename(os.path.dirname(globals()['__vsc_ipynb_file__']))\n",
    "resource_group_name = f\"lab-{deployment_name}\" # change the name to match your naming style\n",
    "resource_group_location = \"westeurope\"\n",
    "\n",
    "aiservices_config = [{\"name\": \"foundry1\", \"location\": \"swedencentral\"}]\n",
    "\n",
    "models_config = [{\"name\": \"gpt-4.1-mini\", \"publisher\": \"OpenAI\", \"version\": \"2025-04-14\", \"sku\": \"GlobalStandard\", \"capacity\": 100}]\n",
    "\n",
    "apim_sku = 'Basicv2'\n",
    "apim_subscriptions_config = [{\"name\": \"subscription1\", \"displayName\": \"Subscription 1\"}, \n",
    "                             {\"name\": \"subscription2\", \"displayName\": \"Subscription 2\"}, \n",
    "                             {\"name\": \"subscription3\", \"displayName\": \"Subscription 3\"}]\n",
    "\n",
    "inference_api_path = \"inference\"  # path to the inference API in the APIM service\n",
    "inference_api_name = \"inference-api\"  # name of the inference API in the APIM service\n",
    "inference_api_type = \"AzureOpenAI\"  # options: AzureOpenAI, AzureAI, OpenAI, PassThrough\n",
    "inference_api_version = \"2025-03-01-preview\"\n",
    "foundry_project_name = deployment_name\n",
    "\n",
    "backend_id = 'foundry1' if len(aiservices_config) > 1 else aiservices_config[0]['name']\n",
    " \n",
    "utils.print_ok('Notebook initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "### 1Ô∏è‚É£ Verify the Azure CLI and the connected Azure subscription\n",
    "\n",
    "The following commands ensure that you have the latest version of the Azure CLI and that the Azure CLI is connected to your Azure subscription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az account show \u001b[0m\n",
      "‚úÖ \u001b[1;32mRetrieved az account\u001b[0m ‚åö 12:53:00.943199 [0m:10s]\n",
      "üëâüèΩ \u001b[1;34mCurrent user: lproux@microsoft.com\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mTenant ID: 2b9d9f47-1fb6-400a-a438-39fe7d768649\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mSubscription ID: d334f2cd-3efd-494e-9fd3-2470b1a13e4c\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "output = utils.run(\"az account show\", \"Retrieved az account\", \"Failed to get the current az account\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    current_user = output.json_data['user']['name']\n",
    "    tenant_id = output.json_data['tenantId']\n",
    "    subscription_id = output.json_data['id']\n",
    "\n",
    "    utils.print_info(f\"Current user: {current_user}\")\n",
    "    utils.print_info(f\"Tenant ID: {tenant_id}\")\n",
    "    utils.print_info(f\"Subscription ID: {subscription_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### 2Ô∏è‚É£ Create deployment using ü¶æ Bicep\n",
    "\n",
    "This lab uses [Bicep](https://learn.microsoft.com/azure/azure-resource-manager/bicep/overview?tabs=bicep) to declarative define all the resources that will be deployed in the specified resource group. Change the parameters or the [main.bicep](main.bicep) directly to try different configurations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az group show --name lab-secure-responses-api \u001b[0m\n",
      "üëâüèΩ \u001b[1;34mResource group lab-secure-responses-api does not yet exist. Creating the resource group now...\u001b[0m\n",
      "‚öôÔ∏è \u001b[1;34mRunning: az group create --name lab-secure-responses-api --location westeurope --tags source=ai-gateway \u001b[0m\n",
      "‚ùå \u001b[1;33mFailed to create the resource group 'lab-secure-responses-api'\u001b[0m ‚åö 12:58:10.250465 [0m:3s] ERROR: User 'lproux@microsoft.com' does not exist in MSAL token cache. Run `az login`.\n",
      "\n",
      "‚öôÔ∏è \u001b[1;34mRunning: az deployment group create --name secure-responses-api --resource-group lab-secure-responses-api --template-file main.bicep --parameters params.json \u001b[0m\n",
      "‚ùå \u001b[1;33mDeployment 'secure-responses-api' failed\u001b[0m ‚åö 12:58:16.426705 [0m:6s] ERROR: c:\\Users\\lproux\\OneDrive - Microsoft\\bkp\\Documents\\GitHub\\MCP-servers-internalMSFT-and-external\\AI-Gateway\\labs\\secure-responses-api\\main.bicep(63,7) : Error BCP037: The property \"modelsConfig\" is not allowed on objects of type \"params\". Permissible properties include \"appInsightsId\", \"appInsightsInstrumentationKey\", \"foundry1Models\", \"foundry2Models\", \"foundry3Models\", \"lawId\". [https://aka.ms/bicep/core-diagnostics#BCP037]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the resource group if doesn't exist\n",
    "utils.create_resource_group(resource_group_name, resource_group_location)\n",
    "\n",
    "# Define the Bicep parameters\n",
    "bicep_parameters = {\n",
    "    \"$schema\": \"https://schema.management.azure.com/schemas/2019-04-01/deploymentParameters.json#\",\n",
    "    \"contentVersion\": \"1.0.0.0\",\n",
    "    \"parameters\": {\n",
    "        \"apimSku\": { \"value\": apim_sku },\n",
    "        \"aiServicesConfig\": { \"value\": aiservices_config },\n",
    "        \"modelsConfig\": { \"value\": models_config },\n",
    "        \"apimSubscriptionsConfig\": { \"value\": apim_subscriptions_config },\n",
    "        \"inferenceAPIName\": { \"value\": inference_api_name },\n",
    "        \"inferenceAPIPath\": { \"value\": inference_api_path },\n",
    "        \"inferenceAPIType\": { \"value\": inference_api_type },\n",
    "        \"foundryProjectName\": { \"value\": foundry_project_name },\n",
    "    }\n",
    "}\n",
    "\n",
    "# Write the parameters to the params.json file\n",
    "with open('params.json', 'w') as bicep_parameters_file:\n",
    "    bicep_parameters_file.write(json.dumps(bicep_parameters))\n",
    "\n",
    "# Run the deployment\n",
    "output = utils.run(f\"az deployment group create --name {deployment_name} --resource-group {resource_group_name} --template-file main.bicep --parameters params.json\",\n",
    "    f\"Deployment '{deployment_name}' succeeded\", f\"Deployment '{deployment_name}' failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### 3Ô∏è‚É£ Get the deployment outputs\n",
    "\n",
    "We are now at the stage where we only need to retrieve the gateway URL and the subscription before we are ready for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az deployment group show --name secure-responses-api -g lab-secure-responses-api \u001b[0m\n",
      "‚ùå \u001b[1;33mFailed to retrieve deployment: secure-responses-api\u001b[0m ‚åö 12:58:19.121611 [0m:2s] ERROR: User 'lproux@microsoft.com' does not exist in MSAL token cache. Run `az login`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtain all of the outputs from the deployment\n",
    "output = utils.run(f\"az deployment group show --name {deployment_name} -g {resource_group_name}\", f\"Retrieved deployment: {deployment_name}\", f\"Failed to retrieve deployment: {deployment_name}\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    log_analytics_id = utils.get_deployment_output(output, 'logAnalyticsWorkspaceId', 'Log Analytics Id')\n",
    "    apim_service_id = utils.get_deployment_output(output, 'apimServiceId', 'APIM Service Id')\n",
    "    apim_resource_name = utils.get_deployment_output(output, 'apimResourceName', 'APIM Resource Name')\n",
    "    apim_resource_gateway_url = utils.get_deployment_output(output, 'apimResourceGatewayURL', 'APIM API Gateway URL')\n",
    "    apim_subscriptions = json.loads(utils.get_deployment_output(output, 'apimSubscriptions').replace(\"\\'\", \"\\\"\"))\n",
    "    for subscription in apim_subscriptions:\n",
    "        subscription_name = subscription['name']\n",
    "        subscription_key = subscription['key']\n",
    "        utils.print_info(f\"Subscription Name: {subscription_name}\")\n",
    "        utils.print_info(f\"Subscription Key: ****{subscription_key[-4:]}\")\n",
    "    api_key = apim_subscriptions[0].get(\"key\") # default api key to the first subscription key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='requests'></a>\n",
    "### üß™ Test the Responses API using a direct HTTP call\n",
    "\n",
    "Tip: Use the [tracing tool](../../tools/tracing.ipynb) to track the behavior and troubleshoot the [policy](policy.xml)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'apim_resource_gateway_url' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mrequests\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m url = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mapim_resource_gateway_url\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minference_api_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/openai/responses?api-version=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minference_api_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28minput\u001b[39m = \u001b[33m'\u001b[39m\u001b[33mWhat is the OpenAI responses API?\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Initialize a session for connection pooling and set any default headers\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'apim_resource_gateway_url' is not defined"
     ]
    }
   ],
   "source": [
    "import json, requests, time\n",
    "\n",
    "url = f\"{apim_resource_gateway_url}/{inference_api_path}/openai/responses?api-version={inference_api_version}\"\n",
    "input = 'What is the OpenAI responses API?'\n",
    "\n",
    "# Initialize a session for connection pooling and set any default headers\n",
    "session = requests.Session()\n",
    "session.headers.update({\n",
    "    'api-key': api_key,\n",
    "    'Content-Type': 'application/json'\n",
    "})\n",
    "\n",
    "try:\n",
    "    response = session.post(url, json = {'model': models_config[0].get('name'), 'input': input})\n",
    "    utils.print_response_code(response)\n",
    "    print(f\"Response headers: {json.dumps(dict(response.headers), indent = 4)}\")\n",
    "\n",
    "    if (response.status_code == 200):\n",
    "        data = json.loads(response.text)\n",
    "        print(f\"Model: {data['model']}\")\n",
    "        print(f\"Token usage: {json.dumps(dict(data['usage']), indent = 4)}\\n\")\n",
    "        print(f\"Output: {json.dumps(data['output'], indent = 4)}\\n\")\n",
    "    else:\n",
    "        print(f\"{response.text}\\n\")\n",
    "\n",
    "finally:\n",
    "    # Close the session to release the connection\n",
    "    session.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sdk'></a>\n",
    "### üß™ Test the Responses API with the Azure OpenAI Python SDK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"resp_00e8183b261271090068fb42324b5c819094f0bb3f615f00d7\",\n",
      "  \"created_at\": 1761296946.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-4.1-mini\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"msg_00e8183b261271090068fb4232a3288190b904fc50c99b7e11\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"Test received! How can I assist you today?\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": []\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"conversation\": null,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": null,\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": \"medium\"\n",
      "  },\n",
      "  \"top_logprobs\": 0,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 12,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 11,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 23\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"content_filters\": null,\n",
      "  \"store\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=f\"{apim_resource_gateway_url}/{inference_api_path}/openai\",\n",
    "    default_query={\"api-version\": inference_api_version},\n",
    "    api_version=inference_api_version\n",
    ")\n",
    "\n",
    "response = client.responses.create(   \n",
    "  model=str(models_config[0].get('name')), \n",
    "  input=\"This is a test.\",\n",
    ")\n",
    "\n",
    "print(response.model_dump_json(indent=2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "### 4Ô∏è‚É£ Update the policy so only the user who creates a response can see it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az account get-access-token --resource https://management.azure.com/ \u001b[0m\n",
      "‚úÖ \u001b[1;32mSuccessfully obtained access token\u001b[0m ‚åö 10:09:13.499737 [0m:5s]\n",
      "Updating the API policy...\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "secure_policy_xml_file = \"secure-policy.xml\"\n",
    "\n",
    "with open(secure_policy_xml_file, 'r') as file:\n",
    "    policy_xml = file.read()\n",
    "    policy_xml = policy_xml.replace('{backend-id}', backend_id)\n",
    "    utils.update_api_policy(subscription_id, resource_group_name, apim_resource_name, inference_api_name, policy_xml)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='testSecureWithDirectHttp'></a>\n",
    "### üß™ Test the Policy change with direct HTTP call\n",
    "\n",
    "In this example, we demonstrate how the new APIM Policy enforces per-user access restrictions ‚Äî meaning that only the user who created a response can view or use it later.\n",
    "\n",
    "The code below:\n",
    "- Obtains an Azure ARM access token to authenticate API requests.\n",
    "- Creates two separate responses using two different simulated users (fishing-user and basketball-user).\n",
    "  - For our example, we send in the userId as a header, but in production you would want to use the user's identity (e.g., from a JWT token). The APIM Policy we are using has this capability built-in, but it is commented out for testing purposes.\n",
    "- Validates retrieval rules:\n",
    "  - The basketball user can retrieve their own response (200 OK).\n",
    "  - The fishing user attempting to retrieve the basketball user‚Äôs response receives a 403 Forbidden.\n",
    "- Checks contextual linking:\n",
    "  - The basketball user sends a follow-up request referencing their previous response (previous_response_id), and the API returns a result that incorporates the prior context.\n",
    "\n",
    "This process confirms that the API:\n",
    "- Correctly enforces ownership-based visibility for responses.\n",
    "- Allows context chaining only for the original creator of a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az account get-access-token --resource https://management.azure.com/ \u001b[0m\n",
      "‚úÖ \u001b[1;32mRetrieved access token\u001b[0m ‚åö 10:09:17.414526 [0m:2s]\n",
      "üëâüèΩ \u001b[1;34mAccess token (masked): eyJ0eXAi...GPQ5kA\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mExpires On: 2025-10-24 11:18:19.000000\u001b[0m\n",
      "üëâüèΩ \u001b[1;34mFishing User Response - 200 expected:\u001b[0m\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {\n",
      "    \"Content-Length\": \"1601\",\n",
      "    \"Content-Type\": \"application/json\",\n",
      "    \"Date\": \"Fri, 24 Oct 2025 09:09:22 GMT\",\n",
      "    \"Strict-Transport-Security\": \"max-age=31536000; includeSubDomains; preload\",\n",
      "    \"apim-request-id\": \"e17b8971-7a09-4839-b863-fd8513241488\",\n",
      "    \"x-ratelimit-limit-tokens\": \"100000\",\n",
      "    \"x-ratelimit-remaining-tokens\": \"99939\",\n",
      "    \"X-Request-ID\": \"aff6fe59-0d99-47ba-accd-f105e1a457f0\",\n",
      "    \"X-Content-Type-Options\": \"nosniff\",\n",
      "    \"x-ms-region\": \"Sweden Central\",\n",
      "    \"x-ratelimit-remaining-requests\": \"98\",\n",
      "    \"x-ms-oai-backend-host\": \"https://aoai-sp-g41mss-414-h100-sec-prod.swedencentral.inference.ml.azure.com\",\n",
      "    \"x-ratelimit-limit-requests\": \"100\",\n",
      "    \"DataPlane-short-context-15gpu\": \"true\",\n",
      "    \"x-ms-cmp-host\": \"cmp.swedencentral.hyena.infra.ai.azure.com\",\n",
      "    \"azure-openai-data-collection\": \"true\",\n",
      "    \"x-ms-client-request-id\": \"Not-Set\",\n",
      "    \"x-ms-deployment-name\": \"gpt-4.1-mini\",\n",
      "    \"x-debug-output-response-id\": \"resp_0d558c36b1104ef90068fb4240dcc881938ac3df89662548e3\",\n",
      "    \"x-debug-user-id\": \"fishing-user\",\n",
      "    \"Request-Context\": \"appId=cid-v1:c78fe494-ae83-4513-b4b3-2af276f9b5a7\"\n",
      "}\n",
      "Model: gpt-4.1-mini\n",
      "Output: [\n",
      "    {\n",
      "        \"id\": \"msg_0d558c36b1104ef90068fb4241304881938b24242b57f11082\",\n",
      "        \"type\": \"message\",\n",
      "        \"status\": \"completed\",\n",
      "        \"content\": [\n",
      "            {\n",
      "                \"type\": \"output_text\",\n",
      "                \"annotations\": [],\n",
      "                \"logprobs\": [],\n",
      "                \"text\": \"That's awesome! Fishing can be a very relaxing and rewarding hobby. What kind of fishing do you enjoy? Freshwater, saltwater, fly fishing, or something else? Any favorite fishing spots or types of fish you like to catch?\"\n",
      "            }\n",
      "        ],\n",
      "        \"role\": \"assistant\"\n",
      "    }\n",
      "]\n",
      "Fishing User Response Id: resp_0d558c36b1104ef90068fb4240dcc881938ac3df89662548e3\n",
      "\n",
      "üëâüèΩ \u001b[1;34mBasketball User Response - 200 expected:\u001b[0m\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {\n",
      "    \"Content-Length\": \"1585\",\n",
      "    \"Content-Type\": \"application/json\",\n",
      "    \"Date\": \"Fri, 24 Oct 2025 09:09:23 GMT\",\n",
      "    \"Strict-Transport-Security\": \"max-age=31536000; includeSubDomains; preload\",\n",
      "    \"apim-request-id\": \"32fdf716-2612-4803-8366-c3af47b31e6e\",\n",
      "    \"x-ratelimit-limit-tokens\": \"100000\",\n",
      "    \"x-ratelimit-remaining-tokens\": \"99907\",\n",
      "    \"X-Request-ID\": \"ec1de315-9036-4ce7-be69-317c2fb8761c\",\n",
      "    \"X-Content-Type-Options\": \"nosniff\",\n",
      "    \"x-ms-region\": \"Sweden Central\",\n",
      "    \"x-ratelimit-remaining-requests\": \"97\",\n",
      "    \"x-ms-oai-backend-host\": \"https://aoai-sp-g41mss-414-h100-sec-prod.swedencentral.inference.ml.azure.com\",\n",
      "    \"x-ratelimit-limit-requests\": \"100\",\n",
      "    \"DataPlane-short-context-15gpu\": \"true\",\n",
      "    \"x-ms-cmp-host\": \"cmp.swedencentral.hyena.infra.ai.azure.com\",\n",
      "    \"azure-openai-data-collection\": \"true\",\n",
      "    \"x-ms-client-request-id\": \"Not-Set\",\n",
      "    \"x-ms-deployment-name\": \"gpt-4.1-mini\",\n",
      "    \"x-debug-output-response-id\": \"resp_08cc438b62ec3aad0068fb424247a08197b3ffc5722a40e68b\",\n",
      "    \"x-debug-user-id\": \"basketball-user\",\n",
      "    \"Request-Context\": \"appId=cid-v1:c78fe494-ae83-4513-b4b3-2af276f9b5a7\"\n",
      "}\n",
      "Model: gpt-4.1-mini\n",
      "Output: [\n",
      "    {\n",
      "        \"id\": \"msg_08cc438b62ec3aad0068fb4242a0e0819793dae78f3684b05c\",\n",
      "        \"type\": \"message\",\n",
      "        \"status\": \"completed\",\n",
      "        \"content\": [\n",
      "            {\n",
      "                \"type\": \"output_text\",\n",
      "                \"annotations\": [],\n",
      "                \"logprobs\": [],\n",
      "                \"text\": \"That's awesome! Basketball is a great sport for fitness, teamwork, and fun. Do you have a favorite position you like to play or a favorite team? Or maybe you want some tips or drills to improve your game?\"\n",
      "            }\n",
      "        ],\n",
      "        \"role\": \"assistant\"\n",
      "    }\n",
      "]\n",
      "Basketball User Response Id: resp_08cc438b62ec3aad0068fb424247a08197b3ffc5722a40e68b\n",
      "\n",
      "üëâüèΩ \u001b[1;34mGet Basketball User Response as Basketball User - 200 expected:\u001b[0m\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {\n",
      "    \"Content-Length\": \"1585\",\n",
      "    \"Content-Type\": \"application/json\",\n",
      "    \"Date\": \"Fri, 24 Oct 2025 09:09:23 GMT\",\n",
      "    \"Strict-Transport-Security\": \"max-age=31536000; includeSubDomains; preload\",\n",
      "    \"azureml-internal-forward-count\": \"0\",\n",
      "    \"openai-version\": \"2020-10-01\",\n",
      "    \"openai-organization\": \"d48f08b1663241bc9c099fcc15168d3b\",\n",
      "    \"X-Request-ID\": \"fbbed625-2d37-41ff-8d08-6eddf7f4fbdb\",\n",
      "    \"openai-processing-ms\": \"124\",\n",
      "    \"azureml-served-by-cluster\": \"hyena-swedencentral-01\",\n",
      "    \"apim-request-id\": \"9648638a-4c9b-4202-95e8-ffa177e8cab0\",\n",
      "    \"X-Content-Type-Options\": \"nosniff\",\n",
      "    \"x-ms-region\": \"Sweden Central\",\n",
      "    \"x-debug-input-response-id\": \"resp_08cc438b62ec3aad0068fb424247a08197b3ffc5722a40e68b\",\n",
      "    \"x-debug-output-response-id\": \"resp_08cc438b62ec3aad0068fb424247a08197b3ffc5722a40e68b\",\n",
      "    \"x-debug-user-id\": \"basketball-user\",\n",
      "    \"Request-Context\": \"appId=cid-v1:c78fe494-ae83-4513-b4b3-2af276f9b5a7\"\n",
      "}\n",
      "Model: gpt-4.1-mini\n",
      "Output: [\n",
      "    {\n",
      "        \"id\": \"msg_08cc438b62ec3aad0068fb4242a0e0819793dae78f3684b05c\",\n",
      "        \"type\": \"message\",\n",
      "        \"status\": \"completed\",\n",
      "        \"content\": [\n",
      "            {\n",
      "                \"type\": \"output_text\",\n",
      "                \"annotations\": [],\n",
      "                \"logprobs\": [],\n",
      "                \"text\": \"That's awesome! Basketball is a great sport for fitness, teamwork, and fun. Do you have a favorite position you like to play or a favorite team? Or maybe you want some tips or drills to improve your game?\"\n",
      "            }\n",
      "        ],\n",
      "        \"role\": \"assistant\"\n",
      "    }\n",
      "]\n",
      "\n",
      "\n",
      "üëâüèΩ \u001b[1;34mGet Basketball User Response as Fishing User - 403 expected:\u001b[0m\n",
      "Response status: \u001b[1;31m403 - Forbidden\u001b[0m\n",
      "Response headers: {\n",
      "    \"Content-Length\": \"37\",\n",
      "    \"Date\": \"Fri, 24 Oct 2025 09:09:23 GMT\",\n",
      "    \"Request-Context\": \"appId=cid-v1:c78fe494-ae83-4513-b4b3-2af276f9b5a7\"\n",
      "}\n",
      "Unauthorized to access this response.\n",
      "\n",
      "üëâüèΩ \u001b[1;34mBasketball User Response - 200 expected, with a response that should include context of something to do with basketball:\u001b[0m\n",
      "Response status: \u001b[1;32m200 - OK\u001b[0m\n",
      "Response headers: {\n",
      "    \"Content-Length\": \"2095\",\n",
      "    \"Content-Type\": \"application/json\",\n",
      "    \"Date\": \"Fri, 24 Oct 2025 09:09:26 GMT\",\n",
      "    \"Strict-Transport-Security\": \"max-age=31536000; includeSubDomains; preload\",\n",
      "    \"apim-request-id\": \"083c8ce4-9744-49d4-a54a-6097ef7c9a71\",\n",
      "    \"x-ratelimit-limit-tokens\": \"100000\",\n",
      "    \"x-ratelimit-remaining-tokens\": \"99816\",\n",
      "    \"X-Request-ID\": \"4bf51c1a-05c1-4937-93d4-dfc8c775e700\",\n",
      "    \"X-Content-Type-Options\": \"nosniff\",\n",
      "    \"x-ms-region\": \"Sweden Central\",\n",
      "    \"x-ratelimit-remaining-requests\": \"96\",\n",
      "    \"x-ms-oai-backend-host\": \"https://aoai-sp-g41mss-414-h100-sec-prod.swedencentral.inference.ml.azure.com\",\n",
      "    \"x-ratelimit-limit-requests\": \"100\",\n",
      "    \"DataPlane-short-context-15gpu\": \"true\",\n",
      "    \"x-ms-cmp-host\": \"cmp.swedencentral.hyena.infra.ai.azure.com\",\n",
      "    \"azure-openai-data-collection\": \"true\",\n",
      "    \"x-ms-client-request-id\": \"Not-Set\",\n",
      "    \"x-ms-deployment-name\": \"gpt-4.1-mini\",\n",
      "    \"x-debug-input-response-id\": \"resp_08cc438b62ec3aad0068fb424247a08197b3ffc5722a40e68b\",\n",
      "    \"x-debug-output-response-id\": \"resp_08cc438b62ec3aad0068fb424404b88197aa0971680bfb175e\",\n",
      "    \"x-debug-user-id\": \"basketball-user\",\n",
      "    \"Request-Context\": \"appId=cid-v1:c78fe494-ae83-4513-b4b3-2af276f9b5a7\"\n",
      "}\n",
      "Model: gpt-4.1-mini\n",
      "Output: [\n",
      "    {\n",
      "        \"id\": \"msg_08cc438b62ec3aad0068fb42445f2081979dcd49e63683f78e\",\n",
      "        \"type\": \"message\",\n",
      "        \"status\": \"completed\",\n",
      "        \"content\": [\n",
      "            {\n",
      "                \"type\": \"output_text\",\n",
      "                \"annotations\": [],\n",
      "                \"logprobs\": [],\n",
      "                \"text\": \"Since you like playing basketball, how about spending some time playing this weekend? Here are a few ideas:\\n\\n1. **Pick-up Game:** Find a local court and join a pick-up game with others.\\n2. **Practice Skills:** Work on shooting, dribbling, or free throws to improve your game.\\n3. **Watch a Game:** Watch a professional or college basketball game, either live or on TV, to learn new moves and strategies.\\n4. **Go Outdoors:** If the weather is nice, shoot hoops at an outdoor court and enjoy the fresh air.\\n5. **Invite Friends:** Organize a friendly game or shoot-around session with friends.\\n\\nIf you want more ideas outside basketball, just let me know!\"\n",
      "            }\n",
      "        ],\n",
      "        \"role\": \"assistant\"\n",
      "    }\n",
      "]\n",
      "Basketball User Response Id: resp_08cc438b62ec3aad0068fb424404b88197aa0971680bfb175e\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json, requests, time\n",
    "\n",
    "access_token = None\n",
    "\n",
    "def pretty_out(resp):\n",
    "    utils.print_response_code(response)\n",
    "    print(f\"Response headers: {json.dumps(dict(response.headers), indent = 4)}\")\n",
    "    if (resp.status_code == 200):\n",
    "        data = json.loads(resp.text)\n",
    "        resp_id = data['id']\n",
    "        print(f\"Model: {data['model']}\")\n",
    "        print(f\"Output: {json.dumps(data['output'], indent = 4)}\")\n",
    "        return resp_id\n",
    "    else:\n",
    "        print(f\"{resp.text}\\n\")\n",
    "        return None\n",
    "\n",
    "# Get an ARM (management) access token via utils.run\n",
    "output = utils.run( \"az account get-access-token --resource https://management.azure.com/\", \"Retrieved access token\", \"Failed to retrieve access token\")\n",
    "\n",
    "if output.success and output.json_data:\n",
    "    access_token = output.json_data.get(\"accessToken\")\n",
    "    expires_on = output.json_data.get(\"expiresOn\")\n",
    "    # Mask all but first 8 / last 6 chars\n",
    "    if access_token:\n",
    "        masked = f\"{access_token[:8]}...{access_token[-6:]}\"\n",
    "        utils.print_info(f\"Access token (masked): {masked}\")\n",
    "    utils.print_info(f\"Expires On: {expires_on}\")\n",
    "else:\n",
    "    utils.print_error(\"Could not fetch token\")\n",
    "\n",
    "baseUrl = f\"{apim_resource_gateway_url}/{inference_api_path}/openai/responses\"\n",
    "queryParams = f\"?api-version={inference_api_version}\"\n",
    "postUrl = f\"{baseUrl}{queryParams}\"\n",
    "\n",
    "# Initialize a session for connection pooling and set any default headers\n",
    "session = requests.Session()\n",
    "session.headers.update({\n",
    "    'api-key': api_key,\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': f'Bearer {access_token}' if access_token else ''\n",
    "})\n",
    "\n",
    "try:\n",
    "    # 1) Create response as fishing user\n",
    "    fishing_response_id = None\n",
    "    session.headers['userId'] = 'fishing-user'\n",
    "    fishing_payload = {\n",
    "        'model': models_config[0].get('name'),\n",
    "        'input': 'Hi, I like to fish'\n",
    "    }\n",
    "    response = session.post(postUrl, json = fishing_payload)\n",
    "    utils.print_info(\"Fishing User Response - 200 expected:\")\n",
    "    fishing_response_id = pretty_out(response)\n",
    "    print(f\"Fishing User Response Id: {fishing_response_id}\\n\")\n",
    "\n",
    "    # 2) Create response as basketball user\n",
    "    basketball_response_id = None\n",
    "    session.headers['userId'] = 'basketball-user'\n",
    "    basketball_payload = {\n",
    "        'model': models_config[0].get('name'),\n",
    "        'input': 'Hi, I like to play basketball'\n",
    "    }\n",
    "    response = session.post(postUrl, json = basketball_payload)\n",
    "    utils.print_info(\"Basketball User Response - 200 expected:\")\n",
    "    basketball_response_id = pretty_out(response)\n",
    "    print(f\"Basketball User Response Id: {basketball_response_id}\\n\")\n",
    "\n",
    "    # 3) Get basketball user response as basketball user - should succeed with 200\n",
    "    session.headers['userId'] = 'basketball-user'\n",
    "    response = session.get(f\"{baseUrl}/{basketball_response_id}{queryParams}\")\n",
    "    utils.print_info(\"Get Basketball User Response as Basketball User - 200 expected:\")\n",
    "    pretty_out(response)\n",
    "    print(f\"\\n\")\n",
    "\n",
    "    # 4) Get basketball user response as fishing user - should fail with 403\n",
    "    session.headers['userId'] = 'fishing-user'\n",
    "    response = session.get(f\"{baseUrl}/{basketball_response_id}{queryParams}\")\n",
    "    utils.print_info(\"Get Basketball User Response as Fishing User - 403 expected:\")\n",
    "    pretty_out(response)\n",
    "\n",
    "    # 5) Post new response as basketball user to get context of previous response - should succeed with 200\n",
    "    session.headers['userId'] = 'basketball-user'\n",
    "    basketball_payload = {\n",
    "        'model': models_config[0].get('name'),\n",
    "        'input': 'What should I do this weekend?',\n",
    "        'previous_response_id': basketball_response_id\n",
    "    }\n",
    "    response = session.post(postUrl, json = basketball_payload)\n",
    "    utils.print_info(\"Basketball User Response - 200 expected, with a response that should include context of something to do with basketball:\")\n",
    "    basketball_response_id = pretty_out(response)\n",
    "    print(f\"Basketball User Response Id: {basketball_response_id}\\n\")\n",
    "\n",
    "\n",
    "finally:\n",
    "    # Close the session to release the connection\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='testSecureWithDirectHttp'></a>\n",
    "### üß™ Test the Policy Change with the Azure OpenAI Python SDK\n",
    "\n",
    "Here we are doing the same example as above, except from the Python SDK. We demonstrate how the new APIM Policy enforces per-user access restrictions ‚Äî meaning that only the user who created a response can view or use it later.\n",
    "\n",
    "The code below:\n",
    "- Obtains a access token to authenticate API requests.\n",
    "- Creates two separate responses using two different simulated users (fishing-user and hiking-user).\n",
    "  - For our example, we send in the userId as a header, but in production you would want to use the user's identity (e.g., from a JWT token). The APIM Policy we are using has this capability built-in, but it is commented out for testing purposes.\n",
    "- Validates retrieval rules:\n",
    "  - The hiking user can retrieve their own response (200 OK).\n",
    "  - The fishing user attempting to retrieve the hiking user‚Äôs response receives a 403 Forbidden.\n",
    "- Checks contextual linking:\n",
    "  - The hiking user sends a follow-up request referencing their previous response (previous_response_id), and the API returns a result that incorporates the prior context.\n",
    "\n",
    "This process confirms that the API:\n",
    "- Correctly enforces ownership-based visibility for responses.\n",
    "- Allows context chaining only for the original creator of a response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected 200, with initial fishing response\n",
      "[ResponseOutputMessage(id='msg_0aba5568ee7ed46d0068fb4251d7f081948d69167566a3b379', content=[ResponseOutputText(annotations=[], text=\"That's great! Fishing is a relaxing and rewarding hobby. Do you have a favorite type of fishing or a favorite spot where you like to fish? Or are you interested in tips, gear recommendations, or fishing techniques?\", type='output_text', logprobs=[])], role='assistant', status='completed', type='message')]\n",
      "Expected 200, with initial hiking response\n",
      "[ResponseOutputMessage(id='msg_00d39673f891f3290068fb4252c8f88190a8d4580713ba10d5', content=[ResponseOutputText(annotations=[], text=\"That's great! Hiking is a wonderful way to enjoy nature, get exercise, and clear your mind. Do you have any favorite hiking spots or types of trails you enjoy? Or are you looking for recommendations or tips?\", type='output_text', logprobs=[])], role='assistant', status='completed', type='message')]\n",
      "Expected 200, with initial hiking response\n",
      "[ResponseOutputMessage(id='msg_00d39673f891f3290068fb4252c8f88190a8d4580713ba10d5', content=[ResponseOutputText(annotations=[], text=\"That's great! Hiking is a wonderful way to enjoy nature, get exercise, and clear your mind. Do you have any favorite hiking spots or types of trails you enjoy? Or are you looking for recommendations or tips?\", type='output_text', logprobs=[])], role='assistant', status='completed', type='message')]\n",
      "Received 403 Forbidden as expected: Unauthorized to access this response.\n",
      "Expected 200, with output that has something to do with hiking for a weekend activity\n",
      "[ResponseOutputMessage(id='msg_00d39673f891f3290068fb425457908190b8fd31cdacb91c5f', content=[ResponseOutputText(annotations=[], text=\"Since you enjoy hiking, how about planning a hike this weekend? Here are a few ideas to make your weekend enjoyable:\\n\\n1. **Explore a New Trail:** Find a nearby hiking trail you haven't explored yet. Look for scenic routes or trails with interesting landmarks like waterfalls, viewpoints, or wildlife.\\n\\n2. **Sunrise or Sunset Hike:** Plan a hike early in the morning or late in the day to catch a beautiful sunrise or sunset from the trail.\\n\\n3. **Day Hike with a Picnic:** Pack a picnic and enjoy a relaxing break at a scenic spot during your hike.\\n\\n4. **Join a Hiking Group:** Check if there are any local hiking clubs or groups hosting hikes this weekend‚Äîit‚Äôs a great way to meet fellow outdoor enthusiasts.\\n\\n5. **Hiking Challenge:** Set a personal goal‚Äîlike hiking a certain distance or elevation‚Äîand challenge yourself.\\n\\nIf you want, I can help you find trails near your location or suggest gear and safety tips. What do you think?\", type='output_text', logprobs=[])], role='assistant', status='completed', type='message')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "# Get an ARM (management) access token via get_bearer_token_provider\n",
    "token_provider = get_bearer_token_provider(DefaultAzureCredential(), \"https://management.azure.com/.default\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    default_headers={'api-key': f'{api_key}'},\n",
    "    base_url=f\"{apim_resource_gateway_url}/{inference_api_path}/openai\",\n",
    "    azure_ad_token_provider=token_provider,\n",
    "    api_version=inference_api_version\n",
    ")\n",
    "\n",
    "# 1) Create response as fishing user\n",
    "fishing_response = client.responses.create(   \n",
    "  model=str(models_config[0].get('name')), \n",
    "  input=\"Hi, I enjoy fishing.\",\n",
    "  extra_headers={'userId': 'fishing-user'}\n",
    ")\n",
    "print(\"Expected 200, with initial fishing response\")\n",
    "print(fishing_response.output) \n",
    "\n",
    "# 2) Create response as hiking user\n",
    "hiking_response = client.responses.create(   \n",
    "  model=str(models_config[0].get('name')), \n",
    "  input=\"Hi, I enjoy hiking.\",\n",
    "  extra_headers={'userId': 'hiking-user'}\n",
    ")\n",
    "print(\"Expected 200, with initial hiking response\")\n",
    "print(hiking_response.output) \n",
    "\n",
    "# 3) Get hiking user response as hiking user - should succeed with 200\n",
    "try:\n",
    "  hiking_as_hiking_response = client.responses.retrieve(\n",
    "    hiking_response.id,\n",
    "    extra_headers={'userId': 'hiking-user'}\n",
    "  )\n",
    "  print(\"Expected 200, with initial hiking response\")\n",
    "  print(hiking_as_hiking_response.output)\n",
    "except Exception as e:\n",
    "  print(f\"Unexpected error: {e}\")\n",
    "\n",
    "# 4) Get hiking user response as fishing user - should fail with 403\n",
    "try:\n",
    "  hiking_as_fishing_response = client.responses.retrieve(\n",
    "    hiking_response.id,\n",
    "    extra_headers={'userId': 'fishing-user'}\n",
    "  )\n",
    "  print(hiking_as_fishing_response.output)\n",
    "except Exception as e:\n",
    "  print(f\"Received 403 Forbidden as expected: {e}\")\n",
    "\n",
    "# 5) Post new response as hiking user to get context of previous response - should succeed with 200\n",
    "try:\n",
    "  hiking_response = client.responses.create(   \n",
    "    model=str(models_config[0].get('name')), \n",
    "    previous_response_id=hiking_response.id,\n",
    "    input=\"What should I do this weekend?\",\n",
    "    extra_headers={'userId': 'hiking-user'}\n",
    "  )\n",
    "  print(\"Expected 200, with output that has something to do with hiking for a weekend activity\")\n",
    "  print(hiking_response.output)\n",
    "except Exception as e:\n",
    "  print(f\"Unexpected error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='kql'></a>\n",
    "### üîç Display LLM logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è \u001b[1;34mRunning: az monitor log-analytics query -w 950aeb53-28d7-4645-81f7-ef57b140f588 --analytics-query \"let llmHeaderLogs = ApiManagementGatewayLlmLog | where DeploymentName != ''; let llmLogsWithSubscriptionId = llmHeaderLogs | join kind=leftouter ApiManagementGatewayLogs on CorrelationId | project     SubscriptionId = ApimSubscriptionId, DeploymentName, TotalTokens; llmLogsWithSubscriptionId | summarize     SumTotalTokens      = sum(TotalTokens)   by SubscriptionId, DeploymentName\" \u001b[0m\n",
      "‚úÖ \u001b[1;32mRetrieved log analytics query output\u001b[0m ‚åö 10:11:47.374557 [1m:55s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "query = \"let llmHeaderLogs = ApiManagementGatewayLlmLog \\\n",
    "| where DeploymentName != ''; \\\n",
    "let llmLogsWithSubscriptionId = llmHeaderLogs \\\n",
    "| join kind=leftouter ApiManagementGatewayLogs on CorrelationId \\\n",
    "| project \\\n",
    "    SubscriptionId = ApimSubscriptionId, DeploymentName, TotalTokens; \\\n",
    "llmLogsWithSubscriptionId \\\n",
    "| summarize \\\n",
    "    SumTotalTokens      = sum(TotalTokens) \\\n",
    "  by SubscriptionId, DeploymentName\"\n",
    "\n",
    "output = utils.run(f\"az monitor log-analytics query -w {log_analytics_id} --analytics-query \\\"{query}\\\"\", \"Retrieved log analytics query output\", \"Failed to retrieve log analytics query output\") \n",
    "if output.success and output.json_data:\n",
    "    table = output.json_data\n",
    "    display(pd.DataFrame(table))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "### üóëÔ∏è Clean up resources\n",
    "\n",
    "When you're finished with the lab, you should remove all your deployed resources from Azure to avoid extra charges and keep your Azure subscription uncluttered.\n",
    "Use the [clean-up-resources notebook](clean-up-resources.ipynb) for that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
